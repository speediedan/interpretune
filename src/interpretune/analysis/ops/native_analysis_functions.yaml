---
labels_to_ids:
  description: Convert label strings to tensor IDs
  implementation: interpretune.analysis.ops.definitions.labels_to_ids_impl
  aliases: []
  output_schema:
    # TODO: this should be renamed to label_ids to avoid a name collision with common labels from datamodule
    labels:  # directly used
      datasets_dtype: int64
    orig_labels:  # directly used
      datasets_dtype: int64
  input_schema:
    labels:
      datasets_dtype: string
      connected_obj: datamodule

get_answer_indices:
  description: Extract answer indices from batch
  implementation: interpretune.analysis.ops.definitions.get_answer_indices_impl
  aliases: []
  output_schema:
    answer_indices:  # directly used
      datasets_dtype: int64
    tokens:  # directly used
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false

get_alive_latents:
  description: Extract alive latents from cache
  implementation: interpretune.analysis.ops.definitions.get_alive_latents_impl
  aliases: []
  input_schema:
    cache:  # directly used
      required: false
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true
    answer_indices:  # directly used
      required: false
      datasets_dtype: int64
  output_schema:
    alive_latents: # directly used
      required: false
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
    answer_indices:  # indirect only
      required: false
      datasets_dtype: int64

model_forward:
  description: Basic model forward pass
  implementation: interpretune.analysis.ops.definitions.model_forward_impl
  aliases: []
  output_schema:
    answer_logits:
      datasets_dtype: float32
      sequence_type: false
      dyn_dim: 1
      dyn_dim_ceil: max_seq_len
      array_shape: [null, batch_size, vocab_size]
    answer_indices:
      datasets_dtype: int64

model_cache_forward:
  description: Model forward pass with cache
  implementation: interpretune.analysis.ops.definitions.model_cache_forward_impl
  aliases: ['model_forward_cache']
  input_schema:
    cache:  # directly used
      required: false
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true
    answer_indices: # directly used
      required: false
      datasets_dtype: int64
    alive_latents: # directly used
      required: false
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
  output_schema:
    answer_logits:  # directly used
      datasets_dtype: float32
      sequence_type: false
      dyn_dim: 1
      dyn_dim_ceil: max_seq_len
      array_shape: [null, batch_size, vocab_size]
    answer_indices:  # directly used
      datasets_dtype: int64
    cache:  # directly used
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true

model_ablation:
  description: Model ablation analysis
  implementation: interpretune.analysis.ops.definitions.model_ablation_impl
  function_params:
    ablate_latent_fn: interpretune.analysis.ops.definitions.ablate_sae_latent
  aliases: []
  output_schema:
    answer_logits:
      datasets_dtype: float32
      per_latent: true
      sequence_type: false
      array_shape: [batch_size, vocab_size]
    answer_indices:
      datasets_dtype: int64
    alive_latents:
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
    logit_diffs:
      datasets_dtype: float32
      required: false
    loss:
      datasets_dtype: float32
      sequence_type: false
      required: false
    preds:
      datasets_dtype: int64
      required: false
    labels:
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
    tokens:
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:
      datasets_dtype: string
      required: false
      non_tensor: true
  input_schema:
    alive_latents:
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
    logit_diffs:
      datasets_dtype: float32
      required: false
    answer_logits:
      datasets_dtype: float32
      sequence_type: false
      array_shape: [batch_size, max_answer_tokens, num_classes]
    loss:
      datasets_dtype: float32
      sequence_type: false
      required: false
    preds:
      datasets_dtype: int64
      required: false
    labels:  # TODO: this should be renamed to label_ids to avoid a name collision with common labels from datamodule
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
    answer_indices:
      datasets_dtype: int64
    tokens:
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:
      datasets_dtype: string
      required: false
      non_tensor: true

model_gradient:
  description: Model gradient-based attribution
  implementation: interpretune.analysis.ops.definitions.model_gradient_impl
  function_params:
    logit_diff_fn: interpretune.analysis.ops.definitions.boolean_logits_to_avg_logit_diff
    get_loss_preds_diffs: interpretune.analysis.ops.definitions.get_loss_preds_diffs
  aliases: []
  input_schema:
    labels:  # TODO: this should be renamed to label_ids to avoid a name collision with common labels from datamodule
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
  output_schema:
    answer_logits:
      datasets_dtype: float32
      sequence_type: false
      array_shape: [batch_size, max_answer_tokens, num_classes]
    answer_indices:
      datasets_dtype: int64
    loss:
      datasets_dtype: float32
      sequence_type: false
    logit_diffs:
      datasets_dtype: float32
    preds:
      datasets_dtype: int64
    grad_cache:
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true

logit_diffs:
  description: Clean forward pass for computing logit differences
  implementation: interpretune.analysis.ops.definitions.logit_diffs_impl
  function_params:
    logit_diff_fn: interpretune.analysis.ops.definitions.boolean_logits_to_avg_logit_diff
    get_loss_preds_diffs: interpretune.analysis.ops.definitions.get_loss_preds_diffs
  aliases: []
  output_schema:
    logit_diffs:  # directly used
      datasets_dtype: float32
    answer_logits:  # directly used
      datasets_dtype: float32
      sequence_type: false
      array_shape: [batch_size, max_answer_tokens, num_classes]
    loss:  # directly used
      datasets_dtype: float32
      sequence_type: false
    preds:  # directly used
      datasets_dtype: int64
    labels:  # directly used
      datasets_dtype: int64
    orig_labels:  # directly used
      datasets_dtype: int64
    answer_indices:  # directly used
      datasets_dtype: int64
    tokens:  # indirect only
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:  # indirect only
      datasets_dtype: string
      required: false
      non_tensor: true
  input_schema:
    input:
      datasets_dtype: float32
      connected_obj: datamodule
    labels:  # TODO: this should be renamed to label_ids to avoid a name collision with common labels from datamodule
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
    answer_logits:
      datasets_dtype: float32
      sequence_type: false
      dyn_dim: 1
      dyn_dim_ceil: max_seq_len
      array_shape: [null, batch_size, vocab_size]
    answer_indices:
      datasets_dtype: int64

logit_diffs_cache:
  description: Clean forward pass for computing logit differences including cache activations (composition only)
  implementation: interpretune.analysis.ops.definitions.logit_diffs_impl
  function_params:
    logit_diff_fn: interpretune.analysis.ops.definitions.boolean_logits_to_avg_logit_diff
    get_loss_preds_diffs: interpretune.analysis.ops.definitions.get_loss_preds_diffs
  aliases: []
  output_schema:
    logit_diffs:
      datasets_dtype: float32
    answer_logits:
      datasets_dtype: float32
      sequence_type: false
      array_shape: [batch_size, max_answer_tokens, num_classes]
    loss:
      datasets_dtype: float32
      sequence_type: false
    preds:
      datasets_dtype: int64
    labels:
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
    answer_indices:
      datasets_dtype: int64
    tokens:
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:
      datasets_dtype: string
      required: false
      non_tensor: true
    cache:
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true
  input_schema:
    input:
      datasets_dtype: float32
      connected_obj: datamodule
    labels:  # TODO: this should be renamed to label_ids to avoid a name collision with common labels from datamodule
      datasets_dtype: int64
      # connected_obj: datamodule
    orig_labels:
      datasets_dtype: int64
    answer_logits:
      datasets_dtype: float32
      sequence_type: false
      dyn_dim: 1
      dyn_dim_ceil: max_seq_len
      array_shape: [null, batch_size, vocab_size]
    answer_indices:
      datasets_dtype: int64
    cache:
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true

sae_correct_acts:
  description: Compute correct activations from SAE cache
  implementation: interpretune.analysis.ops.definitions.sae_correct_acts_impl
  aliases: []
  output_schema:
    logit_diffs:
      datasets_dtype: float32
    answer_indices:
      datasets_dtype: int64
    tokens:
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:
      datasets_dtype: string
      required: false
      non_tensor: true
    cache:
      required: false
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true
    alive_latents:
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
    correct_activations:
      datasets_dtype: float32
      per_sae_hook: true
  input_schema:
    logit_diffs:
      datasets_dtype: float32
    answer_indices:
      datasets_dtype: int64
    cache:
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true

gradient_attribution:
  description: Compute attribution values from gradients
  implementation: interpretune.analysis.ops.definitions.gradient_attribution_impl
  aliases: []
  output_schema:
    logit_diffs:
      datasets_dtype: float32
    answer_indices:
      datasets_dtype: int64
    tokens:
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:
      datasets_dtype: string
      required: false
      non_tensor: true
    alive_latents:
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
    attribution_values:
      datasets_dtype: float32
      per_sae_hook: true
    correct_activations:
      datasets_dtype: float32
      per_sae_hook: true
    grad_cache:
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true
  input_schema:
    answer_indices:
      datasets_dtype: int64
    logit_diffs:
      datasets_dtype: float32
    grad_cache:
      datasets_dtype: object
      non_tensor: true
      intermediate_only: true

ablation_attribution:
  description: Compute attribution values from ablation
  implementation: interpretune.analysis.ops.definitions.ablation_attribution_impl
  function_params:
    logit_diff_fn: interpretune.analysis.ops.definitions.boolean_logits_to_avg_logit_diff
    get_loss_preds_diffs: interpretune.analysis.ops.definitions.get_loss_preds_diffs
  aliases: []
  output_schema:
    attribution_values:
      datasets_dtype: float32
      per_sae_hook: true
    logit_diffs:
      datasets_dtype: float32
      per_latent: true
    answer_logits:
      datasets_dtype: float32
      per_latent: true
      sequence_type: false
      array_shape: [batch_size, max_answer_tokens, num_classes]
    loss:
      datasets_dtype: float32
      per_latent: true
      sequence_type: false
    preds:
      datasets_dtype: int64
      per_latent: true
    labels:
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
  input_schema:
    answer_indices:
      datasets_dtype: int64
    alive_latents:
      datasets_dtype: int64
      per_sae_hook: true
      non_tensor: true
    logit_diffs:
      datasets_dtype: float32
    answer_logits:
      datasets_dtype: float32
      per_latent: true
      sequence_type: false
      array_shape: [batch_size, vocab_size]
    labels:
      datasets_dtype: int64
    orig_labels:
      datasets_dtype: int64
    tokens:
      datasets_dtype: int64
      required: false
      dyn_dim: 1
      array_shape: [null, batch_size]
      sequence_type: false
    prompts:
      datasets_dtype: string
      required: false
      non_tensor: true

# Composite operations
composite_operations:
  logit_diffs_base:
    composition: labels_to_ids.model_forward.logit_diffs

  logit_diffs_sae:
    composition: labels_to_ids.model_cache_forward.logit_diffs_cache.sae_correct_acts

  logit_diffs_attr_grad:
    composition: labels_to_ids.model_gradient.gradient_attribution

  logit_diffs_attr_ablation:
    composition: labels_to_ids.model_cache_forward.logit_diffs_cache.model_ablation.ablation_attribution
    aliases: [logit_diffs_ablation]
