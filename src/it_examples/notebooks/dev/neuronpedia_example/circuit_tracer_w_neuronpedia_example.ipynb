{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Interpretune Neuronpedia Extension\n",
    "\n",
    "This tutorial demonstrates Interpretune's integration with Circuit Tracer and Neuronpedia, guiding the user through generating and sharing a basic model attribution graph.\n",
    "Future tutorials will demonstrate the use of Interpretune's analytical abstractions to\n",
    "generate, transform and share more advanced model attribution graphs in the context of world model analysis, research or AI agent/application interpretability maximization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Parameters\n",
    "\n",
    "This cell contains parameters that can be modified for different test configurations using papermill.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters - These will be injected by papermill during parameterized test runs\n",
    "use_baseline_salient_logits = True  # logits computation mode: True->salient logits, False->specific logits\n",
    "use_baseline_transcoder_arch = True  # transcoder architecture: True->SingleLayerTranscoder, False->CrossLayerTranscoder\n",
    "core_log_dir = None  # Directory to save analysis logs (if None, a temp directory will be created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import interpretune as it  # registered analysis ops will be available as it.<op> when analysis is imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this example assumes the user has either installed `interpretune` with the `examples` extra\n",
    "# (or that circuit_tracer and neuronpedia are installed separately in addition to base interpretune dependencies)\n",
    "\n",
    "# Import circuit tracer and required modules\n",
    "from transformer_lens import ActivationCache  # noqa: F401\n",
    "from datetime import datetime\n",
    "\n",
    "from it_examples import _ACTIVE_PATCHES  # noqa: F401  # TODO: add note about this unless patched in SL before release\n",
    "from it_examples.example_module_registry import MODULE_EXAMPLE_REGISTRY  # TODO: move to hub once implemented\n",
    "from it_examples.utils.example_helpers import required_os_env\n",
    "from interpretune import ITSessionConfig, ITSession\n",
    "from interpretune.base.call import it_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "env_path: str | None = None  # set to '/full/path/to/.env' to override\n",
    "\n",
    "# Note: We need to set your API keys via environment variables:\n",
    "# export NEURONPEDIA_API_KEY=\"your-production-key\"\n",
    "# export DEV_NEURONPEDIA_API_KEY=\"your-dev-key\"  # if using dev API\n",
    "use_localhost = os.environ.get(\"USE_LOCALHOST\", \"false\").lower() == \"true\"\n",
    "# Note there is a planned request for neuronpedia to qualify USE_LOCALHOST as NP_USE_LOCALHOST\n",
    "os_env_reqs = [(\"DEV_NEURONPEDIA_API_KEY\",)] if use_localhost else [(\"NEURONPEDIA_API_KEY\",)]\n",
    "assert required_os_env(env_path=env_path, env_reqs=os_env_reqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our demo config (this will be done from the hub once that is available)\n",
    "base_itdm_cfg, base_it_cfg, dm_cls, m_cls = MODULE_EXAMPLE_REGISTRY.get(\"gemma2.rte_demo.circuit_tracer_w_neuronpedia\")\n",
    "# Optionally override base_it_cfg.core_log_dir with the notebook parameter if provided\n",
    "if core_log_dir:\n",
    "    base_it_cfg.core_log_dir = core_log_dir\n",
    "# configure our session with our desired adapter composition, core and circuit_tracer in this case\n",
    "session_cfg = ITSessionConfig(\n",
    "    adapter_ctx=(it.Adapter.core, it.Adapter.circuit_tracer),\n",
    "    datamodule_cfg=base_itdm_cfg,\n",
    "    module_cfg=base_it_cfg,\n",
    "    datamodule_cls=dm_cls,\n",
    "    module_cls=m_cls,\n",
    ")\n",
    "\n",
    "# start our session\n",
    "it_session = ITSession(session_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual init for now\n",
    "it_init(**it_session)\n",
    "print(\"\\nIT Session initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Using Circuit Tracer to generate a custom graph and upload to Neuronpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and upload graph in one step\n",
    "prompt = \"The capital of the state containing Dallas is\"\n",
    "ct_module = it_session.module\n",
    "# we use the datetime to ensure the slug is unique\n",
    "slug = f\"it-generated-compute-specific-logits-demo-graph-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "# This method does everything:\n",
    "# - Generates attribution graph\n",
    "# - Transforms it for Neuronpedia compatibility\n",
    "# - Uploads to Neuronpedia\n",
    "# - Returns both the graph and the Neuronpedia metadata\n",
    "\n",
    "# if you want to set custom metadata for Neuronpedia graph, you can do so here.\n",
    "# in this demo, since the circuit-tracer generated graph does not currently have cantor-paired feature nodes, we\n",
    "# need to avoid setting neuronpedia_source_set in the feature_details metadata\n",
    "# temporary hack: https://bit.ly/non_cantor_edge_case\n",
    "graph, local_graph_path, neuronpedia_metadata = ct_module.generate_graph(\n",
    "    prompt=prompt,\n",
    "    slug=slug,\n",
    "    upload_to_np=False,  # Upload the produced graph to Neuronpedia if True, or just return the graph if False\n",
    ")\n",
    "\n",
    "print(f\"Generated and saved graph locally to {local_graph_path}\")\n",
    "\n",
    "if neuronpedia_metadata and hasattr(neuronpedia_metadata, \"url\"):\n",
    "    print(\"Graph uploaded successfully.\")\n",
    "    print(f\"View your graph at: {neuronpedia_metadata.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Just transform an existing graph\n",
    "# transformed_graph, np_metadata = ct_module.neuronpedia.transform_graph_for_np(\n",
    "#     graph_path=local_graph_path,\n",
    "#     # slug=\"it-generated-dallas-austin-demo-graph-20250725-121824-retransformed\",\n",
    "#     upload_to_np=False  # Set to True to upload the transformed graph\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it_latest (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
