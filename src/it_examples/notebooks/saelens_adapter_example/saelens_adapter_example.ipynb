{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretune SAELens Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fine-Tuning Scheduler logo](logo_fts.png){height=\"55px\" width=\"401px\"}\n",
    "\n",
    "### Intro\n",
    "\n",
    "[Interpretune](https://github.com/speediedan/interpretune) is a flexible framework for exploring, analyzing and tuning llm world models. In this tutorial, we'll walk through a simple example of using Interpretune to pursue interpretability research with SAELens. As we'll see, Interpretune handles the required execution context composition, allowing us to use the same code in a variety of contexts, depending upon the level of abstraction required.\n",
    "\n",
    "As a long-time PyTorch and PyTorch Lightning contributor, I've found the PyTorch Lightning framework is the right level of abstraction for a large variety of ML research contexts, but some contexts benefit from using core PyTorch directly. Additionally, some users may prefer to use the core PyTorch framework directly for a wide variety of reasons including maximizing portability. As will be demonstrated here, Interpretune maximizes flexibility and portability by adhering to a well-defined protocol that allows auto-composition of our research module with the adapters required for execution in a wide variety of contexts. In this example, we'll be executing the same module with core PyTorch and PyTorch Lightning, demonstrating the use of `SAELens` w/ Interpretune for interpretability research.\n",
    "\n",
    "> Note - **this is a WIP**, but this is the core idea. If you have any feedback, please let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on memory usage\n",
    "\n",
    "In these exercises, we'll be loading some pretty large models into memory (e.g. Gemma 2-2B and its SAEs, as well as a host of other models in later sections of the material). It's useful to have functions which can help profile memory usage for you, so that if you encounter OOM errors you can try and clear out unnecessary models. For example, we've found that with the right memory handling (i.e. deleting models and objects when you're not using them any more) it should be possible to run all the exercises in this material on a Colab Pro notebook, and all the exercises minus the handful involving Gemma on a free Colab notebook.\n",
    "\n",
    "<details>\n",
    "<summary>See this dropdown for some functions which you might find helpful, and how to use them.</summary>\n",
    "\n",
    "First, we can run some code to inspect our current memory usage. Here's me running this code during the exercise set on SAE circuits, after having already loaded in the Gemma models from the previous section. This was on a Colab Pro notebook.\n",
    "\n",
    "```python\n",
    "# Profile memory usage, and delete gemma models if we've loaded them in\n",
    "namespace = globals().copy() | locals()\n",
    "part32_utils.profile_pytorch_memory(namespace=namespace, filter_device=\"cuda:0\")\n",
    "```\n",
    "\n",
    "<pre style=\"font-family: Consolas; font-size: 14px\">Allocated = 35.88 GB\n",
    "Total = 39.56 GB\n",
    "Free = 3.68 GB\n",
    "┌──────────────────────┬────────────────────────┬──────────┬─────────────┐\n",
    "│ Name                 │ Object                 │ Device   │   Size (GB) │\n",
    "├──────────────────────┼────────────────────────┼──────────┼─────────────┤\n",
    "│ gemma_2_2b           │ HookedSAETransformer   │ cuda:0   │       11.94 │\n",
    "│ gpt2                 │ HookedSAETransformer   │ cuda:0   │        0.61 │\n",
    "│ gemma_2_2b_sae       │ SAE                    │ cuda:0   │        0.28 │\n",
    "│ sae_resid_dirs       │ Tensor (4, 24576, 768) │ cuda:0   │        0.28 │\n",
    "│ gpt2_sae             │ SAE                    │ cuda:0   │        0.14 │\n",
    "│ logits               │ Tensor (4, 15, 50257)  │ cuda:0   │        0.01 │\n",
    "│ logits_with_ablation │ Tensor (4, 15, 50257)  │ cuda:0   │        0.01 │\n",
    "│ clean_logits         │ Tensor (4, 15, 50257)  │ cuda:0   │        0.01 │\n",
    "│ _                    │ Tensor (16, 128, 768)  │ cuda:0   │        0.01 │\n",
    "│ clean_sae_acts_post  │ Tensor (4, 15, 24576)  │ cuda:0   │        0.01 │\n",
    "└──────────────────────┴────────────────────────┴──────────┴─────────────┘</pre>\n",
    "\n",
    "From this, we see that we've allocated a lot of memory for the the Gemma model, so let's delete it. We'll also run some code to move any remaining objects on the GPU which are larger than 100MB to the CPU, and print the memory status again.\n",
    "\n",
    "```python\n",
    "del gemma_2_2b\n",
    "del gemma_2_2b_sae\n",
    "\n",
    "THRESHOLD = 0.1  # GB\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if isinstance(obj, torch.nn.Module) and part32_utils.get_tensors_size(obj) / 1024**3 > THRESHOLD:\n",
    "            if hasattr(obj, \"cuda\"):\n",
    "                obj.cpu()\n",
    "            if hasattr(obj, \"reset\"):\n",
    "                obj.reset()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Move our gpt2 model & SAEs back to GPU (we'll need them for the exercises we're about to do)\n",
    "gpt2.to(device)\n",
    "gpt2_saes = {layer: sae.to(device) for layer, sae in gpt2_saes.items()}\n",
    "\n",
    "part32_utils.print_memory_status()\n",
    "```\n",
    "\n",
    "<pre style=\"font-family: Consolas; font-size: 14px\">Allocated = 14.90 GB\n",
    "Reserved = 39.56 GB\n",
    "Free = 24.66</pre>\n",
    "\n",
    "Mission success! We've managed to free up a lot of memory. Note that the code which moves all objects collected by the garbage collector to the CPU is often necessary to free up the memory. We can't just delete the objects directly because PyTorch can still sometimes keep references to them (i.e. their tensors) in memory. In fact, if you add code to the for loop above to print out `obj.shape` when `obj` is a tensor, you'll see that a lot of those tensors are actually Gemma model weights, even once you've deleted `gemma_2_2b`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (don't read, just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/speediedan/repos/interpretune/src/interpretune/adapters/transformer_lens.py:130: Interpretune manages the HF model instantiation via `model_name_or_path`. Since `tokenizer_name was not provided, the value provided for `tl_cfg.cfg.tokenizer_name` will be used for `tokenizer_name`.\n",
      "/home/speediedan/repos/interpretune/src/interpretune/adapters/transformer_lens.py:130: Interpretune manages the HF model instantiation via `model_name_or_path`. Since `tokenizer_name` was provided, `tl_cfg.cfg.tokenizer_name` will be ignored.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import logging\n",
    "from typing import Any, Dict, Optional, Tuple, List, Callable, Literal\n",
    "from dataclasses import dataclass, field\n",
    "from pprint import pformat\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "\n",
    "import evaluate\n",
    "import datasets\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch import Tensor\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "from transformers.tokenization_utils_base import BatchEncoding\n",
    "from datasets.arrow_dataset import LazyDict\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "#from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from tabulate import tabulate\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from sae_lens import SAE, HookedSAETransformer\n",
    "from sae_lens.toolkit.pretrained_saes_directory import (\n",
    "    #PretrainedSAELookup,\n",
    "    get_pretrained_saes_directory,\n",
    "    #get_repo_id_and_folder_name,\n",
    ")\n",
    "\n",
    "from it_examples.example_module_registry import MODULE_EXAMPLE_REGISTRY\n",
    "from interpretune.adapters.transformer_lens import ITLensConfig\n",
    "from interpretune.adapters.sae_lens import SAELensConfig\n",
    "from interpretune.adapters.core import ITModule\n",
    "from interpretune.base.call import it_init\n",
    "from interpretune.base.config.datamodule import PromptConfig, ITDataModuleConfig\n",
    "from interpretune.base.config.module import ITConfig\n",
    "from interpretune.base.config.mixins import GenerativeClassificationConfig, BaseGenerationConfig, HFGenerationConfig\n",
    "from interpretune.base.components.mixins import ProfilerHooksMixin\n",
    "from interpretune.base.datamodules import ITDataModule\n",
    "from interpretune.utils.logging import rank_zero_warn\n",
    "from interpretune.utils.types import STEP_OUTPUT\n",
    "from interpretune.utils.tokenization import _sanitize_input_name\n",
    "from interpretune.adapters.transformer_lens import ITLensFromPretrainedConfig, ITLensCustomConfig\n",
    "from interpretune.adapters.sae_lens import SAELensFromPretrainedConfig, SAELensCustomConfig\n",
    "from interpretune.base.config.shared import Adapter\n",
    "from interpretune.base.config.datamodule import ITDataModuleConfig\n",
    "from interpretune.base.config.module import ITConfig\n",
    "from interpretune.base.contract.session import ITSessionConfig, ITSession\n",
    "from interpretune.utils.types import StrOrPath\n",
    "from tests import seed_everything\n",
    "from tests.utils import get_model_input_dtype\n",
    "from base_defaults import  BaseCfg\n",
    "from it_examples.notebooks.saelens_adapter_example.sl_utils import sl_mem_utils\n",
    "#from interpretune.base.components.cli import IT_BASE\n",
    "\n",
    "# TODO: re-enable cuda detection after initial cpu-only debugging\n",
    "device = \"cpu\"\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# EXAMPLE_DIR = Path(IT_BASE) / \"experiments\" / \"notebooks\" / \"saelens_adapter_example\"\n",
    "# if str(EXAgenerative_classification_test_steps.path:\n",
    "#     sys.path.append(str(EXAMPLE_DIR))\n",
    "\n",
    "# import sl_utils.part31_tests as part31_tests\n",
    "# import sl_utils.part31_utils as part31_utils\n",
    "# import sl_utils.part32_tests as part32_tests\n",
    "# import sl_utils.sl_mem_utils as part32_utils\n",
    "# from sl_utils.plotly_utils import imshow, line\n",
    "\n",
    "#MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Our IT Module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "\n",
    "TASK_TEXT_FIELD_MAP = {\"rte\": (\"premise\", \"hypothesis\"), \"boolq\": (\"passage\", \"question\")}\n",
    "TASK_NUM_LABELS = {\"boolq\": 2, \"rte\": 2}\n",
    "DEFAULT_TASK = \"rte\"\n",
    "INVALID_TASK_MSG = f\" is an invalid task_name. Proceeding with the default task: {DEFAULT_TASK!r}\"\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class RTEBoolqEntailmentMapping:\n",
    "    entailment_mapping: Tuple = (\"Yes\", \"No\")  # RTE style, invert mapping for BoolQ\n",
    "    entailment_mapping_indices: Optional[torch.Tensor] = None\n",
    "\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class RTEBoolqPromptConfig(PromptConfig):\n",
    "    ctx_question_join: str = 'Does the previous passage imply that '\n",
    "    question_suffix: str = '? Answer with only one word, either Yes or No.'\n",
    "    cust_task_prompt: Optional[Dict[str, Any]] = None\n",
    "\n",
    "#from interpretune.adapters.registration import register_user_composition\n",
    "\n",
    "# if you want add custom attributes to module (ITConfig) or datamodule (ITDataModuleConfig) configs, you can have\n",
    "# Interpretune generate the corresponding adapter configs like so:\n",
    "\n",
    "# @dataclass(kw_only=True)\n",
    "# class RTEBoolqConfig(RTEBoolqEntailmentMapping, ITConfig):\n",
    "#     ...\n",
    "\n",
    "#register_user_composition(RTEBoolqConfig, RTEBoolqEntailmentMapping, ITConfig)\n",
    "# register_user_composition(\"RTEBoolqConfig\", RTEBoolqEntailmentMapping, ITConfig)\n",
    "\n",
    "# which is equivalent to manually generating the configs as follows:\n",
    "\n",
    "# @dataclass(kw_only=True)\n",
    "# class RTEBoolqConfig(RTEBoolqEntailmentMapping, ITConfig):\n",
    "#     ...\n",
    "\n",
    "# @dataclass(kw_only=True)\n",
    "# class RTEBoolqConfig__transformer_lens(RTEBoolqEntailmentMapping, ITLensConfig):\n",
    "#     ...\n",
    "\n",
    "# @dataclass(kw_only=True)\n",
    "# class RTEBoolqConfig__sae_lens(RTEBoolqEntailmentMapping, SAELensConfig):\n",
    "#     ...\n",
    "\n",
    "\n",
    "class RTEBoolqDataModule(ITDataModule):\n",
    "    def __init__(self, itdm_cfg: ITDataModuleConfig) -> None:\n",
    "        if itdm_cfg.task_name not in TASK_NUM_LABELS.keys():\n",
    "            rank_zero_warn(itdm_cfg.task_name + INVALID_TASK_MSG)\n",
    "            itdm_cfg.task_name = DEFAULT_TASK\n",
    "        itdm_cfg.text_fields = TASK_TEXT_FIELD_MAP[itdm_cfg.task_name]\n",
    "        super().__init__(itdm_cfg=itdm_cfg)\n",
    "\n",
    "    def prepare_data(self, target_model: Optional[torch.nn.Module] = None) -> None:\n",
    "        \"\"\"Load the SuperGLUE dataset.\"\"\"\n",
    "        # N.B. prepare_data is called in a single process (rank 0, either per node or globally) so do not use it to\n",
    "        # assign state (e.g. self.x=y)\n",
    "        # note for raw pytorch we require a target_model\n",
    "        # NOTE [HF Datasets Transformation Caching]:\n",
    "        # HF Datasets' transformation cache fingerprinting algo necessitates construction of these partials as the hash\n",
    "        # is generated using function args, dataset file, mapping args: https://bit.ly/HF_Datasets_fingerprint_algo)\n",
    "        tokenization_func = partial(\n",
    "            self.encode_for_rteboolq,\n",
    "            tokenizer=self.tokenizer,\n",
    "            text_fields=self.itdm_cfg.text_fields,\n",
    "            prompt_cfg=self.itdm_cfg.prompt_cfg,\n",
    "            template_fn=self.itdm_cfg.prompt_cfg.model_chat_template_fn,\n",
    "            tokenization_pattern=self.itdm_cfg.cust_tokenization_pattern,\n",
    "        )\n",
    "        dataset = datasets.load_dataset(\"super_glue\", self.itdm_cfg.task_name, trust_remote_code=True)\n",
    "        for split in dataset.keys():\n",
    "            dataset[split] = dataset[split].map(tokenization_func, **self.itdm_cfg.prepare_data_map_cfg)\n",
    "            dataset[split] = self._remove_unused_columns(dataset[split], target_model)\n",
    "        dataset.save_to_disk(self.itdm_cfg.dataset_path)\n",
    "\n",
    "    def dataloader_factory(self, split: str, use_train_batch_size: bool = False) -> DataLoader:\n",
    "        dataloader_kwargs = {\"dataset\": self.dataset[split], \"collate_fn\":self.data_collator,\n",
    "                             **self.itdm_cfg.dataloader_kwargs}\n",
    "        dataloader_kwargs['batch_size'] = self.itdm_cfg.train_batch_size if use_train_batch_size else \\\n",
    "            self.itdm_cfg.eval_batch_size\n",
    "        return DataLoader(**dataloader_kwargs)\n",
    "\n",
    "    # TODO: change to partialmethod's?\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return self.dataloader_factory(split='train', use_train_batch_size=True)\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return self.dataloader_factory(split='validation')\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return self.dataloader_factory(split='validation')\n",
    "\n",
    "    def predict_dataloader(self) -> DataLoader:\n",
    "        return self.dataloader_factory(split='validation')\n",
    "\n",
    "    #TODO: relax PreTrainedTokenizerBase to the protocol that is actually required\n",
    "    @staticmethod\n",
    "    def encode_for_rteboolq(example_batch: LazyDict, tokenizer: PreTrainedTokenizerBase, text_fields: List[str],\n",
    "                            prompt_cfg: PromptConfig, template_fn: Callable,\n",
    "                            tokenization_pattern: Optional[str] = None) -> BatchEncoding:\n",
    "        example_batch['sequences'] = []\n",
    "        # TODO: use promptsource instead of this manual approach after tinkering\n",
    "        for field1, field2 in zip(example_batch[text_fields[0]],\n",
    "                                  example_batch[text_fields[1]]):\n",
    "            if prompt_cfg.cust_task_prompt:\n",
    "                task_prompt = (prompt_cfg.cust_task_prompt['context'] + \"\\n\" +\n",
    "                               field1 + \"\\n\" +\n",
    "                               prompt_cfg.cust_task_prompt['question'] + \"\\n\" +\n",
    "                               field2)\n",
    "            else:\n",
    "                task_prompt = (field1 + prompt_cfg.ctx_question_join + field2 \\\n",
    "                               + prompt_cfg.question_suffix)\n",
    "            sequence = template_fn(task_prompt=task_prompt, tokenization_pattern=tokenization_pattern)\n",
    "            example_batch['sequences'].append(sequence)\n",
    "        features = tokenizer.batch_encode_plus(example_batch[\"sequences\"], padding=\"longest\",\n",
    "                                               padding_side=tokenizer.padding_side)\n",
    "        features[\"labels\"] = example_batch[\"label\"]  # Rename label to labels, easier to pass to model forward\n",
    "        features = _sanitize_input_name(tokenizer.model_input_names, features)\n",
    "        return features\n",
    "\n",
    "# TODO: maybe keep as tensors via cat for future analysis rather than separate batches\n",
    "@dataclass(kw_only=True)\n",
    "class LogitDiffsSumm:\n",
    "    logit_diffs: list[torch.Tensor] = field(default_factory=list)\n",
    "    answer_logits: list[torch.Tensor] = field(default_factory=list)\n",
    "    loss: list[torch.Tensor] = field(default_factory=list)\n",
    "    labels: list[torch.Tensor] = field(default_factory=list)\n",
    "    orig_labels: list[torch.Tensor] = field(default_factory=list)\n",
    "    preds: list[torch.Tensor] = field(default_factory=list)\n",
    "    caches: list[ActivationCache] = field(default_factory=list)\n",
    "    alive_latents: list[int] = field(default_factory=list)\n",
    "    answer_indices: list[torch.Tensor] = field(default_factory=list)\n",
    "    correct_activations: list[torch.Tensor] = field(default_factory=list)\n",
    "    ablation_effects: list[torch.Tensor] = field(default_factory=list)\n",
    "    tokens: list[torch.Tensor] = field(default_factory=list)\n",
    "    prompts: list[str] = field(default_factory=list)\n",
    "\n",
    "DEFAULT_DECODE_KWARGS = dict( skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "logit_diff_summaries = {}\n",
    "\n",
    "def boolean_logits_to_avg_logit_diff(\n",
    "    logits: Float[Tensor, \"batch seq 2\"],\n",
    "    target_indices: torch.Tensor,\n",
    "    reduction: Literal[\"mean\", \"sum\"] | None = \"mean\",\n",
    "    keep_as_tensor: bool = False,\n",
    ") -> list[float] | float:\n",
    "    \"\"\"\n",
    "    Returns the avg logit diff on a set of prompts, with fixed s2 pos and stuff.\n",
    "    \"\"\"\n",
    "    incorrect_indices = 1 - target_indices\n",
    "    correct_logits = torch.gather(logits, 2, torch.reshape(target_indices, (-1,1,1))).squeeze()\n",
    "    incorrect_logits = torch.gather(logits, 2, torch.reshape(incorrect_indices, (-1,1,1))).squeeze()\n",
    "    logit_diff = correct_logits - incorrect_logits\n",
    "    if reduction is not None:\n",
    "        logit_diff = logit_diff.mean() if reduction == \"mean\" else logit_diff.sum()\n",
    "    return logit_diff if keep_as_tensor else logit_diff.tolist()\n",
    "\n",
    "def resolve_answer_indices(tokens):\n",
    "    nonpadding_mask = tokens != 50256\n",
    "    answer_indices = torch.where(nonpadding_mask, 1, 0).sum(dim=1) - 1\n",
    "    return answer_indices\n",
    "\n",
    "def batch_alive_latents(answer_indices, cache, hook_names):\n",
    "    acts = cache[hook_names]\n",
    "    alive_latents = (acts[torch.arange(acts.size(0)), answer_indices, :] > 0).any(dim=0).nonzero().squeeze().tolist()\n",
    "    return alive_latents\n",
    "\n",
    "def ablate_sae_latent(\n",
    "    sae_acts: Tensor,\n",
    "    hook: HookPoint,\n",
    "    latent_idx: int | None = None,\n",
    "    #seq_pos: int | None = None,\n",
    "    seq_pos: torch.Tensor | None = None,  # batched\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Ablate a particular latent at a particular sequence position. If either argument is None, we ablate at all latents\n",
    "    / sequence positions.\n",
    "    \"\"\"\n",
    "    #sae_acts[:, seq_pos, latent_idx] = 0.0\n",
    "    sae_acts[torch.arange(sae_acts.size(0)), seq_pos, latent_idx] = 0.0\n",
    "    return sae_acts\n",
    "\n",
    "class RTEBoolqModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # when using TransformerLens, we need to manually calculate our loss from logit output\n",
    "        self.loss_fn = CrossEntropyLoss()\n",
    "\n",
    "    def setup(self, *args, **kwargs) -> None:\n",
    "        super().setup(*args, **kwargs)\n",
    "        self._init_entailment_mapping()\n",
    "\n",
    "    def _before_it_cfg_init(self, it_cfg: ITConfig) -> ITConfig:\n",
    "        if it_cfg.task_name not in TASK_NUM_LABELS.keys():\n",
    "            rank_zero_warn(it_cfg.task_name + INVALID_TASK_MSG)\n",
    "            it_cfg.task_name = DEFAULT_TASK\n",
    "        it_cfg.num_labels = 0 if it_cfg.generative_step_cfg.enabled else TASK_NUM_LABELS[it_cfg.task_name]\n",
    "        return it_cfg\n",
    "\n",
    "    def load_metric(self) -> None:\n",
    "        self.metric = evaluate.load(\"super_glue\", self.it_cfg.task_name,\n",
    "                                    experiment_id=self._it_state._init_hparams['experiment_id'])\n",
    "\n",
    "    def _init_entailment_mapping(self) -> None:\n",
    "        ent_cfg, tokenizer = self.it_cfg, self.datamodule.tokenizer\n",
    "        token_ids = tokenizer.convert_tokens_to_ids(ent_cfg.entailment_mapping)\n",
    "        device = self.device if isinstance(self.device, torch.device) else self.output_device\n",
    "        ent_cfg.entailment_mapping_indices = torch.tensor(token_ids).to(device)\n",
    "\n",
    "    def labels_to_ids(self, labels: List[str]) -> List[int]:\n",
    "        return torch.take(self.it_cfg.entailment_mapping_indices, labels), labels\n",
    "\n",
    "    # TODO: add this helper function to SL adapter?\n",
    "    def run_with_ctx(self, mode: str, batch: BatchEncoding, batch_idx: int, fwd_hooks_cfg: Optional[Dict] = None, \n",
    "                     hooks_filter: Optional[str]= None, **kwargs):\n",
    "        if mode == 'clean':\n",
    "            return self(**batch), None\n",
    "        elif mode == 'cache_with_saes':\n",
    "            return self.model.run_with_cache_with_saes(**batch, saes=self.sae_handles, names_filter=hooks_filter)\n",
    "        elif mode == 'hooks_with_saes':\n",
    "            assert fwd_hooks_cfg is not None\n",
    "            per_latent_answer_logits = {}\n",
    "            for latent_idx in tqdm(fwd_hooks_cfg['alive_latents'][batch_idx]):\n",
    "                batch_answer_idxs = fwd_hooks_cfg['answer_indices'][batch_idx]\n",
    "                #shape_summ = sl_mem_utils.summarize_cuda_tensors_by_shape()\n",
    "                answer_logits = self.model.run_with_hooks_with_saes(\n",
    "                    **batch,\n",
    "                    saes=self.sae_handles,\n",
    "                    #names_filter=hooks_filter,\n",
    "                    clear_contexts=True,\n",
    "                    fwd_hooks=[\n",
    "                        (fwd_hooks_cfg['hook_names'],\n",
    "                         partial(fwd_hooks_cfg['hook_fn'], latent_idx=latent_idx, seq_pos=batch_answer_idxs)\n",
    "                        )\n",
    "                    ],\n",
    "                )\n",
    "                per_latent_answer_logits[latent_idx] = answer_logits  # answer_logits.detach().cpu()\n",
    "                #shape_summ_after = sl_mem_utils.summarize_cuda_tensors_by_shape()\n",
    "                pass\n",
    "            return per_latent_answer_logits, None\n",
    "        else:\n",
    "            return self.model.run_with_saes(**batch, saes=self.sae_handles)\n",
    "\n",
    "    def ablation_logits_with_labels(\n",
    "        self,\n",
    "        batch: BatchEncoding,\n",
    "        batch_idx: int,\n",
    "        run_ctx: str,\n",
    "        fwd_hooks_cfg: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        label_ids, labels = self.labels_to_ids(batch.pop(\"labels\"))\n",
    "        batch_sz = batch['input'].size(0)\n",
    "        answer_indices = fwd_hooks_cfg['answer_indices'][batch_idx]\n",
    "        per_latent_logits, cache = self.run_with_ctx(run_ctx, batch, batch_idx, fwd_hooks_cfg=fwd_hooks_cfg)\n",
    "        per_latent_logits = {k: v[torch.arange(batch_sz), answer_indices, :] for k, v in per_latent_logits.items()}\n",
    "        #logits = self(**batch)\n",
    "        # TODO: add another layer of abstraction here to handle different model output types? Tradeoffs to consider...\n",
    "        # if not isinstance(logits, torch.Tensor):\n",
    "        #     logits = logits.logits\n",
    "        #     assert isinstance(logits, torch.Tensor), f\"Expected logits to be a torch.Tensor but got {type(logits)}\"\n",
    "        return per_latent_logits, label_ids, labels, cache\n",
    "\n",
    "    def logits_and_labels(self, batch: BatchEncoding, batch_idx: int, run_ctx: str, hooks_filter: Optional[str] = None) -> torch.Tensor:\n",
    "        label_ids, labels = self.labels_to_ids(batch.pop(\"labels\"))\n",
    "        cache = None\n",
    "        logits, cache = self.run_with_ctx(run_ctx, batch, batch_idx, hooks_filter=hooks_filter)\n",
    "        #logits = self(**batch)\n",
    "        # TODO: add another layer of abstraction here to handle different model output types? Tradeoffs to consider...\n",
    "        if not isinstance(logits, torch.Tensor):\n",
    "            logits = logits.logits\n",
    "            assert isinstance(logits, torch.Tensor), f\"Expected logits to be a torch.Tensor but got {type(logits)}\"\n",
    "        return torch.squeeze(logits[:, -1, :], dim=1), label_ids, labels, cache\n",
    "\n",
    "    @ProfilerHooksMixin.memprofilable\n",
    "    def training_step(self, batch: BatchEncoding, batch_idx: int) -> STEP_OUTPUT:\n",
    "        # TODO: need to be explicit about the compatibility constraints/contract\n",
    "        # TODO: note that this example uses generative_step_cfg and lm_head except for the test_step where we demo how to\n",
    "        # use the GenerativeStepMixin to run inference with or without a generative_step_cfg enabled as well as with\n",
    "        # different heads (e.g., seqclassification or LM head in this case)\n",
    "        answer_logits, labels, *_ = self.logits_and_labels(batch, batch_idx)\n",
    "        loss = self.loss_fn(answer_logits, labels)\n",
    "        self.log(\"train_loss\", loss, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    @ProfilerHooksMixin.memprofilable\n",
    "    def validation_step(self, batch: BatchEncoding, batch_idx: int, dataloader_idx: int = 0) -> Optional[STEP_OUTPUT]:\n",
    "        answer_logits, labels, orig_labels, cache = self.logits_and_labels(batch, batch_idx)\n",
    "        val_loss = self.loss_fn(answer_logits, labels)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True, sync_dist=True)\n",
    "        self.collect_answers(answer_logits, orig_labels)\n",
    "\n",
    "    @ProfilerHooksMixin.memprofilable\n",
    "    def test_step(self, batch: BatchEncoding, batch_idx: int, dataloader_idx: int = 0) -> Optional[STEP_OUTPUT]:\n",
    "        if self.it_cfg.generative_step_cfg.enabled:\n",
    "            self.generative_classification_test_step(batch, batch_idx, dataloader_idx=dataloader_idx)\n",
    "        else:\n",
    "            self.default_test_step(batch, batch_idx, dataloader_idx=dataloader_idx)\n",
    "\n",
    "    def generative_classification_test_step(self, batch: BatchEncoding, batch_idx: int, dataloader_idx: int = 0) -> \\\n",
    "        Optional[STEP_OUTPUT]:\n",
    "        labels = batch.pop(\"labels\")\n",
    "        outputs = self.it_generate(batch, **self.it_cfg.generative_step_cfg.lm_generation_cfg.generate_kwargs)\n",
    "        self.collect_answers(outputs.logits, labels)\n",
    "\n",
    "    def save_summary(self, batch: BatchEncoding, summ_map: Dict, out_summ: Optional[LogitDiffsSumm] = None, \n",
    "                           save_prompts: Optional[bool] = False, save_tokens: bool = False, \n",
    "                           save_caches: bool = False, cache: Optional[ActivationCache] = None) -> None:\n",
    "        if save_prompts:\n",
    "            summ_map[\"prompts\"] = self.datamodule.tokenizer.batch_decode(batch['input'], **DEFAULT_DECODE_KWARGS)\n",
    "        if save_tokens:\n",
    "            summ_map[\"tokens\"] = batch['input'].detach().cpu()\n",
    "        if save_caches:\n",
    "            summ_map[\"caches\"] = cache\n",
    "        if out_summ:\n",
    "            for key, val in summ_map.items():\n",
    "                getattr(out_summ, key).append(val.detach().cpu() if isinstance(val, torch.Tensor) else val)\n",
    "        else:\n",
    "            return summ_map\n",
    "\n",
    "    def ablation_test_step(self, batch: BatchEncoding, batch_idx: int, logit_diff_fn: Callable, \n",
    "                                 run_ctx: str = 'hooks_with_saes', fwd_hooks_cfg: Optional[Dict] = None,\n",
    "                                 out_summ: Optional[LogitDiffsSumm] = None, save_caches: bool = False,\n",
    "                                 save_prompts: bool = False, save_tokens: bool = False,\n",
    "                                 dataloader_idx: int = 0, *args, **kwargs) -> \\\n",
    "        Optional[STEP_OUTPUT]:\n",
    "        #torch.cuda.memory._dump_snapshot(Path(self.core_log_dir) / \"before_first_ablation_step.pickle\")\n",
    "        # namespace = globals().copy() | locals()\n",
    "        # sl_mem_utils.profile_pytorch_memory(namespace=namespace, filter_device=\"cuda:0\")\n",
    "        per_latent_answer_logits, labels, orig_labels, cache = self.ablation_logits_with_labels(\n",
    "            batch, batch_idx, run_ctx=run_ctx, fwd_hooks_cfg=fwd_hooks_cfg\n",
    "        )\n",
    "        preds, per_latent_loss, per_latent_logit_diffs, per_latent_preds = None, {}, {}, {}\n",
    "        #aggregate_activations = torch.zeros(self.sae_handles[0].cfg.d_sae)\n",
    "        ablation_effects = torch.zeros(batch['input'].size(0), self.sae_handles[0].cfg.d_sae)\n",
    "        # TODO: return per-latent cache, preds, logit_diffs and loss or just ablation_effects?\n",
    "        for latent_idx, logits in per_latent_answer_logits.items():\n",
    "            per_latent_loss[latent_idx] = self.loss_fn(logits, labels)\n",
    "            logits = self.standardize_logits(logits)\n",
    "            per_example_answers, _ = torch.max(logits, dim=-2)\n",
    "            per_latent_preds[latent_idx] = torch.argmax(per_example_answers, axis=-1)\n",
    "            logit_diffs = logit_diff_fn(logits, target_indices=orig_labels, reduction=None, keep_as_tensor=True)\n",
    "            example_mask = (logit_diffs > 0).cpu()\n",
    "            per_latent_logit_diffs[latent_idx] = logit_diffs[example_mask].detach().cpu()\n",
    "            # for the edge case where the mask/saved batch tensors are scalars (usually due to a batch size of 1)\n",
    "            for t in [example_mask, fwd_hooks_cfg['base_logit_diffs'][batch_idx]]:\n",
    "                if t.dim() == 0:\n",
    "                    t.unsqueeze_(0)\n",
    "            ablation_effects[example_mask, latent_idx] = (\n",
    "                fwd_hooks_cfg['base_logit_diffs'][batch_idx][example_mask] - per_latent_logit_diffs[latent_idx]\n",
    "            )\n",
    "            #self.model.reset_hooks(including_permanent=True)\n",
    "\n",
    "        summ_map = {\"loss\": per_latent_loss, \"logit_diffs\": per_latent_logit_diffs, \"labels\": labels,\n",
    "                    \"orig_labels\": orig_labels, \"preds\": per_latent_preds, \"ablation_effects\": ablation_effects}\n",
    "        #torch.cuda.memory._dump_snapshot(Path(self.core_log_dir) / \"after_first_ablation_step_before_save.pickle\")\n",
    "        self.save_summary(batch, summ_map, out_summ, save_prompts, save_tokens, save_caches, cache)\n",
    "        #torch.cuda.memory._dump_snapshot(Path(self.core_log_dir) / \"after_first_ablation_step_after_save.pickle\")\n",
    "        #pass\n",
    "\n",
    "    def activation_cache_test_step(self, batch: BatchEncoding, batch_idx: int, logit_diff_fn: Callable, \n",
    "                                   hooks_filter: str, run_ctx: str = 'clean', out_summ: Optional[LogitDiffsSumm] = None,\n",
    "                                   save_caches: bool = False, save_prompts: bool = False, save_tokens: bool = False,\n",
    "                                   dataloader_idx: int = 0) -> \\\n",
    "        Optional[STEP_OUTPUT]:\n",
    "        answer_logits, labels, orig_labels, cache = self.logits_and_labels(batch, batch_idx, run_ctx=run_ctx, hooks_filter=hooks_filter)\n",
    "        loss = self.loss_fn(answer_logits, labels)\n",
    "        answer_logits = self.standardize_logits(answer_logits)\n",
    "        per_example_answers, _ = torch.max(answer_logits, dim=-2)\n",
    "        preds = torch.argmax(per_example_answers, axis=-1)  # type: ignore[call-arg]\n",
    "        logit_diffs = logit_diff_fn(answer_logits, target_indices=orig_labels, reduction=None, keep_as_tensor=True)\n",
    "        for t in [logit_diffs]:\n",
    "            if t.dim() == 0:\n",
    "                t.unsqueeze_(0)\n",
    "        summ_map = {\"loss\": loss, \"logit_diffs\": logit_diffs, \"labels\": labels, \"orig_labels\": orig_labels, \n",
    "                    \"preds\": preds, \"answer_logits\": answer_logits}\n",
    "        if run_ctx == 'cache_with_saes':\n",
    "            answer_indices = resolve_answer_indices(batch['input'].detach().cpu()) if \\\n",
    "                self.datamodule.tokenizer.padding_side == 'right' else torch.full((batch['input'].size(0),), -1)\n",
    "            alive_latents = batch_alive_latents(answer_indices, cache, hooks_filter)\n",
    "            correct_activations = cache[hooks_filter][(logit_diffs > 0), -1, :]\n",
    "            #avg_correct_activation = .mean(dim=0)\n",
    "            summ_map.update({\"answer_indices\": answer_indices, \"alive_latents\": alive_latents,\n",
    "                             \"correct_activations\": correct_activations})\n",
    "        self.save_summary(batch, summ_map, out_summ, save_prompts, save_tokens, save_caches, cache)\n",
    "\n",
    "    def default_test_step(self, batch: BatchEncoding, batch_idx: int, dataloader_idx: int = 0) -> Optional[STEP_OUTPUT]:\n",
    "        labels = batch.pop(\"labels\")\n",
    "        outputs = self(**batch)\n",
    "        self.collect_answers(outputs.logits, labels)\n",
    "\n",
    "    def predict_step(self, batch: BatchEncoding, batch_idx: int, dataloader_idx: int = 0) -> Optional[STEP_OUTPUT]:\n",
    "        labels = batch.pop(\"labels\")\n",
    "        outputs = self(**batch)\n",
    "        return self.collect_answers(outputs, labels, mode='return')\n",
    "\n",
    "    def collect_answers(self, logits: torch.Tensor | tuple, labels: torch.Tensor, mode: str = 'log') -> Optional[Dict]:\n",
    "        logits = self.standardize_logits(logits)\n",
    "        per_example_answers, _ = torch.max(logits, dim=-2)\n",
    "        preds = torch.argmax(per_example_answers, axis=-1)  # type: ignore[call-arg]\n",
    "        metric_dict = self.metric.compute(predictions=preds, references=labels)\n",
    "        # TODO: check if this type casting is still required for lightning torchmetrics, bug should be fixed now...\n",
    "        metric_dict = dict(map(lambda x: (x[0], torch.tensor(x[1], device=self.device)\n",
    "                                          .to(torch.float32)), \n",
    "                               metric_dict.items()))\n",
    "        if mode == 'log':\n",
    "            self.log_dict(metric_dict, prog_bar=True, sync_dist=True)\n",
    "        else:\n",
    "            return metric_dict\n",
    "\n",
    "    def standardize_logits(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        # to support generative classification/non-generative classification configs and LM/SeqClassification heads we\n",
    "        # adhere to the following logits logical shape invariant:\n",
    "        # [batch size, positions to consider, answers to consider]\n",
    "        if isinstance(logits, tuple):\n",
    "            logits = torch.stack([out for out in logits], dim=1)\n",
    "        logits = logits.to(device=self.device)\n",
    "        if logits.ndim == 2:  # if answer logits have already been squeezed\n",
    "            logits = logits.unsqueeze(1)\n",
    "        if logits.shape[-1] != self.it_cfg.num_labels:\n",
    "            logits = torch.index_select(logits, -1, self.it_cfg.entailment_mapping_indices)\n",
    "            if not self.it_cfg.generative_step_cfg.enabled:\n",
    "                logits = logits[:, -1:, :]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure our IT Session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/speediedan/repos/interpretune/src/interpretune/adapters/transformer_lens.py:282: Overriding `device_map` passed to TransformerLens to transform pretrained weights on cpu prior to moving the model to target device: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/speediedan/.venvs/it_latest/lib/python3.12/site-packages/sae_lens/toolkit/pretrained_sae_loaders.py:203: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(file_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "from interpretune.adapters.transformer_lens import TLensGenerationConfig\n",
    "from interpretune.base.config.mixins import HFFromPretrainedConfig\n",
    "from interpretune.adapters.transformer_lens import ITLensFromPretrainedNoProcessingConfig\n",
    "from interpretune.base.config.shared import ITSharedConfig, AutoCompConfig\n",
    "\n",
    "#torch.cuda.memory._record_memory_history()\n",
    "\n",
    "shared_cfg = ITSharedConfig(model_name_or_path='gpt2', task_name='rte', tokenizer_id_overrides={'pad_token_id': 50256},\n",
    "                  tokenizer_kwargs={'model_input_names': ['input'], 'padding_side': 'left', 'add_bos_token': True})\n",
    "datamodule_cfg = ITDataModuleConfig(prompt_cfg=RTEBoolqPromptConfig(), train_batch_size=2, eval_batch_size=2,\n",
    "                                    signature_columns=['input', 'labels'], prepare_data_map_cfg={\"batched\": True})\n",
    "genclassif_cfg = GenerativeClassificationConfig(enabled=True, lm_generation_cfg=TLensGenerationConfig(max_new_tokens=1))\n",
    "hf_cfg = HFFromPretrainedConfig(pretrained_kwargs={'torch_dtype': 'float32'}, model_head='transformers.GPT2LMHeadModel')\n",
    "tl_cfg = ITLensFromPretrainedNoProcessingConfig(model_name=\"gpt2-small\", default_padding_side='left')\n",
    "# testing using attention SAEs release here instead of pre resid small res\n",
    "# sae_cfgs = [\n",
    "#     SAELensFromPretrainedConfig(release=\"gpt2-small-res-jb\", sae_id=\"blocks.9.hook_resid_pre\"),\n",
    "#     SAELensFromPretrainedConfig(release=\"gpt2-small-res-jb\", sae_id=\"blocks.10.hook_resid_pre\"),\n",
    "# ]\n",
    "sae_cfgs = [\n",
    "    SAELensFromPretrainedConfig(release=\"gpt2-small-hook-z-kk\", sae_id=\"blocks.9.hook_z\"),\n",
    "    SAELensFromPretrainedConfig(release=\"gpt2-small-hook-z-kk\", sae_id=\"blocks.10.hook_z\"),\n",
    "]\n",
    "auto_comp_cfg = AutoCompConfig(module_cfg_name='RTEBoolqConfig', module_cfg_mixin=RTEBoolqEntailmentMapping)\n",
    "module_cfg = ITConfig(auto_comp_cfg=auto_comp_cfg, generative_step_cfg=genclassif_cfg, hf_from_pretrained_cfg=hf_cfg,\n",
    "                      tl_cfg=tl_cfg, sae_cfgs=sae_cfgs)\n",
    "\n",
    "session_cfg = ITSessionConfig(adapter_ctx=(Adapter.core, Adapter.sae_lens),\n",
    "                              datamodule_cls=RTEBoolqDataModule, module_cls=RTEBoolqModule,\n",
    "                              shared_cfg=shared_cfg, datamodule_cfg=datamodule_cfg, module_cfg=module_cfg)\n",
    "it_session = ITSession(session_cfg)\n",
    "# TODO: maybe open a PR for the below\n",
    "# https://github.com/jbloomAus/SAELens/blob/aa8f42bf06d9c68bb890f4881af0aac916ecd17c/sae_lens/sae.py#L144-L151 warning\n",
    "# that inspects whether the loaded model has a default config override specified in ``pretrained_saes.yaml`` (e.g.\n",
    "# 'gpt2-small-res-jb', config_overrides: model_from_pretrained_kwargs: center_writing_weights: true) and if so, avoids\n",
    "# giving an arguably spurious warning to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repr(module_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"hello world\"\n",
    "# sl_test_module = it_session.module\n",
    "# filter_sae_acts = lambda name: \"hook_sae_acts_post\" in name\n",
    "# cache_dict = {\"fwd\": {}, \"bwd\": {}}\n",
    "\n",
    "\n",
    "# def cache_hook(act, hook, dir: Literal[\"fwd\", \"bwd\"]):\n",
    "#     cache_dict[dir][hook.name] = act.detach()\n",
    "\n",
    "# with sl_test_module.model.saes(saes=sl_test_module.sae_handles):\n",
    "#     # We add hooks to cache values from the forward and backward pass respectively\n",
    "#     with sl_test_module.model.hooks(\n",
    "#         fwd_hooks=[(filter_sae_acts, partial(cache_hook, dir=\"fwd\"))],\n",
    "#         bwd_hooks=[(filter_sae_acts, partial(cache_hook, dir=\"bwd\"))],\n",
    "#     ):\n",
    "#         # fill fwd/bwd cache, hooks then removed on cm exit\n",
    "#         out = sl_test_module.model(prompt)\n",
    "#         out[0, -1, 42].backward()\n",
    "\n",
    "# cache_dict = {k: ActivationCache(cache_dict[k], sl_test_module.model) for k in cache_dict.keys()}\n",
    "# for cache in cache_dict.values():\n",
    "#     assert isinstance(cache, ActivationCache)\n",
    "#     for sae_handle in sl_test_module.sae_handles:\n",
    "#         assert sae_handle.name + \".hook_sae_acts_post\" in cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_grad_enabled(False)\n",
    "\n",
    "# pass\n",
    "\n",
    "# gpt2: HookedSAETransformer = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "# gpt2_sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "#     release=\"gpt2-small-res-jb\",\n",
    "#     sae_id=\"blocks.7.hook_resid_pre\",\n",
    "#     device=str(device),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dashboard(\n",
    "    sae_release=\"gpt2-small-res-jb\",\n",
    "    sae_id=\"blocks.9.hook_resid_pre\",\n",
    "    latent_idx=0,\n",
    "    width=800,\n",
    "    height=600,\n",
    "):\n",
    "    release = get_pretrained_saes_directory()[sae_release]\n",
    "    neuronpedia_id = release.neuronpedia_id[sae_id]\n",
    "\n",
    "    url = f\"https://neuronpedia.org/{neuronpedia_id}/{latent_idx}?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
    "\n",
    "    print(url)\n",
    "    display(IFrame(url, width=width, height=height))\n",
    "\n",
    "sl_test_module = it_session.module\n",
    "gpt2_sae = sl_test_module.saes[0].handle  # just inspect the first SAE for now\n",
    "latent_idx = random.randint(0, gpt2_sae.cfg.d_sae)\n",
    "#display_dashboard(latent_idx=latent_idx, sae_id=gpt2_sae.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# attn_saes = {\n",
    "#     layer: SAE.from_pretrained(\n",
    "#         \"gpt2-small-hook-z-kk\",\n",
    "#         f\"blocks.{layer}.hook_z\",\n",
    "#         device=str(device),\n",
    "#     )[0]\n",
    "#     for layer in range(sl_test_module.cfg.n_layers)\n",
    "# }\n",
    "\n",
    "layer = 9\n",
    "\n",
    "# display_dashboard(\n",
    "#     sae_release=\"gpt2-small-hook-z-kk\",\n",
    "#     sae_id=f\"blocks.{layer}.hook_z\",\n",
    "#     latent_idx=2,  # or you can try `random.randint(0, attn_saes[layer].cfg.d_sae)`\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ca106440dc4fcd93bf3d87d0b526b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb951d0bde7433a995eff4b8bc1cb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d749763c12f436587d99f037f5a2a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c467fc92c8e54752bc06736e94abc825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1575e1b99c694ae893c0c7c4fa700ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/277 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e21f192267e49698a109619e597f0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3644e975b143899968cfaa44bf2a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe319721fab411582ae41db5aa3ba80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a0d0aafd4e4bd3869d52396049a269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9d10c865204422984945c3c20300c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda3cee62d5c464ea8c58bdce4bd623b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef90339edac46ac9f1ef55cf7049207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1c93d59e4a459d97d52aa1e3ed5df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f431c0006b41958068b1ae51400553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ccf773b81c415bb43f2d89865e60c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870610c013f349dab49cc4723f601f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e57550018f48d49ba79209bffc85f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9a86060670445cbc5fadd9378295e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8044d610f24871bb29d58358c3358d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4eba877b4d49b9b9bc0fbb6ea8e37f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98cf1407dc343708f2ddd4deed478a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabe9c1d844b407e810753c0fc0462e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e3778da60946bfb88bc7564c3aac32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f2039ceb8747a58878ee9f312123b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b29662530b4df3a68877bf7b4ec6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4211304b7ae4ab885dbc82b621a04b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695d51f3fbb446a293eea5e2fcd3a335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68179be026da44d7807cd53984f11737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e39b4fa77de4961b49fc7efa35eaa46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db444bf56d064a4ebdb1b32d9473c655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf85841a0ec4eaba7d95423e47394f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57b8549dc914a7eae5e5f456c67582d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70f5a7ef2b4c40eea8935871d5398a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b028651883df4d33bea0cd16cedb17e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b013dd945bfc4719a048dcda69d9a000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598b8676609b40fc84ef6f9fd526660f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c6c2a9d0ac494fb88b7921de8b12d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a5e7cd6a804787b14494aed17e8015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610a663135a34731994efceb4ff705d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8fe9add488445d9de4ebff0ce961d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644ff21585d54d61a7063700df0aa6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63280acc622e409da29a45ce12eb5c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96a1ad697e343359df3677fb286e8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc6531ae7f543a0bc1821d326bce994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b611e4e2d1476d90316b278cc6a679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5098639cd2564b37b7dbc7cbace7304e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f62482368146aa89863f44da4e3403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22839ab753c499280737412378a1117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bc35e2d6134b6eb556c54915e5a70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1de79c9a139440bb3fa7ed7c79d3d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e5499335d54d829276cde17d84cace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee29d43616e4eba81647a1740409327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dee7f47b8f847ed923979f03050ed1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf97f66aec8b45a6970a3e1a30bd37ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8babb2391d94095b771247ca04416c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6cf7899ef84c1b8e27b3daa063e033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcab1ab853a41d69137f2533ab95804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae84df75a3449bbb9cf5c70a41dd24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b9553c674c446da0f3c07b16da61ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ebb82301ec4619b38967ba531d7994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ef1ef861db4e219c6ee3424f2756ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac62299f429547d9af0f10836de1d74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869a359b8e3e402db2f53f154dd0aeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c333c6507094de8b8d4cc513221251b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afba24c4569a44fb8789a461ec918875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29ca81c4292454c9bb5d4290f610c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51f888c6ba8440eb4ceb882fd98e8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae568e12ab1c4e108c48713ad1a34b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d655d25cd544ecb9e4f822868c4ba07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a9601b9b854eadae817cedb95472cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74f1d42172f462bb58c2bd72a7c48ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04ea462d3174efe904960ef5d43b631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75cb8f9e99cf4d26a075036da904a69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e414afcebaac474f86e13880a06e984d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb8e1550dc648b6bc56a6234f1d7670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fe89fa49e94bc6ad53781bb8a7a5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1951e26d7504a0ebe4bffe80e56f86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bb20e0084d452fa6d13363f53b4d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f3c7f2d7b548bcba8fd7f222425332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad08b8284b8440b6a6224f70a10d5afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29440b1d338440f5b39342e35b79191c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5d6493956242208db769b05892eff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28a483df0f1468387910d9ef6197cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b26557e4c9c47fe892db822283d9800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0521d498d36442ba8d068dee7683b904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c15b0aabed446e8547ddc2f822abfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa273d12745d4f88b379d039fe9110c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30576395c6a34ede9e31f2c32803640b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df196aafe474b97ba42194e4f308aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1ebbb1dfba43be89bd8882270b73a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed983ad0fa471d9b1edf5fc8f25ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12ed88581f24caf97aaf0cb6a69c583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abbedaedf6f44dfbc60b9e55eb4e588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eab0bfdf0545f6b0429075e11159cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7547581bb724f108b3f0269fe7ec64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "045481631a174a549fd15e40daa520e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fea2fc054d4ae29884446f8b089747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fde90475904c2991372d7754fa454b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ddb5f819974e90abfc76a1cc6a108f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d7b846ec6649fd80cec4357d7cd201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c19d3708d54dab8403059f67067210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b6848209bc459c89cb1dc87055ef4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7eff720175742e9987960787f3b4d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c91f62983364b54ac4378073a453361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b205a8468ca549d6af16f4e3d7da3d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242b1f96759644a29d97e4cd9b6598b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a297003d033e4fa980fcf807daf98e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1846b197bc4d8d86678319b9b0b7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9546073ce6b44119a5ab64ea0a825bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea999816f82941d68495bbf3bd921ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aed4f12f4bc4193aaa8efa396c08adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a014700fc2a34226b309318558aadc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45546616b7a477a978356f2d8f6288a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55117dd650340c1947e0930efee8ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4ab03cff4b409fb226cf0c75a80380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7d51d5dfd54bb49e007f7ba612b48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7eb7558dbb4e7bad99304b510f617b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c918f381b76a4f4583e28e0a5a2f1d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5c8b3da51c4694ac0d7bdfed968317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7cdfb4341a48879e8f81f5b5088fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3755c885d484dca820b7db0055826b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cfbcea2a9c941338f720f41e91b61f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114862f158984c4db8fe94c95fbbbeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d42bfd38c2b04c5cbaac9aa64142267b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc4dd89e4f844b79daff8d4a886158a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb0396b7b9e4fedbb910f6f2b0753ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68127aa93e0448ab9469efef6468cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7696b2d4ecc47afa1a447cbdc91a86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3373439309bd4762b0e3f096747bf360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b04a0c64594190a565980e30edd050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9defc26f2d15400e9116b75b4b87bf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e74a5d1df0b429d9ebcbc8f7bc123b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369f020801eb4aba9744c08411ad2650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d53bf023234ed3a4aecbe52abe1726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5008e6e989dc4d1a8f18e0767a5e47a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649e1945a94242b983480de8b443cf5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3971069c50c5491aad5cbab2ffc1ca7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939bcc21b4d14c878702eaca9ad6cb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43526b99ec9c4dcba493cd33d529f868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58ff78c086d48c7aadad57e57a2a5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380aafc6d68d4b529a9251ddb5ef3c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce1753f64b9491daf24781edca8f9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2890ecdd7c214889a48650e4368ef588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0218c4898aa5477d84500f55045e7bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8979e5379943f68f77954734960b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b05cffad894c2a95dc9cfa8dc8f756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87b35fcfbcf415c92abf1de9905e271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogitDiffsSumm(logit_diffs=[{70: tensor([0.4429]), 4963: tensor([0.4689]), 9492: tensor([0.4424]), 17491: tensor([0.4424]), 17550: tensor([0.4424]), 18914: tensor([0.4424]), 21642: tensor([0.4424]), 21988: tensor([0.4363])}, {1750: tensor([0.2972, 0.6439]), 2102: tensor([0.2970, 0.6442]), 7482: tensor([0.2928, 0.6439]), 7823: tensor([0.2970, 0.6500]), 8721: tensor([0.2970, 0.6475]), 13212: tensor([0.2970, 0.6440]), 13701: tensor([0.2970, 0.6442]), 16325: tensor([0.2970, 0.6423]), 24551: tensor([0.2970, 0.6424])}, {4963: tensor([]), 6600: tensor([]), 7690: tensor([]), 12680: tensor([])}, {70: tensor([]), 1172: tensor([]), 3986: tensor([]), 4963: tensor([]), 7267: tensor([]), 11786: tensor([]), 12817: tensor([]), 13187: tensor([]), 17588: tensor([]), 21328: tensor([])}, {70: tensor([0.1190]), 1063: tensor([0.0987]), 2107: tensor([0.1192]), 4963: tensor([0.0734]), 5374: tensor([0.1192]), 7146: tensor([0.1192]), 12943: tensor([0.1069]), 17489: tensor([0.1269])}, {2421: tensor([0.3577]), 4505: tensor([0.3428]), 4858: tensor([0.3519]), 7261: tensor([0.3540]), 17407: tensor([0.3540]), 17704: tensor([0.3525]), 18525: tensor([0.3525]), 21328: tensor([0.3525]), 21336: tensor([0.3525])}, {49: tensor([0.2144]), 70: tensor([0.2186]), 1750: tensor([0.2186]), 2102: tensor([0.2183]), 2198: tensor([0.2186]), 4081: tensor([0.2186]), 7855: tensor([0.2186]), 10850: tensor([0.2208]), 15354: tensor([0.2186]), 17550: tensor([0.2128])}, {70: tensor([0.1779, 0.3176]), 4963: tensor([0.1753, 0.3900]), 7236: tensor([0.1786, 0.3177]), 8036: tensor([0.1802, 0.3177]), 9492: tensor([0.1783, 0.3177]), 12943: tensor([0.1779, 0.3199]), 14445: tensor([0.1807, 0.3177]), 16132: tensor([0.1789, 0.3177]), 17335: tensor([0.1782, 0.3177]), 17960: tensor([0.1628, 0.3177]), 18976: tensor([0.1822, 0.3177]), 20078: tensor([0.1838, 0.3177]), 22161: tensor([0.1825, 0.3177])}, {2421: tensor([0.2718]), 3777: tensor([0.2724]), 4858: tensor([0.2724]), 4963: tensor([0.2695]), 6979: tensor([0.2695]), 12943: tensor([0.2695]), 13503: tensor([0.2695]), 14826: tensor([0.2695]), 15177: tensor([0.2679]), 19675: tensor([0.2670])}, {234: tensor([0.0391, 0.4479]), 4714: tensor([0.0391, 0.4494]), 4963: tensor([0.0247, 0.4517]), 7261: tensor([0.0384, 0.4517]), 7267: tensor([0.0322, 0.4517])}, {70: tensor([]), 2107: tensor([]), 4963: tensor([]), 10112: tensor([]), 13187: tensor([]), 17055: tensor([]), 18646: tensor([]), 22743: tensor([]), 24070: tensor([])}, {70: tensor([]), 1750: tensor([]), 4963: tensor([]), 12943: tensor([]), 15573: tensor([]), 17588: tensor([]), 18646: tensor([])}, {70: tensor([0.1734, 0.4454]), 4963: tensor([0.1757, 0.4690]), 11012: tensor([0.1694, 0.4452]), 12943: tensor([0.1783, 0.4455]), 22161: tensor([0.1694, 0.4451])}, {4963: tensor([0.4688]), 6327: tensor([0.4501]), 7267: tensor([0.4501]), 11020: tensor([0.4501]), 11267: tensor([0.4496]), 14496: tensor([0.4494]), 17133: tensor([0.4501]), 17230: tensor([0.4530]), 24070: tensor([0.4503])}, {70: tensor([0.3778]), 742: tensor([0.3768]), 1050: tensor([0.3768]), 4667: tensor([0.3761]), 4963: tensor([0.4036]), 7146: tensor([0.3768]), 7545: tensor([0.3768]), 7818: tensor([0.3768]), 9591: tensor([0.3768]), 10112: tensor([0.3768]), 12943: tensor([0.3811]), 17558: tensor([0.3768]), 17969: tensor([0.3768]), 24070: tensor([0.3768])}, {2102: tensor([0.4405]), 4963: tensor([0.4814]), 11373: tensor([0.4458]), 11568: tensor([0.4421]), 12943: tensor([0.4429]), 13184: tensor([0.4403]), 22308: tensor([0.4136]), 24334: tensor([0.4429])}, {70: tensor([0.3091]), 1187: tensor([0.3091]), 1750: tensor([0.3091]), 3689: tensor([0.3090]), 7267: tensor([0.3145]), 7395: tensor([0.2935]), 8326: tensor([0.3091]), 15573: tensor([0.3184]), 17588: tensor([0.3068]), 18799: tensor([0.3071])}, {55: tensor([0.5858]), 4963: tensor([0.6000]), 5991: tensor([0.5734]), 13334: tensor([0.5858]), 24006: tensor([0.5858])}, {556: tensor([0.3469]), 2107: tensor([0.3440]), 3088: tensor([0.3440]), 4963: tensor([0.3440]), 7395: tensor([0.3420]), 19032: tensor([0.3389]), 21328: tensor([0.3378])}, {234: tensor([0.5097]), 2107: tensor([0.5160]), 4963: tensor([0.5485]), 13602: tensor([0.5186]), 19020: tensor([0.5186]), 24070: tensor([0.5194])}, {1750: tensor([0.4644]), 2107: tensor([0.4641]), 4963: tensor([0.4795]), 15573: tensor([0.4677]), 19675: tensor([0.4644])}, {70: tensor([]), 4963: tensor([]), 12247: tensor([]), 12839: tensor([]), 16325: tensor([]), 16595: tensor([]), 17588: tensor([]), 19556: tensor([]), 22161: tensor([])}, {2198: tensor([0.3629]), 4963: tensor([0.4082]), 6726: tensor([0.3626]), 7267: tensor([0.3663]), 9492: tensor([0.3626]), 10240: tensor([0.3626]), 12943: tensor([0.3693]), 15354: tensor([0.3626]), 15559: tensor([0.3626]), 18914: tensor([0.3655])}, {1947: tensor([0.6956]), 3777: tensor([0.6965]), 4809: tensor([0.6934]), 4963: tensor([0.7092]), 5648: tensor([0.6933]), 8916: tensor([0.6934]), 11434: tensor([0.7021]), 12333: tensor([0.6934]), 13334: tensor([0.6934]), 16968: tensor([0.6934])}, {4963: tensor([0.5994, 0.5434]), 6327: tensor([0.5433, 0.5234]), 7261: tensor([0.5433, 0.5463]), 7395: tensor([0.5433, 0.5402]), 17083: tensor([0.5468, 0.5434]), 17133: tensor([0.5433, 0.5432])}, {70: tensor([0.6403]), 4963: tensor([0.6886]), 9401: tensor([0.6403]), 12943: tensor([0.6403]), 13457: tensor([0.6399]), 24186: tensor([0.6403])}, {70: tensor([0.7140]), 541: tensor([0.7105]), 3283: tensor([0.7074]), 4714: tensor([0.6991]), 4963: tensor([0.7438]), 12943: tensor([0.7218]), 18914: tensor([0.7183]), 21328: tensor([0.7064])}, {1231: tensor([0.2152]), 4963: tensor([0.2328]), 6327: tensor([0.2143]), 6602: tensor([0.2152]), 8221: tensor([0.2103]), 10740: tensor([0.2149]), 15573: tensor([0.2179]), 23941: tensor([0.2152])}, {70: tensor([]), 11465: tensor([]), 14013: tensor([])}, {70: tensor([0.7649, 0.2542]), 1187: tensor([0.7649, 0.2510]), 2107: tensor([0.7649, 0.2552]), 2252: tensor([0.7625, 0.2551]), 4963: tensor([0.7781, 0.2357]), 8172: tensor([0.7533, 0.2551]), 9492: tensor([0.7649, 0.2551]), 15354: tensor([0.7649, 0.2628]), 21124: tensor([0.7649, 0.2518])}, {70: tensor([0.3096]), 2107: tensor([0.3081]), 4963: tensor([0.3315]), 8036: tensor([0.3096]), 9651: tensor([0.3096]), 12943: tensor([0.3186]), 14121: tensor([0.3106]), 15354: tensor([0.3096]), 24045: tensor([0.3129])}, {70: tensor([0.4306]), 4029: tensor([0.4301]), 4516: tensor([0.4309]), 4963: tensor([0.4786]), 5991: tensor([0.4240]), 9932: tensor([0.4051]), 12307: tensor([0.4242]), 22743: tensor([0.4476]), 24070: tensor([0.4304])}, {49: tensor([0.5962]), 2107: tensor([0.5962]), 2198: tensor([0.5962]), 3777: tensor([0.5962]), 4276: tensor([0.5962]), 4963: tensor([0.6453]), 5648: tensor([0.5962]), 8172: tensor([0.5934]), 8865: tensor([0.5962]), 10850: tensor([0.5962]), 12943: tensor([0.6016]), 15354: tensor([0.5902]), 15701: tensor([0.5962]), 21328: tensor([0.5917]), 23413: tensor([0.5962]), 24070: tensor([0.5962])}, {2226: tensor([]), 2435: tensor([]), 4963: tensor([]), 6726: tensor([]), 7265: tensor([]), 8724: tensor([]), 10112: tensor([]), 10534: tensor([]), 19288: tensor([]), 21178: tensor([]), 22337: tensor([])}, {70: tensor([]), 3986: tensor([]), 4564: tensor([]), 6217: tensor([]), 11431: tensor([]), 11568: tensor([]), 12943: tensor([]), 13187: tensor([]), 17335: tensor([])}, {70: tensor([]), 234: tensor([]), 454: tensor([]), 1067: tensor([]), 2102: tensor([]), 2107: tensor([]), 2256: tensor([]), 3777: tensor([]), 5773: tensor([]), 9501: tensor([]), 10216: tensor([]), 11062: tensor([]), 12752: tensor([]), 12943: tensor([]), 13715: tensor([]), 24045: tensor([]), 24551: tensor([])}, {2943: tensor([0.5959]), 4963: tensor([0.5959]), 5374: tensor([0.5604]), 10956: tensor([0.5938]), 21249: tensor([0.5917]), 21988: tensor([0.5887]), 22126: tensor([0.5959])}, {1750: tensor([0.1724]), 4963: tensor([0.1774]), 7395: tensor([0.1774]), 24355: tensor([0.1733])}, {70: tensor([0.4527]), 2505: tensor([0.4544]), 4963: tensor([0.4568]), 10751: tensor([0.4516]), 12732: tensor([0.4516]), 12752: tensor([0.4516]), 12943: tensor([0.4516]), 13212: tensor([0.4516]), 13457: tensor([0.4366]), 18071: tensor([0.4516]), 18115: tensor([0.4516]), 24551: tensor([0.4516])}, {1750: tensor([0.3157]), 3520: tensor([0.3594]), 3777: tensor([0.3157]), 10850: tensor([0.3157])}, {70: tensor([0.5609]), 2107: tensor([0.5609]), 4963: tensor([0.5609]), 8220: tensor([0.5609]), 8454: tensor([0.5609]), 10112: tensor([0.5609]), 19831: tensor([0.5609]), 21328: tensor([0.5596]), 24070: tensor([0.5609])}, {4963: tensor([0.2586]), 6488: tensor([0.2406]), 7842: tensor([0.2290]), 12680: tensor([0.2329]), 13282: tensor([0.2365]), 17588: tensor([0.2345])}, {4963: tensor([0.1445]), 9219: tensor([0.1000]), 11431: tensor([0.0985]), 15573: tensor([0.1008]), 15886: tensor([0.0997]), 22599: tensor([0.0997])}, {4963: tensor([0.1843, 0.5565]), 9309: tensor([0.2068, 0.5286]), 12943: tensor([0.1957, 0.5370]), 21093: tensor([0.2037, 0.5370]), 22683: tensor([0.2100, 0.5370])}, {70: tensor([0.2680]), 742: tensor([0.2680]), 2198: tensor([0.2684]), 2796: tensor([0.2821]), 7146: tensor([0.2608]), 9636: tensor([0.2672]), 10534: tensor([0.2680]), 15177: tensor([0.2680]), 17913: tensor([0.2680]), 18863: tensor([0.2680]), 19675: tensor([0.2680]), 23828: tensor([0.2680]), 23977: tensor([0.2680])}, {70: tensor([0.1793]), 4963: tensor([0.2099])}, {4963: tensor([]), 12943: tensor([]), 24551: tensor([])}, {70: tensor([0.4018, 0.0913]), 1187: tensor([0.4018, 0.0912]), 2107: tensor([0.4018, 0.0901]), 2421: tensor([0.4018, 0.0912]), 2581: tensor([0.4018, 0.0546]), 4963: tensor([0.4018, 0.1003]), 9492: tensor([0.4018, 0.0912]), 12943: tensor([0.4018, 0.1051]), 15354: tensor([0.4018, 0.0882]), 22588: tensor([0.4018, 0.0905])}, {796: tensor([0.0135]), 1503: tensor([0.0223]), 2107: tensor([0.0223]), 2904: tensor([0.0231]), 4963: tensor([0.0223]), 7146: tensor([0.0223]), 7635: tensor([0.0223]), 22455: tensor([0.0223]), 24070: tensor([0.0223]), 24355: tensor([0.0223])}, {70: tensor([]), 1503: tensor([]), 1750: tensor([]), 4963: tensor([]), 12943: tensor([]), 15542: tensor([]), 16075: tensor([]), 17990: tensor([]), 20078: tensor([]), 22944: tensor([]), 24118: tensor([])}, {70: tensor([0.1384]), 2107: tensor([0.1384]), 3986: tensor([0.1384]), 4963: tensor([0.1309]), 8490: tensor([0.1409]), 9225: tensor([0.1384]), 11786: tensor([0.1384]), 12773: tensor([0.1390]), 12943: tensor([0.1384]), 13187: tensor([0.1384]), 13212: tensor([0.1457]), 15423: tensor([0.1385]), 15573: tensor([0.1384]), 24011: tensor([0.1471]), 24551: tensor([0.1463])}, {1776: tensor([]), 4583: tensor([]), 4963: tensor([]), 7265: tensor([]), 10112: tensor([]), 12725: tensor([]), 13184: tensor([]), 18872: tensor([]), 19057: tensor([]), 21285: tensor([]), 22161: tensor([]), 23188: tensor([])}, {70: tensor([]), 2022: tensor([]), 4963: tensor([]), 13457: tensor([]), 21249: tensor([])}, {1750: tensor([0.2325]), 4766: tensor([0.2325]), 4963: tensor([0.2605]), 5682: tensor([0.2320]), 5773: tensor([0.2325]), 11062: tensor([0.2325]), 12333: tensor([0.2325]), 15701: tensor([0.2325]), 19266: tensor([0.2332]), 20078: tensor([0.2328])}, {2107: tensor([]), 2252: tensor([]), 4963: tensor([]), 6726: tensor([]), 8172: tensor([]), 12943: tensor([]), 19227: tensor([])}, {70: tensor([]), 2107: tensor([]), 4963: tensor([]), 9492: tensor([]), 10740: tensor([]), 12943: tensor([]), 13187: tensor([]), 18799: tensor([]), 18914: tensor([])}, {2107: tensor([0.5310]), 5773: tensor([0.5310]), 6600: tensor([0.5297]), 7146: tensor([0.5310]), 14318: tensor([0.5310]), 17624: tensor([0.5310]), 20349: tensor([0.5327]), 23700: tensor([0.5314]), 24551: tensor([0.5310])}, {924: tensor([0.4058]), 1187: tensor([0.4056]), 4963: tensor([0.4058]), 7107: tensor([0.4259]), 13187: tensor([0.3972]), 13212: tensor([0.4058]), 15664: tensor([0.4113]), 24107: tensor([0.4058])}, {70: tensor([0.3451]), 4963: tensor([0.3450]), 21285: tensor([0.3450])}, {70: tensor([0.6691, 0.2313]), 1750: tensor([0.6691, 0.2279]), 2107: tensor([0.6691, 0.2257]), 4103: tensor([0.6706, 0.2279]), 4963: tensor([0.6971, 0.2749]), 12017: tensor([0.6691, 0.2274]), 12943: tensor([0.6691, 0.2474]), 15354: tensor([0.6691, 0.2123]), 19831: tensor([0.6703, 0.2279])}, {70: tensor([0.1114, 0.0955]), 1437: tensor([0.1112, 0.0995]), 2107: tensor([0.1110, 0.0955]), 4963: tensor([0.1112, 0.1274]), 8752: tensor([0.1112, 0.0964]), 13173: tensor([0.1112, 0.0858]), 18914: tensor([0.1112, 0.1167]), 22588: tensor([0.1049, 0.0955]), 22683: tensor([0.1112, 0.0937])}, {70: tensor([0.1248]), 4963: tensor([0.1393]), 11113: tensor([0.1284]), 14293: tensor([0.1213]), 19003: tensor([0.1213]), 19765: tensor([0.1335])}, {1231: tensor([0.5429, 0.2151]), 2581: tensor([0.5416, 0.2128]), 4963: tensor([0.5416, 0.2192]), 7267: tensor([0.5416, 0.2165]), 8916: tensor([0.5490, 0.2151]), 12861: tensor([0.5415, 0.2151]), 12943: tensor([0.5416, 0.2230]), 17230: tensor([0.5409, 0.2151]), 17394: tensor([0.5416, 0.2236]), 21249: tensor([0.5419, 0.2151]), 24070: tensor([0.5398, 0.2151]), 24551: tensor([0.5395, 0.2151])}, {2107: tensor([0.7133, 0.2618]), 4963: tensor([0.7499, 0.2863]), 7261: tensor([0.7143, 0.2618]), 10512: tensor([0.7135, 0.2717]), 12943: tensor([0.7135, 0.2652]), 22126: tensor([0.7155, 0.2618]), 24186: tensor([0.7261, 0.2618])}, {70: tensor([]), 4103: tensor([]), 4963: tensor([]), 6979: tensor([]), 13457: tensor([]), 17230: tensor([])}, {2757: tensor([0.5396]), 3203: tensor([0.4566]), 3826: tensor([0.5354]), 4963: tensor([0.5497]), 7690: tensor([0.5443]), 13212: tensor([0.5354]), 17055: tensor([0.5365]), 19573: tensor([0.5291])}, {2107: tensor([0.4626]), 2198: tensor([0.4625]), 4809: tensor([0.4621]), 4963: tensor([0.4939]), 13184: tensor([0.4491]), 15636: tensor([0.4653]), 15701: tensor([0.4626]), 17550: tensor([0.4626]), 17796: tensor([0.4626]), 20078: tensor([0.4630]), 23129: tensor([0.4626])}, {1750: tensor([]), 2107: tensor([]), 4583: tensor([]), 4963: tensor([]), 5773: tensor([]), 7265: tensor([]), 8036: tensor([]), 8169: tensor([]), 11062: tensor([]), 12752: tensor([]), 14007: tensor([])}, {4963: tensor([0.2389]), 6739: tensor([0.1990]), 11458: tensor([0.1990]), 18635: tensor([0.1990]), 23584: tensor([0.1990]), 24070: tensor([0.1990]), 24551: tensor([0.1983])}, {1750: tensor([0.5037, 0.3123]), 4516: tensor([0.5072, 0.3247]), 4963: tensor([0.5329, 0.3247]), 6979: tensor([0.5042, 0.3247]), 8454: tensor([0.5037, 0.3222]), 9059: tensor([0.5037, 0.3121]), 10259: tensor([0.5037, 0.3272]), 12943: tensor([0.5043, 0.3247]), 13184: tensor([0.5037, 0.3166]), 13701: tensor([0.5037, 0.3248]), 14121: tensor([0.5052, 0.3247]), 19831: tensor([0.5037, 0.3254]), 22743: tensor([0.5184, 0.3247])}, {4963: tensor([0.5951]), 5773: tensor([0.5658]), 7079: tensor([0.5614]), 7265: tensor([0.5658])}, {2107: tensor([0.8056]), 4963: tensor([0.8056]), 12943: tensor([0.8056]), 15573: tensor([0.8056]), 18646: tensor([0.8046]), 20349: tensor([0.8056]), 20418: tensor([0.8056]), 22202: tensor([0.8056])}, {4260: tensor([0.2755]), 4963: tensor([0.2914]), 12943: tensor([0.2747]), 16618: tensor([0.2747]), 19400: tensor([0.2747])}, {70: tensor([0.0380]), 1172: tensor([0.0380]), 4634: tensor([0.1609]), 4963: tensor([0.0380]), 10323: tensor([0.0380]), 13717: tensor([0.0380]), 20078: tensor([0.0390]), 22187: tensor([0.0380]), 24070: tensor([0.0384])}, {714: tensor([]), 4809: tensor([]), 4963: tensor([]), 5567: tensor([]), 12752: tensor([]), 17737: tensor([]), 22770: tensor([]), 23202: tensor([])}, {4963: tensor([0.4437, 0.8650]), 6979: tensor([0.4004, 0.8486]), 7395: tensor([0.4020, 0.8433]), 7655: tensor([0.4020, 0.8487]), 15258: tensor([0.3831, 0.8486]), 22259: tensor([0.4020, 0.8382]), 23129: tensor([0.3551, 0.8486])}, {1750: tensor([]), 3345: tensor([]), 4341: tensor([]), 4858: tensor([]), 4963: tensor([]), 5408: tensor([]), 10112: tensor([]), 13503: tensor([]), 15014: tensor([]), 19675: tensor([])}, {70: tensor([]), 1750: tensor([]), 4963: tensor([]), 7146: tensor([]), 12241: tensor([]), 12943: tensor([]), 14159: tensor([]), 21965: tensor([]), 22455: tensor([]), 22743: tensor([]), 22910: tensor([])}, {70: tensor([0.3322]), 4963: tensor([0.3840]), 7267: tensor([0.3307]), 10902: tensor([0.3996]), 18646: tensor([0.3307]), 22879: tensor([0.3260])}, {4963: tensor([0.5904, 0.2240]), 5773: tensor([0.5338, 0.1965]), 12752: tensor([0.5860, 0.1965]), 13282: tensor([0.5860, 0.1965]), 17558: tensor([0.5860, 0.1973])}, {1750: tensor([]), 4963: tensor([]), 7146: tensor([]), 8169: tensor([]), 12943: tensor([]), 20349: tensor([])}, {1503: tensor([0.2807, 0.4750]), 2421: tensor([0.2921, 0.4763]), 4963: tensor([0.2921, 0.5007]), 7802: tensor([0.2921, 0.4678]), 9925: tensor([0.2921, 0.5088]), 11568: tensor([0.2921, 0.4758]), 17540: tensor([0.2955, 0.4750])}, {234: tensor([0.0259]), 3898: tensor([]), 4963: tensor([0.0144]), 10216: tensor([0.0259])}, {70: tensor([0.8179, 0.3984]), 585: tensor([0.8309, 0.3981]), 2022: tensor([0.8081, 0.3981]), 2102: tensor([0.8168, 0.3933]), 3777: tensor([0.8168, 0.3993]), 4103: tensor([0.8174, 0.3981]), 4963: tensor([0.8249, 0.3981]), 5991: tensor([0.8168, 0.3807]), 12884: tensor([0.8178, 0.3981]), 13457: tensor([0.8098, 0.3981]), 18914: tensor([0.8168, 0.3988]), 19162: tensor([0.8171, 0.3981]), 21285: tensor([0.8167, 0.3981])}, {541: tensor([0.7399]), 2421: tensor([0.7567]), 4963: tensor([0.7904]), 17491: tensor([0.7567]), 17550: tensor([0.7567]), 20078: tensor([0.7517]), 24070: tensor([0.7495])}, {2107: tensor([]), 3826: tensor([]), 4963: tensor([]), 7146: tensor([]), 13212: tensor([]), 16325: tensor([]), 22161: tensor([]), 22588: tensor([]), 22980: tensor([]), 24551: tensor([])}, {70: tensor([0.9038]), 1531: tensor([0.8960]), 1750: tensor([0.9024]), 4963: tensor([0.9503]), 8630: tensor([0.8772]), 12829: tensor([0.8824]), 12943: tensor([0.9187])}, {70: tensor([0.0049]), 2252: tensor([0.0059]), 3324: tensor([0.0060]), 8006: tensor([0.0060]), 8169: tensor([0.0060]), 12876: tensor([0.0060]), 17550: tensor([0.0093]), 20078: tensor([0.0060])}, {1750: tensor([]), 2107: tensor([]), 4963: tensor([]), 12943: tensor([]), 13334: tensor([]), 13819: tensor([]), 15573: tensor([]), 20418: tensor([]), 21271: tensor([]), 22202: tensor([])}, {70: tensor([0.4584, 0.1661]), 2741: tensor([0.4573, 0.1661]), 3826: tensor([0.4575, 0.1578]), 4619: tensor([0.4575, 0.1661]), 4963: tensor([0.4896, 0.1827]), 5998: tensor([0.4572, 0.1661]), 10259: tensor([0.4575, 0.1693]), 17133: tensor([0.4546, 0.1661]), 22683: tensor([0.4416, 0.1661])}, {6217: tensor([]), 6979: tensor([]), 7057: tensor([]), 8752: tensor([]), 10751: tensor([]), 17133: tensor([]), 18115: tensor([]), 21027: tensor([]), 22683: tensor([])}, {660: tensor([0.2088, 0.4128]), 2107: tensor([0.2063, 0.4128]), 2256: tensor([0.2082, 0.4128]), 2575: tensor([0.2136, 0.4128]), 4963: tensor([0.2100, 0.4460]), 6217: tensor([0.2100, 0.4092]), 6979: tensor([0.2100, 0.4125]), 9492: tensor([0.2100, 0.4128]), 11568: tensor([0.2132, 0.4128]), 12943: tensor([0.2100, 0.4184]), 13184: tensor([0.2074, 0.4128]), 13187: tensor([0.2135, 0.4128]), 14445: tensor([0.2095, 0.4128]), 15693: tensor([0.2100, 0.4045]), 17516: tensor([0.2100, 0.4327]), 20084: tensor([0.2099, 0.4128]), 24045: tensor([0.2251, 0.4128])}, {70: tensor([]), 2107: tensor([]), 4276: tensor([]), 4809: tensor([]), 4963: tensor([]), 12943: tensor([]), 13457: tensor([]), 21642: tensor([]), 24551: tensor([])}, {1750: tensor([]), 2492: tensor([]), 3777: tensor([]), 4583: tensor([]), 4963: tensor([]), 7265: tensor([]), 12752: tensor([]), 12943: tensor([])}, {70: tensor([]), 1531: tensor([]), 2561: tensor([]), 3427: tensor([]), 4103: tensor([]), 4963: tensor([]), 8221: tensor([]), 12943: tensor([]), 20078: tensor([]), 21285: tensor([])}, {2107: tensor([0.8357]), 4963: tensor([0.8509]), 6602: tensor([0.8357]), 7267: tensor([0.8357]), 7635: tensor([0.8357]), 8088: tensor([0.8357]), 10740: tensor([0.8269]), 12943: tensor([0.8357]), 19588: tensor([0.8357]), 22308: tensor([0.8118]), 23941: tensor([0.8357])}, {70: tensor([0.7009]), 2757: tensor([0.7009]), 4963: tensor([0.7589]), 12943: tensor([0.7016]), 13187: tensor([0.7009]), 18767: tensor([0.7009])}, {2107: tensor([0.5907]), 3986: tensor([0.5907]), 4963: tensor([0.6002]), 6979: tensor([0.5903]), 9501: tensor([0.5907]), 12943: tensor([0.5907]), 13036: tensor([0.5907]), 13187: tensor([0.5907]), 15575: tensor([0.5907]), 18646: tensor([0.5860]), 24045: tensor([0.5907])}, {70: tensor([]), 4963: tensor([]), 11465: tensor([]), 12943: tensor([]), 18646: tensor([]), 22005: tensor([])}, {70: tensor([0.2848]), 234: tensor([0.2226]), 1750: tensor([0.2848]), 2252: tensor([0.2848]), 2421: tensor([0.2848]), 4963: tensor([0.2848]), 10216: tensor([0.2689]), 12752: tensor([0.2848]), 15354: tensor([0.2848]), 18106: tensor([0.2848]), 18679: tensor([0.2848])}, {2492: tensor([]), 4963: tensor([]), 10259: tensor([]), 10534: tensor([]), 11568: tensor([]), 18646: tensor([])}, {1497: tensor([0.6495]), 4963: tensor([0.6616]), 8830: tensor([0.6409]), 8865: tensor([0.6618]), 13717: tensor([0.6512])}, {4963: tensor([]), 6217: tensor([]), 7267: tensor([]), 13457: tensor([]), 15575: tensor([])}, {1750: tensor([0.5652, 0.2071]), 1947: tensor([0.5811, 0.2071]), 3986: tensor([0.5786, 0.2074]), 4963: tensor([0.5786, 0.2116]), 6311: tensor([0.5817, 0.2071]), 10835: tensor([0.5552, 0.2071]), 11062: tensor([0.5776, 0.2071]), 12943: tensor([0.5786, 0.2106]), 13187: tensor([0.5786, 0.1932]), 19091: tensor([0.5813, 0.2071])}, {4963: tensor([0.5983, 0.5540]), 5408: tensor([0.5407, 0.5277]), 17588: tensor([0.5415, 0.5278]), 23129: tensor([0.5415, 0.5227])}, {1776: tensor([0.1785]), 4594: tensor([0.1788]), 4963: tensor([0.1302]), 7261: tensor([0.1785]), 7267: tensor([0.1685]), 8916: tensor([0.1785]), 12943: tensor([0.1694]), 18914: tensor([0.1785]), 21328: tensor([0.1785]), 22910: tensor([0.1785]), 24045: tensor([0.1785])}, {70: tensor([0.1643]), 2107: tensor([0.1577]), 2421: tensor([0.1643]), 3520: tensor([0.1671]), 4963: tensor([0.1643]), 8236: tensor([0.1643]), 8830: tensor([0.1633]), 9501: tensor([0.0622]), 14445: tensor([0.1643]), 17205: tensor([0.1664]), 17579: tensor([0.1646]), 20078: tensor([0.1643])}, {234: tensor([0.3471]), 4809: tensor([0.3526]), 4963: tensor([0.3526]), 7146: tensor([0.3524]), 17796: tensor([0.3526])}, {70: tensor([0.2246]), 4963: tensor([0.2231]), 5811: tensor([0.2231]), 7690: tensor([0.2231]), 11568: tensor([0.2240]), 13187: tensor([0.2140]), 22161: tensor([0.2229])}, {4963: tensor([0.4112]), 7690: tensor([0.4209]), 16618: tensor([0.4112]), 19260: tensor([0.4111])}, {70: tensor([0.0965]), 2107: tensor([0.0967]), 3470: tensor([0.0967]), 5374: tensor([0.0967]), 7146: tensor([0.0967]), 14318: tensor([0.0967]), 15333: tensor([0.0967]), 15573: tensor([0.0902]), 22455: tensor([0.0967]), 22743: tensor([0.0967])}, {70: tensor([0.8922, 0.2962]), 2421: tensor([0.8937, 0.2962]), 4963: tensor([0.9427, 0.2962]), 12752: tensor([0.8923, 0.2954]), 17411: tensor([0.8923, 0.2983]), 19573: tensor([0.8923, 0.2951]), 20636: tensor([0.8923, 0.2958])}, {70: tensor([0.4267]), 907: tensor([0.4223]), 1328: tensor([0.4464]), 2102: tensor([0.4223]), 2107: tensor([0.4177]), 4963: tensor([0.4625]), 6327: tensor([0.4221]), 7261: tensor([0.4223]), 8881: tensor([0.5018]), 9492: tensor([0.4223]), 13503: tensor([0.4223]), 15573: tensor([0.4222]), 21328: tensor([0.4205])}, {4963: tensor([]), 8454: tensor([]), 11568: tensor([]), 22308: tensor([])}, {1172: tensor([0.5703]), 1202: tensor([0.5703]), 5991: tensor([0.5703]), 7842: tensor([0.5703]), 11062: tensor([0.5698]), 17680: tensor([0.5703])}, {70: tensor([0.4418]), 4963: tensor([0.4551]), 6979: tensor([0.4414]), 7690: tensor([0.4312]), 10106: tensor([0.4188]), 12943: tensor([0.4414]), 14016: tensor([0.4414])}, {70: tensor([0.1970, 0.1427]), 2256: tensor([0.1970, 0.1395]), 2469: tensor([0.1990, 0.1414]), 2616: tensor([0.1970, 0.1319]), 4463: tensor([0.1970, 0.1418]), 4597: tensor([0.1982, 0.1414]), 11458: tensor([0.1950, 0.1414]), 11568: tensor([0.1970, 0.1545]), 12732: tensor([0.1970, 0.1416]), 13602: tensor([0.2042, 0.1414])}, {1391: tensor([]), 4963: tensor([]), 8916: tensor([]), 14232: tensor([]), 14445: tensor([]), 14496: tensor([]), 15354: tensor([]), 16319: tensor([]), 17588: tensor([]), 20078: tensor([]), 24070: tensor([])}, {70: tensor([0.3706]), 4963: tensor([0.4068]), 12943: tensor([0.3706])}, {70: tensor([0.5318, 0.3100]), 3324: tensor([0.5318, 0.3073]), 4692: tensor([0.5318, 0.4296]), 4963: tensor([0.5503, 0.3088]), 13187: tensor([0.5318, 0.3086]), 22924: tensor([0.5318, 0.3156])}, {70: tensor([]), 2107: tensor([]), 4585: tensor([]), 4963: tensor([]), 7057: tensor([]), 12471: tensor([]), 13184: tensor([]), 13503: tensor([]), 22337: tensor([])}, {70: tensor([0.1636, 0.5413]), 442: tensor([0.1612, 0.5455]), 4963: tensor([0.1612, 0.5413]), 10580: tensor([0.1848, 0.5413]), 16325: tensor([0.1612, 0.5129]), 17588: tensor([0.1607, 0.5413]), 23306: tensor([0.1612, 0.5307])}, {2102: tensor([0.0591]), 4963: tensor([0.0591]), 7146: tensor([0.0388]), 9286: tensor([0.0591]), 10112: tensor([0.0591]), 14496: tensor([0.0586]), 17230: tensor([0.0586]), 18619: tensor([0.0585])}, {70: tensor([0.3279]), 3364: tensor([0.3277]), 4963: tensor([0.3672]), 5718: tensor([0.3277]), 12943: tensor([0.3294]), 13207: tensor([0.3277]), 17714: tensor([0.3277])}, {2107: tensor([0.1355, 1.0132]), 2226: tensor([0.1341, 1.0132]), 4963: tensor([0.1356, 1.0391]), 6726: tensor([0.1285, 1.0132]), 12849: tensor([0.1356, 1.0210]), 13457: tensor([0.1356, 1.0132]), 14491: tensor([0.1356, 1.0141]), 15255: tensor([0.1356, 1.0153])}, {3986: tensor([0.3901]), 4103: tensor([0.3900]), 4963: tensor([0.4029]), 6259: tensor([0.3900]), 6871: tensor([0.3900]), 9492: tensor([0.3903]), 11431: tensor([0.3893]), 13187: tensor([0.3876]), 16403: tensor([0.3900]), 24070: tensor([0.3894])}, {2198: tensor([0.6987]), 2421: tensor([0.6987]), 4963: tensor([0.7572]), 9309: tensor([0.6969]), 15177: tensor([0.6987]), 18966: tensor([0.6987]), 23977: tensor([0.6987]), 24186: tensor([0.7011])}, {70: tensor([0.2340]), 1776: tensor([0.2356]), 2421: tensor([0.2340]), 3377: tensor([0.2384]), 4325: tensor([0.2326]), 4766: tensor([0.2345]), 4963: tensor([0.2563]), 5517: tensor([0.2336]), 12943: tensor([0.2327]), 13187: tensor([0.2309]), 18679: tensor([0.2326]), 19003: tensor([0.2326]), 21285: tensor([0.2317]), 22599: tensor([0.2329]), 23921: tensor([0.2355])}, {70: tensor([]), 1750: tensor([]), 4196: tensor([]), 4963: tensor([]), 15573: tensor([])}, {4963: tensor([1.0665]), 5408: tensor([1.0348]), 6327: tensor([1.0348]), 7267: tensor([1.0393]), 21249: tensor([1.0343]), 22683: tensor([1.0347]), 23426: tensor([1.0127]), 24070: tensor([1.0360])}, {1750: tensor([0.7536]), 4963: tensor([0.7723]), 7690: tensor([0.7603]), 8036: tensor([0.7723]), 13457: tensor([0.7723]), 22588: tensor([0.7715])}, {4963: tensor([]), 6600: tensor([]), 11373: tensor([]), 13503: tensor([]), 22308: tensor([]), 24294: tensor([])}, {1750: tensor([0.4195, 0.5981]), 5374: tensor([0.4202, 0.5636]), 7146: tensor([0.4202, 0.5966]), 17588: tensor([0.4202, 0.5972])}, {1437: tensor([0.6136]), 1750: tensor([0.6098]), 4963: tensor([0.6136]), 9501: tensor([0.5380]), 12943: tensor([0.6136]), 13503: tensor([0.6136]), 18767: tensor([0.6136]), 22198: tensor([0.6141])}, {49: tensor([0.7315]), 4963: tensor([0.7702]), 8172: tensor([0.7339]), 8830: tensor([0.7348]), 10956: tensor([0.7339]), 11012: tensor([0.7339]), 12752: tensor([0.7343]), 12943: tensor([0.7375]), 13717: tensor([0.7296]), 17205: tensor([0.7339]), 17550: tensor([0.7339]), 17588: tensor([0.7339]), 20092: tensor([0.7330]), 21328: tensor([0.7339])}, {70: tensor([0.4781]), 2107: tensor([0.4781]), 4963: tensor([0.5052, 0.0237]), 9219: tensor([0.4781, 0.0081]), 11373: tensor([0.4854]), 11431: tensor([0.4781]), 11568: tensor([0.4785]), 13184: tensor([0.4608]), 13212: tensor([0.4740]), 15573: tensor([0.4781]), 21328: tensor([0.4781]), 22308: tensor([0.4343]), 24551: tensor([0.4711])}, {1750: tensor([]), 4963: tensor([]), 13534: tensor([]), 22588: tensor([])}, {2198: tensor([]), 7267: tensor([]), 7395: tensor([]), 12241: tensor([]), 15573: tensor([]), 17588: tensor([]), 18799: tensor([])}, {4963: tensor([0.8004]), 12943: tensor([0.7898])}], answer_logits=[], loss=[{70: tensor(6.3226, device='cuda:0'), 4963: tensor(6.3264, device='cuda:0'), 9492: tensor(6.3232, device='cuda:0'), 17491: tensor(6.3291, device='cuda:0'), 17550: tensor(6.3186, device='cuda:0'), 18914: tensor(6.3252, device='cuda:0'), 21642: tensor(6.3227, device='cuda:0'), 21988: tensor(6.3249, device='cuda:0')}, {1750: tensor(6.7158, device='cuda:0'), 2102: tensor(6.7169, device='cuda:0'), 7482: tensor(6.7163, device='cuda:0'), 7823: tensor(6.7194, device='cuda:0'), 8721: tensor(6.7267, device='cuda:0'), 13212: tensor(6.7159, device='cuda:0'), 13701: tensor(6.7159, device='cuda:0'), 16325: tensor(6.7196, device='cuda:0'), 24551: tensor(6.7151, device='cuda:0')}, {4963: tensor(6.8200, device='cuda:0'), 6600: tensor(6.7906, device='cuda:0'), 7690: tensor(6.8005, device='cuda:0'), 12680: tensor(6.7900, device='cuda:0')}, {70: tensor(6.5677, device='cuda:0'), 1172: tensor(6.5546, device='cuda:0'), 3986: tensor(6.5681, device='cuda:0'), 4963: tensor(6.5755, device='cuda:0'), 7267: tensor(6.5683, device='cuda:0'), 11786: tensor(6.5696, device='cuda:0'), 12817: tensor(6.5780, device='cuda:0'), 13187: tensor(6.5649, device='cuda:0'), 17588: tensor(6.5662, device='cuda:0'), 21328: tensor(6.5668, device='cuda:0')}, {70: tensor(6.5482, device='cuda:0'), 1063: tensor(6.5569, device='cuda:0'), 2107: tensor(6.5488, device='cuda:0'), 4963: tensor(6.5816, device='cuda:0'), 5374: tensor(6.5475, device='cuda:0'), 7146: tensor(6.5458, device='cuda:0'), 12943: tensor(6.5558, device='cuda:0'), 17489: tensor(6.5432, device='cuda:0')}, {2421: tensor(6.6347, device='cuda:0'), 4505: tensor(6.6075, device='cuda:0'), 4858: tensor(6.6379, device='cuda:0'), 7261: tensor(6.6424, device='cuda:0'), 17407: tensor(6.6376, device='cuda:0'), 17704: tensor(6.6396, device='cuda:0'), 18525: tensor(6.6294, device='cuda:0'), 21328: tensor(6.6264, device='cuda:0'), 21336: tensor(6.6359, device='cuda:0')}, {49: tensor(6.3085, device='cuda:0'), 70: tensor(6.3091, device='cuda:0'), 1750: tensor(6.3038, device='cuda:0'), 2102: tensor(6.3084, device='cuda:0'), 2198: tensor(6.3083, device='cuda:0'), 4081: tensor(6.3094, device='cuda:0'), 7855: tensor(6.3071, device='cuda:0'), 10850: tensor(6.3092, device='cuda:0'), 15354: tensor(6.3131, device='cuda:0'), 17550: tensor(6.3085, device='cuda:0')}, {70: tensor(6.5345, device='cuda:0'), 4963: tensor(6.5320, device='cuda:0'), 7236: tensor(6.5339, device='cuda:0'), 8036: tensor(6.5343, device='cuda:0'), 9492: tensor(6.5343, device='cuda:0'), 12943: tensor(6.5345, device='cuda:0'), 14445: tensor(6.5321, device='cuda:0'), 16132: tensor(6.5334, device='cuda:0'), 17335: tensor(6.5335, device='cuda:0'), 17960: tensor(6.5087, device='cuda:0'), 18976: tensor(6.5305, device='cuda:0'), 20078: tensor(6.5314, device='cuda:0'), 22161: tensor(6.5318, device='cuda:0')}, {2421: tensor(6.5900, device='cuda:0'), 3777: tensor(6.5890, device='cuda:0'), 4858: tensor(6.5929, device='cuda:0'), 4963: tensor(6.5962, device='cuda:0'), 6979: tensor(6.5886, device='cuda:0'), 12943: tensor(6.5924, device='cuda:0'), 13503: tensor(6.5850, device='cuda:0'), 14826: tensor(6.5721, device='cuda:0'), 15177: tensor(6.5899, device='cuda:0'), 19675: tensor(6.5722, device='cuda:0')}, {234: tensor(6.2739, device='cuda:0'), 4714: tensor(6.2747, device='cuda:0'), 4963: tensor(6.2835, device='cuda:0'), 7261: tensor(6.2764, device='cuda:0'), 7267: tensor(6.2821, device='cuda:0')}, {70: tensor(6.5794, device='cuda:0'), 2107: tensor(6.5805, device='cuda:0'), 4963: tensor(6.5930, device='cuda:0'), 10112: tensor(6.5863, device='cuda:0'), 13187: tensor(6.5771, device='cuda:0'), 17055: tensor(6.5802, device='cuda:0'), 18646: tensor(6.5798, device='cuda:0'), 22743: tensor(6.5818, device='cuda:0'), 24070: tensor(6.5798, device='cuda:0')}, {70: tensor(7.0837, device='cuda:0'), 1750: tensor(7.0804, device='cuda:0'), 4963: tensor(7.0974, device='cuda:0'), 12943: tensor(7.0867, device='cuda:0'), 15573: tensor(7.0836, device='cuda:0'), 17588: tensor(7.0828, device='cuda:0'), 18646: tensor(7.0826, device='cuda:0')}, {70: tensor(6.2623, device='cuda:0'), 4963: tensor(6.2643, device='cuda:0'), 11012: tensor(6.2586, device='cuda:0'), 12943: tensor(6.2614, device='cuda:0'), 22161: tensor(6.2599, device='cuda:0')}, {4963: tensor(6.9500, device='cuda:0'), 6327: tensor(6.9301, device='cuda:0'), 7267: tensor(6.9309, device='cuda:0'), 11020: tensor(6.9309, device='cuda:0'), 11267: tensor(6.9313, device='cuda:0'), 14496: tensor(6.9307, device='cuda:0'), 17133: tensor(6.9300, device='cuda:0'), 17230: tensor(6.9276, device='cuda:0'), 24070: tensor(6.9304, device='cuda:0')}, {70: tensor(6.2416, device='cuda:0'), 742: tensor(6.2386, device='cuda:0'), 1050: tensor(6.2340, device='cuda:0'), 4667: tensor(6.2413, device='cuda:0'), 4963: tensor(6.2440, device='cuda:0'), 7146: tensor(6.2572, device='cuda:0'), 7545: tensor(6.2406, device='cuda:0'), 7818: tensor(6.2406, device='cuda:0'), 9591: tensor(6.2383, device='cuda:0'), 10112: tensor(6.2434, device='cuda:0'), 12943: tensor(6.2417, device='cuda:0'), 17558: tensor(6.2389, device='cuda:0'), 17969: tensor(6.2169, device='cuda:0'), 24070: tensor(6.2407, device='cuda:0')}, {2102: tensor(6.7378, device='cuda:0'), 4963: tensor(6.7555, device='cuda:0'), 11373: tensor(6.7372, device='cuda:0'), 11568: tensor(6.7363, device='cuda:0'), 12943: tensor(6.7438, device='cuda:0'), 13184: tensor(6.7371, device='cuda:0'), 22308: tensor(6.7528, device='cuda:0'), 24334: tensor(6.7381, device='cuda:0')}, {70: tensor(6.8301, device='cuda:0'), 1187: tensor(6.8282, device='cuda:0'), 1750: tensor(6.8281, device='cuda:0'), 3689: tensor(6.8281, device='cuda:0'), 7267: tensor(6.8319, device='cuda:0'), 7395: tensor(6.8325, device='cuda:0'), 8326: tensor(6.8304, device='cuda:0'), 15573: tensor(6.8242, device='cuda:0'), 17588: tensor(6.8261, device='cuda:0'), 18799: tensor(6.8291, device='cuda:0')}, {55: tensor(6.6457, device='cuda:0'), 4963: tensor(6.6668, device='cuda:0'), 5991: tensor(6.6383, device='cuda:0'), 13334: tensor(6.6343, device='cuda:0'), 24006: tensor(6.6459, device='cuda:0')}, {556: tensor(6.5352, device='cuda:0'), 2107: tensor(6.5337, device='cuda:0'), 3088: tensor(6.5288, device='cuda:0'), 4963: tensor(6.5557, device='cuda:0'), 7395: tensor(6.5343, device='cuda:0'), 19032: tensor(6.5350, device='cuda:0'), 21328: tensor(6.5301, device='cuda:0')}, {234: tensor(6.6143, device='cuda:0'), 2107: tensor(6.6165, device='cuda:0'), 4963: tensor(6.6155, device='cuda:0'), 13602: tensor(6.6062, device='cuda:0'), 19020: tensor(6.6141, device='cuda:0'), 24070: tensor(6.6115, device='cuda:0')}, {1750: tensor(6.1507, device='cuda:0'), 2107: tensor(6.1543, device='cuda:0'), 4963: tensor(6.1556, device='cuda:0'), 15573: tensor(6.1538, device='cuda:0'), 19675: tensor(6.1501, device='cuda:0')}, {70: tensor(6.9789, device='cuda:0'), 4963: tensor(6.9983, device='cuda:0'), 12247: tensor(6.9768, device='cuda:0'), 12839: tensor(6.9770, device='cuda:0'), 16325: tensor(6.9812, device='cuda:0'), 16595: tensor(6.9857, device='cuda:0'), 17588: tensor(6.9765, device='cuda:0'), 19556: tensor(6.9768, device='cuda:0'), 22161: tensor(6.9697, device='cuda:0')}, {2198: tensor(6.4127, device='cuda:0'), 4963: tensor(6.4349, device='cuda:0'), 6726: tensor(6.4124, device='cuda:0'), 7267: tensor(6.4175, device='cuda:0'), 9492: tensor(6.4193, device='cuda:0'), 10240: tensor(6.4094, device='cuda:0'), 12943: tensor(6.4200, device='cuda:0'), 15354: tensor(6.4203, device='cuda:0'), 15559: tensor(6.4374, device='cuda:0'), 18914: tensor(6.4161, device='cuda:0')}, {1947: tensor(6.5488, device='cuda:0'), 3777: tensor(6.5443, device='cuda:0'), 4809: tensor(6.5483, device='cuda:0'), 4963: tensor(6.5507, device='cuda:0'), 5648: tensor(6.5465, device='cuda:0'), 8916: tensor(6.5469, device='cuda:0'), 11434: tensor(6.5475, device='cuda:0'), 12333: tensor(6.5482, device='cuda:0'), 13334: tensor(6.5439, device='cuda:0'), 16968: tensor(6.5454, device='cuda:0')}, {4963: tensor(6.0561, device='cuda:0'), 6327: tensor(6.0523, device='cuda:0'), 7261: tensor(6.0567, device='cuda:0'), 7395: tensor(6.0558, device='cuda:0'), 17083: tensor(6.0537, device='cuda:0'), 17133: tensor(6.0539, device='cuda:0')}, {70: tensor(6.6120, device='cuda:0'), 4963: tensor(6.6151, device='cuda:0'), 9401: tensor(6.6290, device='cuda:0'), 12943: tensor(6.6121, device='cuda:0'), 13457: tensor(6.6124, device='cuda:0'), 24186: tensor(6.6117, device='cuda:0')}, {70: tensor(6.3736, device='cuda:0'), 541: tensor(6.3619, device='cuda:0'), 3283: tensor(6.3741, device='cuda:0'), 4714: tensor(6.3712, device='cuda:0'), 4963: tensor(6.3901, device='cuda:0'), 12943: tensor(6.3726, device='cuda:0'), 18914: tensor(6.3721, device='cuda:0'), 21328: tensor(6.3721, device='cuda:0')}, {1231: tensor(6.4877, device='cuda:0'), 4963: tensor(6.4885, device='cuda:0'), 6327: tensor(6.4889, device='cuda:0'), 6602: tensor(6.4651, device='cuda:0'), 8221: tensor(6.4907, device='cuda:0'), 10740: tensor(6.4890, device='cuda:0'), 15573: tensor(6.4883, device='cuda:0'), 23941: tensor(6.4872, device='cuda:0')}, {70: tensor(6.7121, device='cuda:0'), 11465: tensor(6.7089, device='cuda:0'), 14013: tensor(6.7080, device='cuda:0')}, {70: tensor(6.1199, device='cuda:0'), 1187: tensor(6.1206, device='cuda:0'), 2107: tensor(6.1214, device='cuda:0'), 2252: tensor(6.1194, device='cuda:0'), 4963: tensor(6.1339, device='cuda:0'), 8172: tensor(6.1192, device='cuda:0'), 9492: tensor(6.1215, device='cuda:0'), 15354: tensor(6.1331, device='cuda:0'), 21124: tensor(6.1245, device='cuda:0')}, {70: tensor(6.2367, device='cuda:0'), 2107: tensor(6.2390, device='cuda:0'), 4963: tensor(6.2514, device='cuda:0'), 8036: tensor(6.2366, device='cuda:0'), 9651: tensor(6.2229, device='cuda:0'), 12943: tensor(6.2410, device='cuda:0'), 14121: tensor(6.2363, device='cuda:0'), 15354: tensor(6.2373, device='cuda:0'), 24045: tensor(6.2361, device='cuda:0')}, {70: tensor(6.5647, device='cuda:0'), 4029: tensor(6.5690, device='cuda:0'), 4516: tensor(6.5630, device='cuda:0'), 4963: tensor(6.5711, device='cuda:0'), 5991: tensor(6.5622, device='cuda:0'), 9932: tensor(6.5739, device='cuda:0'), 12307: tensor(6.5632, device='cuda:0'), 22743: tensor(6.5567, device='cuda:0'), 24070: tensor(6.5616, device='cuda:0')}, {49: tensor(6.3498, device='cuda:0'), 2107: tensor(6.3674, device='cuda:0'), 2198: tensor(6.3643, device='cuda:0'), 3777: tensor(6.3617, device='cuda:0'), 4276: tensor(6.3624, device='cuda:0'), 4963: tensor(6.3582, device='cuda:0'), 5648: tensor(6.3646, device='cuda:0'), 8172: tensor(6.3633, device='cuda:0'), 8865: tensor(6.3646, device='cuda:0'), 10850: tensor(6.3641, device='cuda:0'), 12943: tensor(6.3654, device='cuda:0'), 15354: tensor(6.3768, device='cuda:0'), 15701: tensor(6.3675, device='cuda:0'), 21328: tensor(6.3629, device='cuda:0'), 23413: tensor(6.3646, device='cuda:0'), 24070: tensor(6.3467, device='cuda:0')}, {2226: tensor(6.8198, device='cuda:0'), 2435: tensor(6.7773, device='cuda:0'), 4963: tensor(6.8137, device='cuda:0'), 6726: tensor(6.8072, device='cuda:0'), 7265: tensor(6.7583, device='cuda:0'), 8724: tensor(6.8085, device='cuda:0'), 10112: tensor(6.8144, device='cuda:0'), 10534: tensor(6.8074, device='cuda:0'), 19288: tensor(6.8079, device='cuda:0'), 21178: tensor(6.7928, device='cuda:0'), 22337: tensor(6.8149, device='cuda:0')}, {70: tensor(6.9097, device='cuda:0'), 3986: tensor(6.9083, device='cuda:0'), 4564: tensor(6.9076, device='cuda:0'), 6217: tensor(6.9064, device='cuda:0'), 11431: tensor(6.9095, device='cuda:0'), 11568: tensor(6.9042, device='cuda:0'), 12943: tensor(6.9126, device='cuda:0'), 13187: tensor(6.9030, device='cuda:0'), 17335: tensor(6.9063, device='cuda:0')}, {70: tensor(7.0102, device='cuda:0'), 234: tensor(6.9969, device='cuda:0'), 454: tensor(7.0160, device='cuda:0'), 1067: tensor(7.0140, device='cuda:0'), 2102: tensor(7.0093, device='cuda:0'), 2107: tensor(7.0106, device='cuda:0'), 2256: tensor(7.0094, device='cuda:0'), 3777: tensor(7.0100, device='cuda:0'), 5773: tensor(6.9906, device='cuda:0'), 9501: tensor(6.9862, device='cuda:0'), 10216: tensor(7.0012, device='cuda:0'), 11062: tensor(7.0078, device='cuda:0'), 12752: tensor(7.0098, device='cuda:0'), 12943: tensor(7.0101, device='cuda:0'), 13715: tensor(7.0108, device='cuda:0'), 24045: tensor(7.0152, device='cuda:0'), 24551: tensor(7.0079, device='cuda:0')}, {2943: tensor(6.4714, device='cuda:0'), 4963: tensor(6.4872, device='cuda:0'), 5374: tensor(6.4847, device='cuda:0'), 10956: tensor(6.4732, device='cuda:0'), 21249: tensor(6.4598, device='cuda:0'), 21988: tensor(6.4740, device='cuda:0'), 22126: tensor(6.4676, device='cuda:0')}, {1750: tensor(6.6388, device='cuda:0'), 4963: tensor(6.6589, device='cuda:0'), 7395: tensor(6.6412, device='cuda:0'), 24355: tensor(6.6441, device='cuda:0')}, {70: tensor(6.3137, device='cuda:0'), 2505: tensor(6.3142, device='cuda:0'), 4963: tensor(6.3141, device='cuda:0'), 10751: tensor(6.3079, device='cuda:0'), 12732: tensor(6.3135, device='cuda:0'), 12752: tensor(6.3126, device='cuda:0'), 12943: tensor(6.3211, device='cuda:0'), 13212: tensor(6.3105, device='cuda:0'), 13457: tensor(6.3171, device='cuda:0'), 18071: tensor(6.3142, device='cuda:0'), 18115: tensor(6.3129, device='cuda:0'), 24551: tensor(6.3125, device='cuda:0')}, {1750: tensor(6.6058, device='cuda:0'), 3520: tensor(6.5833, device='cuda:0'), 3777: tensor(6.6014, device='cuda:0'), 10850: tensor(6.6109, device='cuda:0')}, {70: tensor(6.5459, device='cuda:0'), 2107: tensor(6.5461, device='cuda:0'), 4963: tensor(6.5476, device='cuda:0'), 8220: tensor(6.5475, device='cuda:0'), 8454: tensor(6.5458, device='cuda:0'), 10112: tensor(6.5470, device='cuda:0'), 19831: tensor(6.5457, device='cuda:0'), 21328: tensor(6.5453, device='cuda:0'), 24070: tensor(6.5447, device='cuda:0')}, {4963: tensor(6.4785, device='cuda:0'), 6488: tensor(6.4717, device='cuda:0'), 7842: tensor(6.4755, device='cuda:0'), 12680: tensor(6.4761, device='cuda:0'), 13282: tensor(6.4757, device='cuda:0'), 17588: tensor(6.4742, device='cuda:0')}, {4963: tensor(6.8545, device='cuda:0'), 9219: tensor(6.8577, device='cuda:0'), 11431: tensor(6.8598, device='cuda:0'), 15573: tensor(6.8574, device='cuda:0'), 15886: tensor(6.8533, device='cuda:0'), 22599: tensor(6.8529, device='cuda:0')}, {4963: tensor(6.0686, device='cuda:0'), 9309: tensor(6.0601, device='cuda:0'), 12943: tensor(6.0630, device='cuda:0'), 21093: tensor(6.0493, device='cuda:0'), 22683: tensor(6.0537, device='cuda:0')}, {70: tensor(6.7484, device='cuda:0'), 742: tensor(6.7470, device='cuda:0'), 2198: tensor(6.7446, device='cuda:0'), 2796: tensor(6.7367, device='cuda:0'), 7146: tensor(6.7505, device='cuda:0'), 9636: tensor(6.7433, device='cuda:0'), 10534: tensor(6.7454, device='cuda:0'), 15177: tensor(6.7461, device='cuda:0'), 17913: tensor(6.7429, device='cuda:0'), 18863: tensor(6.7462, device='cuda:0'), 19675: tensor(6.7108, device='cuda:0'), 23828: tensor(6.7481, device='cuda:0'), 23977: tensor(6.7378, device='cuda:0')}, {70: tensor(6.6332, device='cuda:0'), 4963: tensor(6.6353, device='cuda:0')}, {4963: tensor(6.7767, device='cuda:0'), 12943: tensor(6.7522, device='cuda:0'), 24551: tensor(6.7489, device='cuda:0')}, {70: tensor(6.2301, device='cuda:0'), 1187: tensor(6.2302, device='cuda:0'), 2107: tensor(6.2314, device='cuda:0'), 2421: tensor(6.2302, device='cuda:0'), 2581: tensor(6.2426, device='cuda:0'), 4963: tensor(6.2333, device='cuda:0'), 9492: tensor(6.2304, device='cuda:0'), 12943: tensor(6.2294, device='cuda:0'), 15354: tensor(6.2376, device='cuda:0'), 22588: tensor(6.2307, device='cuda:0')}, {796: tensor(6.4879, device='cuda:0'), 1503: tensor(6.4806, device='cuda:0'), 2107: tensor(6.4835, device='cuda:0'), 2904: tensor(6.4795, device='cuda:0'), 4963: tensor(6.4833, device='cuda:0'), 7146: tensor(6.4858, device='cuda:0'), 7635: tensor(6.4871, device='cuda:0'), 22455: tensor(6.4819, device='cuda:0'), 24070: tensor(6.4831, device='cuda:0'), 24355: tensor(6.4847, device='cuda:0')}, {70: tensor(6.6342, device='cuda:0'), 1503: tensor(6.6318, device='cuda:0'), 1750: tensor(6.6324, device='cuda:0'), 4963: tensor(6.6539, device='cuda:0'), 12943: tensor(6.6332, device='cuda:0'), 15542: tensor(6.6239, device='cuda:0'), 16075: tensor(6.6338, device='cuda:0'), 17990: tensor(6.6328, device='cuda:0'), 20078: tensor(6.6331, device='cuda:0'), 22944: tensor(6.6325, device='cuda:0'), 24118: tensor(6.6324, device='cuda:0')}, {70: tensor(6.4974, device='cuda:0'), 2107: tensor(6.4980, device='cuda:0'), 3986: tensor(6.4981, device='cuda:0'), 4963: tensor(6.5161, device='cuda:0'), 8490: tensor(6.4969, device='cuda:0'), 9225: tensor(6.5114, device='cuda:0'), 11786: tensor(6.5020, device='cuda:0'), 12773: tensor(6.4968, device='cuda:0'), 12943: tensor(6.4999, device='cuda:0'), 13187: tensor(6.4893, device='cuda:0'), 13212: tensor(6.4947, device='cuda:0'), 15423: tensor(6.4974, device='cuda:0'), 15573: tensor(6.4999, device='cuda:0'), 24011: tensor(6.4965, device='cuda:0'), 24551: tensor(6.4941, device='cuda:0')}, {1776: tensor(7.1093, device='cuda:0'), 4583: tensor(7.1018, device='cuda:0'), 4963: tensor(7.1104, device='cuda:0'), 7265: tensor(7.0954, device='cuda:0'), 10112: tensor(7.1039, device='cuda:0'), 12725: tensor(7.1002, device='cuda:0'), 13184: tensor(7.0997, device='cuda:0'), 18872: tensor(7.1017, device='cuda:0'), 19057: tensor(7.0969, device='cuda:0'), 21285: tensor(7.1014, device='cuda:0'), 22161: tensor(7.0985, device='cuda:0'), 23188: tensor(7.1015, device='cuda:0')}, {70: tensor(6.6739, device='cuda:0'), 2022: tensor(6.6703, device='cuda:0'), 4963: tensor(6.6871, device='cuda:0'), 13457: tensor(6.6732, device='cuda:0'), 21249: tensor(6.6680, device='cuda:0')}, {1750: tensor(6.7063, device='cuda:0'), 4766: tensor(6.7295, device='cuda:0'), 4963: tensor(6.7297, device='cuda:0'), 5682: tensor(6.7292, device='cuda:0'), 5773: tensor(6.7125, device='cuda:0'), 11062: tensor(6.7270, device='cuda:0'), 12333: tensor(6.7303, device='cuda:0'), 15701: tensor(6.7320, device='cuda:0'), 19266: tensor(6.7292, device='cuda:0'), 20078: tensor(6.7299, device='cuda:0')}, {2107: tensor(7.0711, device='cuda:0'), 2252: tensor(7.0682, device='cuda:0'), 4963: tensor(7.0758, device='cuda:0'), 6726: tensor(7.0684, device='cuda:0'), 8172: tensor(7.0679, device='cuda:0'), 12943: tensor(7.0724, device='cuda:0'), 19227: tensor(7.0717, device='cuda:0')}, {70: tensor(6.6577, device='cuda:0'), 2107: tensor(6.6593, device='cuda:0'), 4963: tensor(6.7175, device='cuda:0'), 9492: tensor(6.6654, device='cuda:0'), 10740: tensor(6.6586, device='cuda:0'), 12943: tensor(6.6711, device='cuda:0'), 13187: tensor(6.6586, device='cuda:0'), 18799: tensor(6.6692, device='cuda:0'), 18914: tensor(6.6648, device='cuda:0')}, {2107: tensor(6.6176, device='cuda:0'), 5773: tensor(6.6128, device='cuda:0'), 6600: tensor(6.6170, device='cuda:0'), 7146: tensor(6.6230, device='cuda:0'), 14318: tensor(6.6174, device='cuda:0'), 17624: tensor(6.6174, device='cuda:0'), 20349: tensor(6.6147, device='cuda:0'), 23700: tensor(6.6172, device='cuda:0'), 24551: tensor(6.6138, device='cuda:0')}, {924: tensor(8.1407, device='cuda:0'), 1187: tensor(8.1409, device='cuda:0'), 4963: tensor(8.1624, device='cuda:0'), 7107: tensor(8.1472, device='cuda:0'), 13187: tensor(8.1423, device='cuda:0'), 13212: tensor(8.1375, device='cuda:0'), 15664: tensor(8.1368, device='cuda:0'), 24107: tensor(8.1401, device='cuda:0')}, {70: tensor(6.3029, device='cuda:0'), 4963: tensor(6.3203, device='cuda:0'), 21285: tensor(6.3026, device='cuda:0')}, {70: tensor(6.3101, device='cuda:0'), 1750: tensor(6.3100, device='cuda:0'), 2107: tensor(6.3123, device='cuda:0'), 4103: tensor(6.3086, device='cuda:0'), 4963: tensor(6.3138, device='cuda:0'), 12017: tensor(6.3060, device='cuda:0'), 12943: tensor(6.3165, device='cuda:0'), 15354: tensor(6.3559, device='cuda:0'), 19831: tensor(6.3096, device='cuda:0')}, {70: tensor(6.1151, device='cuda:0'), 1437: tensor(6.1116, device='cuda:0'), 2107: tensor(6.1150, device='cuda:0'), 4963: tensor(6.1142, device='cuda:0'), 8752: tensor(6.1149, device='cuda:0'), 13173: tensor(6.1170, device='cuda:0'), 18914: tensor(6.1150, device='cuda:0'), 22588: tensor(6.1185, device='cuda:0'), 22683: tensor(6.1158, device='cuda:0')}, {70: tensor(6.6610, device='cuda:0'), 4963: tensor(6.6801, device='cuda:0'), 11113: tensor(6.6440, device='cuda:0'), 14293: tensor(6.6599, device='cuda:0'), 19003: tensor(6.6632, device='cuda:0'), 19765: tensor(6.6513, device='cuda:0')}, {1231: tensor(6.6331, device='cuda:0'), 2581: tensor(6.6346, device='cuda:0'), 4963: tensor(6.6350, device='cuda:0'), 7267: tensor(6.6355, device='cuda:0'), 8916: tensor(6.6363, device='cuda:0'), 12861: tensor(6.6337, device='cuda:0'), 12943: tensor(6.6352, device='cuda:0'), 17230: tensor(6.6339, device='cuda:0'), 17394: tensor(6.6322, device='cuda:0'), 21249: tensor(6.6333, device='cuda:0'), 24070: tensor(6.6339, device='cuda:0'), 24551: tensor(6.6339, device='cuda:0')}, {2107: tensor(6.3232, device='cuda:0'), 4963: tensor(6.3240, device='cuda:0'), 7261: tensor(6.3240, device='cuda:0'), 10512: tensor(6.3285, device='cuda:0'), 12943: tensor(6.3234, device='cuda:0'), 22126: tensor(6.3167, device='cuda:0'), 24186: tensor(6.3151, device='cuda:0')}, {70: tensor(7.0050, device='cuda:0'), 4103: tensor(6.9994, device='cuda:0'), 4963: tensor(7.0540, device='cuda:0'), 6979: tensor(6.9848, device='cuda:0'), 13457: tensor(7.0023, device='cuda:0'), 17230: tensor(7.0036, device='cuda:0')}, {2757: tensor(6.3748, device='cuda:0'), 3203: tensor(6.3919, device='cuda:0'), 3826: tensor(6.3721, device='cuda:0'), 4963: tensor(6.3758, device='cuda:0'), 7690: tensor(6.3769, device='cuda:0'), 13212: tensor(6.3721, device='cuda:0'), 17055: tensor(6.3752, device='cuda:0'), 19573: tensor(6.3823, device='cuda:0')}, {2107: tensor(6.6029, device='cuda:0'), 2198: tensor(6.6004, device='cuda:0'), 4809: tensor(6.6044, device='cuda:0'), 4963: tensor(6.6069, device='cuda:0'), 13184: tensor(6.6036, device='cuda:0'), 15636: tensor(6.5937, device='cuda:0'), 15701: tensor(6.6022, device='cuda:0'), 17550: tensor(6.6010, device='cuda:0'), 17796: tensor(6.6025, device='cuda:0'), 20078: tensor(6.6023, device='cuda:0'), 23129: tensor(6.5902, device='cuda:0')}, {1750: tensor(6.9964, device='cuda:0'), 2107: tensor(7.0103, device='cuda:0'), 4583: tensor(7.0234, device='cuda:0'), 4963: tensor(7.0139, device='cuda:0'), 5773: tensor(6.9745, device='cuda:0'), 7265: tensor(7.0086, device='cuda:0'), 8036: tensor(7.0100, device='cuda:0'), 8169: tensor(7.0094, device='cuda:0'), 11062: tensor(7.0035, device='cuda:0'), 12752: tensor(7.0099, device='cuda:0'), 14007: tensor(7.0040, device='cuda:0')}, {4963: tensor(6.5267, device='cuda:0'), 6739: tensor(6.5312, device='cuda:0'), 11458: tensor(6.5363, device='cuda:0'), 18635: tensor(6.5263, device='cuda:0'), 23584: tensor(6.5264, device='cuda:0'), 24070: tensor(6.5246, device='cuda:0'), 24551: tensor(6.5273, device='cuda:0')}, {1750: tensor(6.4558, device='cuda:0'), 4516: tensor(6.4602, device='cuda:0'), 4963: tensor(6.4663, device='cuda:0'), 6979: tensor(6.4594, device='cuda:0'), 8454: tensor(6.4630, device='cuda:0'), 9059: tensor(6.4598, device='cuda:0'), 10259: tensor(6.4648, device='cuda:0'), 12943: tensor(6.4625, device='cuda:0'), 13184: tensor(6.4624, device='cuda:0'), 13701: tensor(6.4623, device='cuda:0'), 14121: tensor(6.4625, device='cuda:0'), 19831: tensor(6.4626, device='cuda:0'), 22743: tensor(6.4567, device='cuda:0')}, {4963: tensor(6.2620, device='cuda:0'), 5773: tensor(6.2580, device='cuda:0'), 7079: tensor(6.2270, device='cuda:0'), 7265: tensor(6.2524, device='cuda:0')}, {2107: tensor(6.3635, device='cuda:0'), 4963: tensor(6.3811, device='cuda:0'), 12943: tensor(6.3709, device='cuda:0'), 15573: tensor(6.3658, device='cuda:0'), 18646: tensor(6.3621, device='cuda:0'), 20349: tensor(6.3622, device='cuda:0'), 20418: tensor(6.3599, device='cuda:0'), 22202: tensor(6.3894, device='cuda:0')}, {4260: tensor(6.8113, device='cuda:0'), 4963: tensor(6.8270, device='cuda:0'), 12943: tensor(6.8146, device='cuda:0'), 16618: tensor(6.8100, device='cuda:0'), 19400: tensor(6.8132, device='cuda:0')}, {70: tensor(6.7112, device='cuda:0'), 1172: tensor(6.7082, device='cuda:0'), 4634: tensor(6.6339, device='cuda:0'), 4963: tensor(6.7220, device='cuda:0'), 10323: tensor(6.7095, device='cuda:0'), 13717: tensor(6.7081, device='cuda:0'), 20078: tensor(6.7078, device='cuda:0'), 22187: tensor(6.7072, device='cuda:0'), 24070: tensor(6.7082, device='cuda:0')}, {714: tensor(6.8094, device='cuda:0'), 4809: tensor(6.8154, device='cuda:0'), 4963: tensor(6.8321, device='cuda:0'), 5567: tensor(6.8139, device='cuda:0'), 12752: tensor(6.8077, device='cuda:0'), 17737: tensor(6.8073, device='cuda:0'), 22770: tensor(6.8067, device='cuda:0'), 23202: tensor(6.8103, device='cuda:0')}, {4963: tensor(6.3005, device='cuda:0'), 6979: tensor(6.2893, device='cuda:0'), 7395: tensor(6.3002, device='cuda:0'), 7655: tensor(6.2986, device='cuda:0'), 15258: tensor(6.2991, device='cuda:0'), 22259: tensor(6.2966, device='cuda:0'), 23129: tensor(6.2872, device='cuda:0')}, {1750: tensor(7.5046, device='cuda:0'), 3345: tensor(7.5025, device='cuda:0'), 4341: tensor(7.5079, device='cuda:0'), 4858: tensor(7.5072, device='cuda:0'), 4963: tensor(7.5200, device='cuda:0'), 5408: tensor(7.5065, device='cuda:0'), 10112: tensor(7.5087, device='cuda:0'), 13503: tensor(7.5063, device='cuda:0'), 15014: tensor(7.4634, device='cuda:0'), 19675: tensor(7.4839, device='cuda:0')}, {70: tensor(7.2466, device='cuda:0'), 1750: tensor(7.2388, device='cuda:0'), 4963: tensor(7.2479, device='cuda:0'), 7146: tensor(7.2461, device='cuda:0'), 12241: tensor(7.1805, device='cuda:0'), 12943: tensor(7.2510, device='cuda:0'), 14159: tensor(7.2670, device='cuda:0'), 21965: tensor(7.2319, device='cuda:0'), 22455: tensor(7.2381, device='cuda:0'), 22743: tensor(7.2465, device='cuda:0'), 22910: tensor(7.2348, device='cuda:0')}, {70: tensor(6.6438, device='cuda:0'), 4963: tensor(6.6528, device='cuda:0'), 7267: tensor(6.6470, device='cuda:0'), 10902: tensor(6.6431, device='cuda:0'), 18646: tensor(6.6441, device='cuda:0'), 22879: tensor(6.6423, device='cuda:0')}, {4963: tensor(6.4580, device='cuda:0'), 5773: tensor(6.4632, device='cuda:0'), 12752: tensor(6.4543, device='cuda:0'), 13282: tensor(6.4544, device='cuda:0'), 17558: tensor(6.4534, device='cuda:0')}, {1750: tensor(7.0097, device='cuda:0'), 4963: tensor(7.0217, device='cuda:0'), 7146: tensor(7.0118, device='cuda:0'), 8169: tensor(7.0056, device='cuda:0'), 12943: tensor(7.0145, device='cuda:0'), 20349: tensor(7.0088, device='cuda:0')}, {1503: tensor(6.4358, device='cuda:0'), 2421: tensor(6.4388, device='cuda:0'), 4963: tensor(6.4444, device='cuda:0'), 7802: tensor(6.4251, device='cuda:0'), 9925: tensor(6.4336, device='cuda:0'), 11568: tensor(6.4392, device='cuda:0'), 17540: tensor(6.4348, device='cuda:0')}, {234: tensor(6.3841, device='cuda:0'), 3898: tensor(6.4299, device='cuda:0'), 4963: tensor(6.4060, device='cuda:0'), 10216: tensor(6.3933, device='cuda:0')}, {70: tensor(6.2395, device='cuda:0'), 585: tensor(6.2349, device='cuda:0'), 2022: tensor(6.2382, device='cuda:0'), 2102: tensor(6.2420, device='cuda:0'), 3777: tensor(6.2364, device='cuda:0'), 4103: tensor(6.2379, device='cuda:0'), 4963: tensor(6.2401, device='cuda:0'), 5991: tensor(6.2283, device='cuda:0'), 12884: tensor(6.2369, device='cuda:0'), 13457: tensor(6.2374, device='cuda:0'), 18914: tensor(6.2389, device='cuda:0'), 19162: tensor(6.2375, device='cuda:0'), 21285: tensor(6.2383, device='cuda:0')}, {541: tensor(6.3600, device='cuda:0'), 2421: tensor(6.3605, device='cuda:0'), 4963: tensor(6.3661, device='cuda:0'), 17491: tensor(6.3631, device='cuda:0'), 17550: tensor(6.3591, device='cuda:0'), 20078: tensor(6.3628, device='cuda:0'), 24070: tensor(6.3601, device='cuda:0')}, {2107: tensor(6.9226, device='cuda:0'), 3826: tensor(6.9212, device='cuda:0'), 4963: tensor(6.9431, device='cuda:0'), 7146: tensor(6.9231, device='cuda:0'), 13212: tensor(6.9122, device='cuda:0'), 16325: tensor(6.9216, device='cuda:0'), 22161: tensor(6.9201, device='cuda:0'), 22588: tensor(6.9211, device='cuda:0'), 22980: tensor(6.9246, device='cuda:0'), 24551: tensor(6.9206, device='cuda:0')}, {70: tensor(6.3131, device='cuda:0'), 1531: tensor(6.3141, device='cuda:0'), 1750: tensor(6.3122, device='cuda:0'), 4963: tensor(6.3224, device='cuda:0'), 8630: tensor(6.3164, device='cuda:0'), 12829: tensor(6.3145, device='cuda:0'), 12943: tensor(6.3149, device='cuda:0')}, {70: tensor(6.5214, device='cuda:0'), 2252: tensor(6.5201, device='cuda:0'), 3324: tensor(6.5235, device='cuda:0'), 8006: tensor(6.5267, device='cuda:0'), 8169: tensor(6.5111, device='cuda:0'), 12876: tensor(6.5194, device='cuda:0'), 17550: tensor(6.5192, device='cuda:0'), 20078: tensor(6.5220, device='cuda:0')}, {1750: tensor(6.7369, device='cuda:0'), 2107: tensor(6.7478, device='cuda:0'), 4963: tensor(6.7753, device='cuda:0'), 12943: tensor(6.7536, device='cuda:0'), 13334: tensor(6.7448, device='cuda:0'), 13819: tensor(6.7463, device='cuda:0'), 15573: tensor(6.7504, device='cuda:0'), 20418: tensor(6.7444, device='cuda:0'), 21271: tensor(6.7465, device='cuda:0'), 22202: tensor(6.7723, device='cuda:0')}, {70: tensor(6.3535, device='cuda:0'), 2741: tensor(6.3535, device='cuda:0'), 3826: tensor(6.3561, device='cuda:0'), 4619: tensor(6.3528, device='cuda:0'), 4963: tensor(6.3560, device='cuda:0'), 5998: tensor(6.3525, device='cuda:0'), 10259: tensor(6.3542, device='cuda:0'), 17133: tensor(6.3512, device='cuda:0'), 22683: tensor(6.3496, device='cuda:0')}, {6217: tensor(6.4921, device='cuda:0'), 6979: tensor(6.4825, device='cuda:0'), 7057: tensor(6.4917, device='cuda:0'), 8752: tensor(6.4930, device='cuda:0'), 10751: tensor(6.4749, device='cuda:0'), 17133: tensor(6.4925, device='cuda:0'), 18115: tensor(6.4913, device='cuda:0'), 21027: tensor(6.4868, device='cuda:0'), 22683: tensor(6.4892, device='cuda:0')}, {660: tensor(6.2550, device='cuda:0'), 2107: tensor(6.2586, device='cuda:0'), 2256: tensor(6.2557, device='cuda:0'), 2575: tensor(6.2525, device='cuda:0'), 4963: tensor(6.2604, device='cuda:0'), 6217: tensor(6.2537, device='cuda:0'), 6979: tensor(6.2509, device='cuda:0'), 9492: tensor(6.2554, device='cuda:0'), 11568: tensor(6.2525, device='cuda:0'), 12943: tensor(6.2559, device='cuda:0'), 13184: tensor(6.2542, device='cuda:0'), 13187: tensor(6.2476, device='cuda:0'), 14445: tensor(6.2487, device='cuda:0'), 15693: tensor(6.2553, device='cuda:0'), 17516: tensor(6.2557, device='cuda:0'), 20084: tensor(6.2548, device='cuda:0'), 24045: tensor(6.2575, device='cuda:0')}, {70: tensor(6.8778, device='cuda:0'), 2107: tensor(6.8773, device='cuda:0'), 4276: tensor(6.8746, device='cuda:0'), 4809: tensor(6.8822, device='cuda:0'), 4963: tensor(6.9008, device='cuda:0'), 12943: tensor(6.8805, device='cuda:0'), 13457: tensor(6.8772, device='cuda:0'), 21642: tensor(6.8776, device='cuda:0'), 24551: tensor(6.8757, device='cuda:0')}, {1750: tensor(7.0310, device='cuda:0'), 2492: tensor(7.0313, device='cuda:0'), 3777: tensor(7.0291, device='cuda:0'), 4583: tensor(7.0358, device='cuda:0'), 4963: tensor(7.0466, device='cuda:0'), 7265: tensor(7.0314, device='cuda:0'), 12752: tensor(7.0316, device='cuda:0'), 12943: tensor(7.0320, device='cuda:0')}, {70: tensor(6.4851, device='cuda:0'), 1531: tensor(6.4831, device='cuda:0'), 2561: tensor(6.4859, device='cuda:0'), 3427: tensor(6.4895, device='cuda:0'), 4103: tensor(6.4837, device='cuda:0'), 4963: tensor(6.5014, device='cuda:0'), 8221: tensor(6.4847, device='cuda:0'), 12943: tensor(6.4913, device='cuda:0'), 20078: tensor(6.4854, device='cuda:0'), 21285: tensor(6.4833, device='cuda:0')}, {2107: tensor(6.7669, device='cuda:0'), 4963: tensor(6.7898, device='cuda:0'), 6602: tensor(6.7465, device='cuda:0'), 7267: tensor(6.7798, device='cuda:0'), 7635: tensor(6.7668, device='cuda:0'), 8088: tensor(6.7690, device='cuda:0'), 10740: tensor(6.7697, device='cuda:0'), 12943: tensor(6.7695, device='cuda:0'), 19588: tensor(6.7635, device='cuda:0'), 22308: tensor(6.7813, device='cuda:0'), 23941: tensor(6.7637, device='cuda:0')}, {70: tensor(6.2752, device='cuda:0'), 2757: tensor(6.2736, device='cuda:0'), 4963: tensor(6.2730, device='cuda:0'), 12943: tensor(6.2740, device='cuda:0'), 13187: tensor(6.2718, device='cuda:0'), 18767: tensor(6.2739, device='cuda:0')}, {2107: tensor(6.6663, device='cuda:0'), 3986: tensor(6.6649, device='cuda:0'), 4963: tensor(6.6844, device='cuda:0'), 6979: tensor(6.6602, device='cuda:0'), 9501: tensor(6.6433, device='cuda:0'), 12943: tensor(6.6681, device='cuda:0'), 13036: tensor(6.6645, device='cuda:0'), 13187: tensor(6.6636, device='cuda:0'), 15575: tensor(6.6680, device='cuda:0'), 18646: tensor(6.6650, device='cuda:0'), 24045: tensor(6.6646, device='cuda:0')}, {70: tensor(6.4567, device='cuda:0'), 4963: tensor(6.4694, device='cuda:0'), 11465: tensor(6.4484, device='cuda:0'), 12943: tensor(6.4586, device='cuda:0'), 18646: tensor(6.4567, device='cuda:0'), 22005: tensor(6.4574, device='cuda:0')}, {70: tensor(6.2072, device='cuda:0'), 234: tensor(6.2171, device='cuda:0'), 1750: tensor(6.2046, device='cuda:0'), 2252: tensor(6.2046, device='cuda:0'), 2421: tensor(6.2068, device='cuda:0'), 4963: tensor(6.2070, device='cuda:0'), 10216: tensor(6.2085, device='cuda:0'), 12752: tensor(6.2065, device='cuda:0'), 15354: tensor(6.2483, device='cuda:0'), 18106: tensor(6.2013, device='cuda:0'), 18679: tensor(6.1990, device='cuda:0')}, {2492: tensor(6.6665, device='cuda:0'), 4963: tensor(6.7171, device='cuda:0'), 10259: tensor(6.6707, device='cuda:0'), 10534: tensor(6.6603, device='cuda:0'), 11568: tensor(6.6669, device='cuda:0'), 18646: tensor(6.6678, device='cuda:0')}, {1497: tensor(7.0400, device='cuda:0'), 4963: tensor(7.0686, device='cuda:0'), 8830: tensor(7.0477, device='cuda:0'), 8865: tensor(7.0473, device='cuda:0'), 13717: tensor(7.0430, device='cuda:0')}, {4963: tensor(6.2813, device='cuda:0'), 6217: tensor(6.2686, device='cuda:0'), 7267: tensor(6.2713, device='cuda:0'), 13457: tensor(6.2709, device='cuda:0'), 15575: tensor(6.2656, device='cuda:0')}, {1750: tensor(8.1062, device='cuda:0'), 1947: tensor(8.1287, device='cuda:0'), 3986: tensor(8.1330, device='cuda:0'), 4963: tensor(8.1308, device='cuda:0'), 6311: tensor(8.1394, device='cuda:0'), 10835: tensor(8.1390, device='cuda:0'), 11062: tensor(8.1270, device='cuda:0'), 12943: tensor(8.1306, device='cuda:0'), 13187: tensor(8.1301, device='cuda:0'), 19091: tensor(8.1273, device='cuda:0')}, {4963: tensor(6.2999, device='cuda:0'), 5408: tensor(6.3062, device='cuda:0'), 17588: tensor(6.3030, device='cuda:0'), 23129: tensor(6.3025, device='cuda:0')}, {1776: tensor(6.9077, device='cuda:0'), 4594: tensor(6.9046, device='cuda:0'), 4963: tensor(6.9342, device='cuda:0'), 7261: tensor(6.9073, device='cuda:0'), 7267: tensor(6.9151, device='cuda:0'), 8916: tensor(6.9117, device='cuda:0'), 12943: tensor(6.9168, device='cuda:0'), 18914: tensor(6.9072, device='cuda:0'), 21328: tensor(6.9038, device='cuda:0'), 22910: tensor(6.9040, device='cuda:0'), 24045: tensor(6.9074, device='cuda:0')}, {70: tensor(7.2003, device='cuda:0'), 2107: tensor(7.2095, device='cuda:0'), 2421: tensor(7.1998, device='cuda:0'), 3520: tensor(7.1952, device='cuda:0'), 4963: tensor(7.2243, device='cuda:0'), 8236: tensor(7.1981, device='cuda:0'), 8830: tensor(7.2010, device='cuda:0'), 9501: tensor(7.0908, device='cuda:0'), 14445: tensor(7.1984, device='cuda:0'), 17205: tensor(7.2020, device='cuda:0'), 17579: tensor(7.1998, device='cuda:0'), 20078: tensor(7.1997, device='cuda:0')}, {234: tensor(6.4414, device='cuda:0'), 4809: tensor(6.4358, device='cuda:0'), 4963: tensor(6.4516, device='cuda:0'), 7146: tensor(6.4440, device='cuda:0'), 17796: tensor(6.4420, device='cuda:0')}, {70: tensor(6.4739, device='cuda:0'), 4963: tensor(6.4897, device='cuda:0'), 5811: tensor(6.4743, device='cuda:0'), 7690: tensor(6.4736, device='cuda:0'), 11568: tensor(6.4674, device='cuda:0'), 13187: tensor(6.4746, device='cuda:0'), 22161: tensor(6.4727, device='cuda:0')}, {4963: tensor(6.7103, device='cuda:0'), 7690: tensor(6.6977, device='cuda:0'), 16618: tensor(6.6943, device='cuda:0'), 19260: tensor(6.6977, device='cuda:0')}, {70: tensor(6.3460, device='cuda:0'), 2107: tensor(6.3473, device='cuda:0'), 3470: tensor(6.3488, device='cuda:0'), 5374: tensor(6.3455, device='cuda:0'), 7146: tensor(6.3275, device='cuda:0'), 14318: tensor(6.3448, device='cuda:0'), 15333: tensor(6.3284, device='cuda:0'), 15573: tensor(6.3483, device='cuda:0'), 22455: tensor(6.3367, device='cuda:0'), 22743: tensor(6.3463, device='cuda:0')}, {70: tensor(6.3035, device='cuda:0'), 2421: tensor(6.3026, device='cuda:0'), 4963: tensor(6.3069, device='cuda:0'), 12752: tensor(6.3040, device='cuda:0'), 17411: tensor(6.2989, device='cuda:0'), 19573: tensor(6.3048, device='cuda:0'), 20636: tensor(6.3036, device='cuda:0')}, {70: tensor(6.5069, device='cuda:0'), 907: tensor(6.5047, device='cuda:0'), 1328: tensor(6.5013, device='cuda:0'), 2102: tensor(6.5051, device='cuda:0'), 2107: tensor(6.5082, device='cuda:0'), 4963: tensor(6.5057, device='cuda:0'), 6327: tensor(6.5050, device='cuda:0'), 7261: tensor(6.5063, device='cuda:0'), 8881: tensor(6.5327, device='cuda:0'), 9492: tensor(6.5055, device='cuda:0'), 13503: tensor(6.5040, device='cuda:0'), 15573: tensor(6.5050, device='cuda:0'), 21328: tensor(6.5044, device='cuda:0')}, {4963: tensor(6.7119, device='cuda:0'), 8454: tensor(6.7008, device='cuda:0'), 11568: tensor(6.6955, device='cuda:0'), 22308: tensor(6.7013, device='cuda:0')}, {1172: tensor(6.2698, device='cuda:0'), 1202: tensor(6.2509, device='cuda:0'), 5991: tensor(6.2492, device='cuda:0'), 7842: tensor(6.2733, device='cuda:0'), 11062: tensor(6.2734, device='cuda:0'), 17680: tensor(6.2653, device='cuda:0')}, {70: tensor(6.2179, device='cuda:0'), 4963: tensor(6.2202, device='cuda:0'), 6979: tensor(6.2157, device='cuda:0'), 7690: tensor(6.2240, device='cuda:0'), 10106: tensor(6.2185, device='cuda:0'), 12943: tensor(6.2178, device='cuda:0'), 14016: tensor(6.1477, device='cuda:0')}, {70: tensor(6.4793, device='cuda:0'), 2256: tensor(6.4803, device='cuda:0'), 2469: tensor(6.4737, device='cuda:0'), 2616: tensor(6.4779, device='cuda:0'), 4463: tensor(6.4792, device='cuda:0'), 4597: tensor(6.4797, device='cuda:0'), 11458: tensor(6.4847, device='cuda:0'), 11568: tensor(6.4662, device='cuda:0'), 12732: tensor(6.4792, device='cuda:0'), 13602: tensor(6.4699, device='cuda:0')}, {1391: tensor(6.6740, device='cuda:0'), 4963: tensor(6.6937, device='cuda:0'), 8916: tensor(6.6805, device='cuda:0'), 14232: tensor(6.6747, device='cuda:0'), 14445: tensor(6.6683, device='cuda:0'), 14496: tensor(6.6715, device='cuda:0'), 15354: tensor(6.6799, device='cuda:0'), 16319: tensor(6.6774, device='cuda:0'), 17588: tensor(6.6735, device='cuda:0'), 20078: tensor(6.6723, device='cuda:0'), 24070: tensor(6.6716, device='cuda:0')}, {70: tensor(6.5657, device='cuda:0'), 4963: tensor(6.5998, device='cuda:0'), 12943: tensor(6.5743, device='cuda:0')}, {70: tensor(6.5793, device='cuda:0'), 3324: tensor(6.5823, device='cuda:0'), 4692: tensor(6.5589, device='cuda:0'), 4963: tensor(6.5824, device='cuda:0'), 13187: tensor(6.5812, device='cuda:0'), 22924: tensor(6.5820, device='cuda:0')}, {70: tensor(6.6836, device='cuda:0'), 2107: tensor(6.6849, device='cuda:0'), 4585: tensor(6.6985, device='cuda:0'), 4963: tensor(6.7024, device='cuda:0'), 7057: tensor(6.6837, device='cuda:0'), 12471: tensor(6.6847, device='cuda:0'), 13184: tensor(6.6817, device='cuda:0'), 13503: tensor(6.6809, device='cuda:0'), 22337: tensor(6.6855, device='cuda:0')}, {70: tensor(6.3041, device='cuda:0'), 442: tensor(6.3012, device='cuda:0'), 4963: tensor(6.3029, device='cuda:0'), 10580: tensor(6.2925, device='cuda:0'), 16325: tensor(6.3144, device='cuda:0'), 17588: tensor(6.3021, device='cuda:0'), 23306: tensor(6.2992, device='cuda:0')}, {2102: tensor(7.0399, device='cuda:0'), 4963: tensor(7.0438, device='cuda:0'), 7146: tensor(7.0482, device='cuda:0'), 9286: tensor(7.0381, device='cuda:0'), 10112: tensor(7.0386, device='cuda:0'), 14496: tensor(7.0352, device='cuda:0'), 17230: tensor(7.0379, device='cuda:0'), 18619: tensor(7.0381, device='cuda:0')}, {70: tensor(6.2902, device='cuda:0'), 3364: tensor(6.3020, device='cuda:0'), 4963: tensor(6.2991, device='cuda:0'), 5718: tensor(6.2918, device='cuda:0'), 12943: tensor(6.2902, device='cuda:0'), 13207: tensor(6.2985, device='cuda:0'), 17714: tensor(6.2779, device='cuda:0')}, {2107: tensor(6.5900, device='cuda:0'), 2226: tensor(6.6054, device='cuda:0'), 4963: tensor(6.5934, device='cuda:0'), 6726: tensor(6.5879, device='cuda:0'), 12849: tensor(6.5920, device='cuda:0'), 13457: tensor(6.5899, device='cuda:0'), 14491: tensor(6.5895, device='cuda:0'), 15255: tensor(6.5881, device='cuda:0')}, {3986: tensor(6.7874, device='cuda:0'), 4103: tensor(6.7829, device='cuda:0'), 4963: tensor(6.7942, device='cuda:0'), 6259: tensor(6.7507, device='cuda:0'), 6871: tensor(6.7863, device='cuda:0'), 9492: tensor(6.7863, device='cuda:0'), 11431: tensor(6.7867, device='cuda:0'), 13187: tensor(6.7864, device='cuda:0'), 16403: tensor(6.7802, device='cuda:0'), 24070: tensor(6.7857, device='cuda:0')}, {2198: tensor(6.8016, device='cuda:0'), 2421: tensor(6.8037, device='cuda:0'), 4963: tensor(6.8033, device='cuda:0'), 9309: tensor(6.8046, device='cuda:0'), 15177: tensor(6.7963, device='cuda:0'), 18966: tensor(6.8069, device='cuda:0'), 23977: tensor(6.8035, device='cuda:0'), 24186: tensor(6.8017, device='cuda:0')}, {70: tensor(6.4573, device='cuda:0'), 1776: tensor(6.4605, device='cuda:0'), 2421: tensor(6.4562, device='cuda:0'), 3377: tensor(6.4562, device='cuda:0'), 4325: tensor(6.4576, device='cuda:0'), 4766: tensor(6.4619, device='cuda:0'), 4963: tensor(6.4666, device='cuda:0'), 5517: tensor(6.4584, device='cuda:0'), 12943: tensor(6.4572, device='cuda:0'), 13187: tensor(6.4576, device='cuda:0'), 18679: tensor(6.4442, device='cuda:0'), 19003: tensor(6.4578, device='cuda:0'), 21285: tensor(6.4575, device='cuda:0'), 22599: tensor(6.4573, device='cuda:0'), 23921: tensor(6.4578, device='cuda:0')}, {70: tensor(6.6130, device='cuda:0'), 1750: tensor(6.6059, device='cuda:0'), 4196: tensor(6.6142, device='cuda:0'), 4963: tensor(6.6187, device='cuda:0'), 15573: tensor(6.6105, device='cuda:0')}, {4963: tensor(6.2302, device='cuda:0'), 5408: tensor(6.2148, device='cuda:0'), 6327: tensor(6.2144, device='cuda:0'), 7267: tensor(6.2199, device='cuda:0'), 21249: tensor(6.2142, device='cuda:0'), 22683: tensor(6.2156, device='cuda:0'), 23426: tensor(6.2072, device='cuda:0'), 24070: tensor(6.2128, device='cuda:0')}, {1750: tensor(6.4534, device='cuda:0'), 4963: tensor(6.4757, device='cuda:0'), 7690: tensor(6.4600, device='cuda:0'), 8036: tensor(6.4530, device='cuda:0'), 13457: tensor(6.4546, device='cuda:0'), 22588: tensor(6.4563, device='cuda:0')}, {4963: tensor(7.1794, device='cuda:0'), 6600: tensor(7.1530, device='cuda:0'), 11373: tensor(7.1679, device='cuda:0'), 13503: tensor(7.1558, device='cuda:0'), 22308: tensor(7.1415, device='cuda:0'), 24294: tensor(7.1528, device='cuda:0')}, {1750: tensor(6.2803, device='cuda:0'), 5374: tensor(6.2908, device='cuda:0'), 7146: tensor(6.2811, device='cuda:0'), 17588: tensor(6.2795, device='cuda:0')}, {1437: tensor(6.8055, device='cuda:0'), 1750: tensor(6.8040, device='cuda:0'), 4963: tensor(6.8439, device='cuda:0'), 9501: tensor(6.7680, device='cuda:0'), 12943: tensor(6.8099, device='cuda:0'), 13503: tensor(6.8041, device='cuda:0'), 18767: tensor(6.8030, device='cuda:0'), 22198: tensor(6.8070, device='cuda:0')}, {49: tensor(6.6267, device='cuda:0'), 4963: tensor(6.6433, device='cuda:0'), 8172: tensor(6.6207, device='cuda:0'), 8830: tensor(6.6291, device='cuda:0'), 10956: tensor(6.6280, device='cuda:0'), 11012: tensor(6.6238, device='cuda:0'), 12752: tensor(6.6274, device='cuda:0'), 12943: tensor(6.6285, device='cuda:0'), 13717: tensor(6.6259, device='cuda:0'), 17205: tensor(6.6359, device='cuda:0'), 17550: tensor(6.6272, device='cuda:0'), 17588: tensor(6.6272, device='cuda:0'), 20092: tensor(6.6281, device='cuda:0'), 21328: tensor(6.6263, device='cuda:0')}, {70: tensor(6.5265, device='cuda:0'), 2107: tensor(6.5281, device='cuda:0'), 4963: tensor(6.5305, device='cuda:0'), 9219: tensor(6.5369, device='cuda:0'), 11373: tensor(6.5274, device='cuda:0'), 11431: tensor(6.5337, device='cuda:0'), 11568: tensor(6.5261, device='cuda:0'), 13184: tensor(6.5235, device='cuda:0'), 13212: tensor(6.5267, device='cuda:0'), 15573: tensor(6.5268, device='cuda:0'), 21328: tensor(6.5259, device='cuda:0'), 22308: tensor(6.5461, device='cuda:0'), 24551: tensor(6.5258, device='cuda:0')}, {1750: tensor(6.1497, device='cuda:0'), 4963: tensor(6.1667, device='cuda:0'), 13534: tensor(6.1910, device='cuda:0'), 22588: tensor(6.1541, device='cuda:0')}, {2198: tensor(6.7291, device='cuda:0'), 7267: tensor(6.7439, device='cuda:0'), 7395: tensor(6.7368, device='cuda:0'), 12241: tensor(6.7383, device='cuda:0'), 15573: tensor(6.7398, device='cuda:0'), 17588: tensor(6.7385, device='cuda:0'), 18799: tensor(6.7372, device='cuda:0')}, {4963: tensor(6.0826, device='cuda:0'), 12943: tensor(6.0797, device='cuda:0')}], labels=[tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([2949, 2949]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([2949, 2949]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([2949, 5297]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 2949]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([2949, 5297]), tensor([5297, 5297]), tensor([2949, 5297]), tensor([5297, 2949]), tensor([5297, 5297]), tensor([2949, 2949]), tensor([5297, 2949]), tensor([5297, 2949]), tensor([2949, 2949]), tensor([5297, 5297]), tensor([5297, 5297]), tensor([2949])], orig_labels=[tensor([1, 0]), tensor([1, 1]), tensor([0, 0]), tensor([0, 0]), tensor([0, 0]), tensor([0, 1]), tensor([1, 0]), tensor([0, 1]), tensor([1, 0]), tensor([0, 1]), tensor([0, 0]), tensor([0, 0]), tensor([1, 1]), tensor([1, 0]), tensor([1, 1]), tensor([1, 0]), tensor([1, 1]), tensor([0, 1]), tensor([1, 0]), tensor([1, 1]), tensor([0, 1]), tensor([0, 0]), tensor([0, 1]), tensor([0, 1]), tensor([1, 1]), tensor([1, 0]), tensor([1, 0]), tensor([0, 1]), tensor([0, 1]), tensor([1, 0]), tensor([0, 1]), tensor([1, 0]), tensor([1, 1]), tensor([0, 0]), tensor([0, 0]), tensor([0, 0]), tensor([1, 0]), tensor([0, 1]), tensor([0, 1]), tensor([1, 0]), tensor([1, 0]), tensor([1, 1]), tensor([1, 0]), tensor([0, 1]), tensor([0, 1]), tensor([0, 1]), tensor([0, 0]), tensor([1, 1]), tensor([1, 0]), tensor([0, 0]), tensor([0, 0]), tensor([0, 0]), tensor([0, 0]), tensor([0, 1]), tensor([0, 0]), tensor([0, 0]), tensor([0, 1]), tensor([1, 0]), tensor([0, 1]), tensor([1, 1]), tensor([1, 1]), tensor([1, 0]), tensor([1, 1]), tensor([1, 1]), tensor([0, 0]), tensor([1, 0]), tensor([0, 1]), tensor([0, 0]), tensor([1, 0]), tensor([1, 1]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([0, 1]), tensor([0, 0]), tensor([1, 1]), tensor([0, 0]), tensor([0, 0]), tensor([1, 0]), tensor([1, 1]), tensor([0, 0]), tensor([1, 1]), tensor([0, 0]), tensor([1, 1]), tensor([1, 1]), tensor([0, 0]), tensor([1, 0]), tensor([0, 0]), tensor([0, 0]), tensor([1, 1]), tensor([0, 0]), tensor([1, 1]), tensor([0, 0]), tensor([0, 0]), tensor([0, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 1]), tensor([0, 0]), tensor([0, 1]), tensor([0, 1]), tensor([1, 1]), tensor([1, 1]), tensor([0, 0]), tensor([0, 1]), tensor([0, 1]), tensor([0, 1]), tensor([1, 0]), tensor([0, 0]), tensor([1, 1]), tensor([0, 1]), tensor([0, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 1]), tensor([0, 0]), tensor([1, 0]), tensor([1, 1]), tensor([0, 0]), tensor([1, 1]), tensor([1, 1]), tensor([1, 0]), tensor([1, 1]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([0, 0]), tensor([1, 0]), tensor([0, 1]), tensor([0, 0]), tensor([1, 1]), tensor([0, 1]), tensor([0, 1]), tensor([1, 1]), tensor([0, 0]), tensor([0, 0]), tensor([1])], preds=[{70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 17491: tensor([1, 1], device='cuda:0'), 17550: tensor([1, 1], device='cuda:0'), 18914: tensor([1, 1], device='cuda:0'), 21642: tensor([1, 1], device='cuda:0'), 21988: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 2102: tensor([1, 1], device='cuda:0'), 7482: tensor([1, 1], device='cuda:0'), 7823: tensor([1, 1], device='cuda:0'), 8721: tensor([1, 1], device='cuda:0'), 13212: tensor([1, 1], device='cuda:0'), 13701: tensor([1, 1], device='cuda:0'), 16325: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 6600: tensor([1, 1], device='cuda:0'), 7690: tensor([1, 1], device='cuda:0'), 12680: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1172: tensor([1, 1], device='cuda:0'), 3986: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 11786: tensor([1, 1], device='cuda:0'), 12817: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 1063: tensor([0, 1], device='cuda:0'), 2107: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 5374: tensor([0, 1], device='cuda:0'), 7146: tensor([0, 1], device='cuda:0'), 12943: tensor([0, 1], device='cuda:0'), 17489: tensor([0, 1], device='cuda:0')}, {2421: tensor([1, 1], device='cuda:0'), 4505: tensor([1, 1], device='cuda:0'), 4858: tensor([1, 1], device='cuda:0'), 7261: tensor([1, 1], device='cuda:0'), 17407: tensor([1, 1], device='cuda:0'), 17704: tensor([1, 1], device='cuda:0'), 18525: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0'), 21336: tensor([1, 1], device='cuda:0')}, {49: tensor([1, 1], device='cuda:0'), 70: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 2102: tensor([1, 1], device='cuda:0'), 2198: tensor([1, 1], device='cuda:0'), 4081: tensor([1, 1], device='cuda:0'), 7855: tensor([1, 1], device='cuda:0'), 10850: tensor([1, 1], device='cuda:0'), 15354: tensor([1, 1], device='cuda:0'), 17550: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 7236: tensor([0, 1], device='cuda:0'), 8036: tensor([0, 1], device='cuda:0'), 9492: tensor([0, 1], device='cuda:0'), 12943: tensor([0, 1], device='cuda:0'), 14445: tensor([0, 1], device='cuda:0'), 16132: tensor([0, 1], device='cuda:0'), 17335: tensor([0, 1], device='cuda:0'), 17960: tensor([0, 1], device='cuda:0'), 18976: tensor([0, 1], device='cuda:0'), 20078: tensor([0, 1], device='cuda:0'), 22161: tensor([0, 1], device='cuda:0')}, {2421: tensor([1, 1], device='cuda:0'), 3777: tensor([1, 1], device='cuda:0'), 4858: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13503: tensor([1, 1], device='cuda:0'), 14826: tensor([1, 1], device='cuda:0'), 15177: tensor([1, 1], device='cuda:0'), 19675: tensor([1, 1], device='cuda:0')}, {234: tensor([0, 1], device='cuda:0'), 4714: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 7261: tensor([0, 1], device='cuda:0'), 7267: tensor([0, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 10112: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 17055: tensor([1, 1], device='cuda:0'), 18646: tensor([1, 1], device='cuda:0'), 22743: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 18646: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 11012: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 22161: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 6327: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 11020: tensor([1, 1], device='cuda:0'), 11267: tensor([1, 1], device='cuda:0'), 14496: tensor([1, 1], device='cuda:0'), 17133: tensor([1, 1], device='cuda:0'), 17230: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 742: tensor([0, 1], device='cuda:0'), 1050: tensor([0, 1], device='cuda:0'), 4667: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 7146: tensor([0, 1], device='cuda:0'), 7545: tensor([0, 1], device='cuda:0'), 7818: tensor([0, 1], device='cuda:0'), 9591: tensor([0, 1], device='cuda:0'), 10112: tensor([0, 1], device='cuda:0'), 12943: tensor([0, 1], device='cuda:0'), 17558: tensor([0, 1], device='cuda:0'), 17969: tensor([0, 1], device='cuda:0'), 24070: tensor([0, 1], device='cuda:0')}, {2102: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 11373: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13184: tensor([1, 1], device='cuda:0'), 22308: tensor([1, 1], device='cuda:0'), 24334: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 1187: tensor([0, 1], device='cuda:0'), 1750: tensor([0, 1], device='cuda:0'), 3689: tensor([0, 1], device='cuda:0'), 7267: tensor([0, 1], device='cuda:0'), 7395: tensor([0, 1], device='cuda:0'), 8326: tensor([0, 1], device='cuda:0'), 15573: tensor([0, 1], device='cuda:0'), 17588: tensor([0, 1], device='cuda:0'), 18799: tensor([0, 1], device='cuda:0')}, {55: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5991: tensor([1, 1], device='cuda:0'), 13334: tensor([1, 1], device='cuda:0'), 24006: tensor([1, 1], device='cuda:0')}, {556: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 3088: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7395: tensor([1, 1], device='cuda:0'), 19032: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0')}, {234: tensor([0, 1], device='cuda:0'), 2107: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 13602: tensor([0, 1], device='cuda:0'), 19020: tensor([0, 1], device='cuda:0'), 24070: tensor([0, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 19675: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12247: tensor([1, 1], device='cuda:0'), 12839: tensor([1, 1], device='cuda:0'), 16325: tensor([1, 1], device='cuda:0'), 16595: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 19556: tensor([1, 1], device='cuda:0'), 22161: tensor([1, 1], device='cuda:0')}, {2198: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6726: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 10240: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 15354: tensor([1, 1], device='cuda:0'), 15559: tensor([1, 1], device='cuda:0'), 18914: tensor([1, 1], device='cuda:0')}, {1947: tensor([1, 1], device='cuda:0'), 3777: tensor([1, 1], device='cuda:0'), 4809: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5648: tensor([1, 1], device='cuda:0'), 8916: tensor([1, 1], device='cuda:0'), 11434: tensor([1, 1], device='cuda:0'), 12333: tensor([1, 1], device='cuda:0'), 13334: tensor([1, 1], device='cuda:0'), 16968: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 6327: tensor([1, 1], device='cuda:0'), 7261: tensor([1, 1], device='cuda:0'), 7395: tensor([1, 1], device='cuda:0'), 17083: tensor([1, 1], device='cuda:0'), 17133: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9401: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 24186: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 541: tensor([1, 1], device='cuda:0'), 3283: tensor([1, 1], device='cuda:0'), 4714: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 18914: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0')}, {1231: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6327: tensor([1, 1], device='cuda:0'), 6602: tensor([1, 1], device='cuda:0'), 8221: tensor([1, 1], device='cuda:0'), 10740: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 23941: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 0], device='cuda:0'), 11465: tensor([1, 0], device='cuda:0'), 14013: tensor([1, 0], device='cuda:0')}, {70: tensor([1, 0], device='cuda:0'), 1187: tensor([1, 0], device='cuda:0'), 2107: tensor([1, 0], device='cuda:0'), 2252: tensor([1, 0], device='cuda:0'), 4963: tensor([1, 0], device='cuda:0'), 8172: tensor([1, 0], device='cuda:0'), 9492: tensor([1, 0], device='cuda:0'), 15354: tensor([1, 0], device='cuda:0'), 21124: tensor([1, 0], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8036: tensor([1, 1], device='cuda:0'), 9651: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 14121: tensor([1, 1], device='cuda:0'), 15354: tensor([1, 1], device='cuda:0'), 24045: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4029: tensor([1, 1], device='cuda:0'), 4516: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5991: tensor([1, 1], device='cuda:0'), 9932: tensor([1, 1], device='cuda:0'), 12307: tensor([1, 1], device='cuda:0'), 22743: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {49: tensor([1, 0], device='cuda:0'), 2107: tensor([1, 0], device='cuda:0'), 2198: tensor([1, 0], device='cuda:0'), 3777: tensor([1, 0], device='cuda:0'), 4276: tensor([1, 0], device='cuda:0'), 4963: tensor([1, 0], device='cuda:0'), 5648: tensor([1, 0], device='cuda:0'), 8172: tensor([1, 0], device='cuda:0'), 8865: tensor([1, 0], device='cuda:0'), 10850: tensor([1, 0], device='cuda:0'), 12943: tensor([1, 0], device='cuda:0'), 15354: tensor([1, 0], device='cuda:0'), 15701: tensor([1, 0], device='cuda:0'), 21328: tensor([1, 0], device='cuda:0'), 23413: tensor([1, 0], device='cuda:0'), 24070: tensor([1, 0], device='cuda:0')}, {2226: tensor([1, 1], device='cuda:0'), 2435: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6726: tensor([1, 1], device='cuda:0'), 7265: tensor([1, 1], device='cuda:0'), 8724: tensor([1, 1], device='cuda:0'), 10112: tensor([1, 1], device='cuda:0'), 10534: tensor([1, 1], device='cuda:0'), 19288: tensor([1, 1], device='cuda:0'), 21178: tensor([1, 1], device='cuda:0'), 22337: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 3986: tensor([1, 1], device='cuda:0'), 4564: tensor([1, 1], device='cuda:0'), 6217: tensor([1, 1], device='cuda:0'), 11431: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 17335: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 234: tensor([1, 1], device='cuda:0'), 454: tensor([1, 1], device='cuda:0'), 1067: tensor([1, 1], device='cuda:0'), 2102: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 2256: tensor([1, 1], device='cuda:0'), 3777: tensor([1, 1], device='cuda:0'), 5773: tensor([1, 1], device='cuda:0'), 9501: tensor([1, 1], device='cuda:0'), 10216: tensor([1, 1], device='cuda:0'), 11062: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13715: tensor([1, 1], device='cuda:0'), 24045: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {2943: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5374: tensor([1, 1], device='cuda:0'), 10956: tensor([1, 1], device='cuda:0'), 21249: tensor([1, 1], device='cuda:0'), 21988: tensor([1, 1], device='cuda:0'), 22126: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7395: tensor([1, 1], device='cuda:0'), 24355: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2505: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 10751: tensor([1, 1], device='cuda:0'), 12732: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13212: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 18071: tensor([1, 1], device='cuda:0'), 18115: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 3520: tensor([1, 1], device='cuda:0'), 3777: tensor([1, 1], device='cuda:0'), 10850: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8220: tensor([1, 1], device='cuda:0'), 8454: tensor([1, 1], device='cuda:0'), 10112: tensor([1, 1], device='cuda:0'), 19831: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {4963: tensor([0, 1], device='cuda:0'), 6488: tensor([0, 1], device='cuda:0'), 7842: tensor([0, 1], device='cuda:0'), 12680: tensor([0, 1], device='cuda:0'), 13282: tensor([0, 1], device='cuda:0'), 17588: tensor([0, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 9219: tensor([1, 1], device='cuda:0'), 11431: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 15886: tensor([1, 1], device='cuda:0'), 22599: tensor([1, 1], device='cuda:0')}, {4963: tensor([0, 1], device='cuda:0'), 9309: tensor([0, 1], device='cuda:0'), 12943: tensor([0, 1], device='cuda:0'), 21093: tensor([0, 1], device='cuda:0'), 22683: tensor([0, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 742: tensor([1, 1], device='cuda:0'), 2198: tensor([1, 1], device='cuda:0'), 2796: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 9636: tensor([1, 1], device='cuda:0'), 10534: tensor([1, 1], device='cuda:0'), 15177: tensor([1, 1], device='cuda:0'), 17913: tensor([1, 1], device='cuda:0'), 18863: tensor([1, 1], device='cuda:0'), 19675: tensor([1, 1], device='cuda:0'), 23828: tensor([1, 1], device='cuda:0'), 23977: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1187: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 2421: tensor([1, 1], device='cuda:0'), 2581: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 15354: tensor([1, 1], device='cuda:0'), 22588: tensor([1, 1], device='cuda:0')}, {796: tensor([1, 1], device='cuda:0'), 1503: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 2904: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 7635: tensor([1, 1], device='cuda:0'), 22455: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0'), 24355: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1503: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 15542: tensor([1, 1], device='cuda:0'), 16075: tensor([1, 1], device='cuda:0'), 17990: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0'), 22944: tensor([1, 1], device='cuda:0'), 24118: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 0], device='cuda:0'), 2107: tensor([1, 0], device='cuda:0'), 3986: tensor([1, 0], device='cuda:0'), 4963: tensor([1, 0], device='cuda:0'), 8490: tensor([1, 0], device='cuda:0'), 9225: tensor([1, 0], device='cuda:0'), 11786: tensor([1, 0], device='cuda:0'), 12773: tensor([1, 0], device='cuda:0'), 12943: tensor([1, 0], device='cuda:0'), 13187: tensor([1, 0], device='cuda:0'), 13212: tensor([1, 0], device='cuda:0'), 15423: tensor([1, 0], device='cuda:0'), 15573: tensor([1, 0], device='cuda:0'), 24011: tensor([1, 0], device='cuda:0'), 24551: tensor([1, 0], device='cuda:0')}, {1776: tensor([1, 1], device='cuda:0'), 4583: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7265: tensor([1, 1], device='cuda:0'), 10112: tensor([1, 1], device='cuda:0'), 12725: tensor([1, 1], device='cuda:0'), 13184: tensor([1, 1], device='cuda:0'), 18872: tensor([1, 1], device='cuda:0'), 19057: tensor([1, 1], device='cuda:0'), 21285: tensor([1, 1], device='cuda:0'), 22161: tensor([1, 1], device='cuda:0'), 23188: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2022: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 21249: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 4766: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5682: tensor([1, 1], device='cuda:0'), 5773: tensor([1, 1], device='cuda:0'), 11062: tensor([1, 1], device='cuda:0'), 12333: tensor([1, 1], device='cuda:0'), 15701: tensor([1, 1], device='cuda:0'), 19266: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 2252: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6726: tensor([1, 1], device='cuda:0'), 8172: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 19227: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 10740: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 18799: tensor([1, 1], device='cuda:0'), 18914: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 5773: tensor([1, 1], device='cuda:0'), 6600: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 14318: tensor([1, 1], device='cuda:0'), 17624: tensor([1, 1], device='cuda:0'), 20349: tensor([1, 1], device='cuda:0'), 23700: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {924: tensor([1, 1], device='cuda:0'), 1187: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7107: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 13212: tensor([1, 1], device='cuda:0'), 15664: tensor([1, 1], device='cuda:0'), 24107: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 21285: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4103: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12017: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 15354: tensor([1, 1], device='cuda:0'), 19831: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1437: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8752: tensor([1, 1], device='cuda:0'), 13173: tensor([1, 1], device='cuda:0'), 18914: tensor([1, 1], device='cuda:0'), 22588: tensor([1, 1], device='cuda:0'), 22683: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 11113: tensor([1, 1], device='cuda:0'), 14293: tensor([1, 1], device='cuda:0'), 19003: tensor([1, 1], device='cuda:0'), 19765: tensor([1, 1], device='cuda:0')}, {1231: tensor([1, 1], device='cuda:0'), 2581: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 8916: tensor([1, 1], device='cuda:0'), 12861: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 17230: tensor([1, 1], device='cuda:0'), 17394: tensor([1, 1], device='cuda:0'), 21249: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7261: tensor([1, 1], device='cuda:0'), 10512: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 22126: tensor([1, 1], device='cuda:0'), 24186: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4103: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 17230: tensor([1, 1], device='cuda:0')}, {2757: tensor([1, 1], device='cuda:0'), 3203: tensor([1, 1], device='cuda:0'), 3826: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7690: tensor([1, 1], device='cuda:0'), 13212: tensor([1, 1], device='cuda:0'), 17055: tensor([1, 1], device='cuda:0'), 19573: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 2198: tensor([1, 1], device='cuda:0'), 4809: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 13184: tensor([1, 1], device='cuda:0'), 15636: tensor([1, 1], device='cuda:0'), 15701: tensor([1, 1], device='cuda:0'), 17550: tensor([1, 1], device='cuda:0'), 17796: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0'), 23129: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4583: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5773: tensor([1, 1], device='cuda:0'), 7265: tensor([1, 1], device='cuda:0'), 8036: tensor([1, 1], device='cuda:0'), 8169: tensor([1, 1], device='cuda:0'), 11062: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 14007: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 6739: tensor([1, 1], device='cuda:0'), 11458: tensor([1, 1], device='cuda:0'), 18635: tensor([1, 1], device='cuda:0'), 23584: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 4516: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 8454: tensor([1, 1], device='cuda:0'), 9059: tensor([1, 1], device='cuda:0'), 10259: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13184: tensor([1, 1], device='cuda:0'), 13701: tensor([1, 1], device='cuda:0'), 14121: tensor([1, 1], device='cuda:0'), 19831: tensor([1, 1], device='cuda:0'), 22743: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 5773: tensor([1, 1], device='cuda:0'), 7079: tensor([1, 1], device='cuda:0'), 7265: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 18646: tensor([1, 1], device='cuda:0'), 20349: tensor([1, 1], device='cuda:0'), 20418: tensor([1, 1], device='cuda:0'), 22202: tensor([1, 1], device='cuda:0')}, {4260: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 16618: tensor([1, 1], device='cuda:0'), 19400: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1172: tensor([1, 1], device='cuda:0'), 4634: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 10323: tensor([1, 1], device='cuda:0'), 13717: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0'), 22187: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {714: tensor([1, 1], device='cuda:0'), 4809: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5567: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 17737: tensor([1, 1], device='cuda:0'), 22770: tensor([1, 1], device='cuda:0'), 23202: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 7395: tensor([1, 1], device='cuda:0'), 7655: tensor([1, 1], device='cuda:0'), 15258: tensor([1, 1], device='cuda:0'), 22259: tensor([1, 1], device='cuda:0'), 23129: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 3345: tensor([1, 1], device='cuda:0'), 4341: tensor([1, 1], device='cuda:0'), 4858: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5408: tensor([1, 1], device='cuda:0'), 10112: tensor([1, 1], device='cuda:0'), 13503: tensor([1, 1], device='cuda:0'), 15014: tensor([1, 1], device='cuda:0'), 19675: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 12241: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 14159: tensor([1, 1], device='cuda:0'), 21965: tensor([1, 1], device='cuda:0'), 22455: tensor([1, 1], device='cuda:0'), 22743: tensor([1, 1], device='cuda:0'), 22910: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 10902: tensor([1, 1], device='cuda:0'), 18646: tensor([1, 1], device='cuda:0'), 22879: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 5773: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 13282: tensor([1, 1], device='cuda:0'), 17558: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 8169: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 20349: tensor([1, 1], device='cuda:0')}, {1503: tensor([1, 1], device='cuda:0'), 2421: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7802: tensor([1, 1], device='cuda:0'), 9925: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 17540: tensor([1, 1], device='cuda:0')}, {234: tensor([0, 1], device='cuda:0'), 3898: tensor([1, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 10216: tensor([0, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 585: tensor([1, 1], device='cuda:0'), 2022: tensor([1, 1], device='cuda:0'), 2102: tensor([1, 1], device='cuda:0'), 3777: tensor([1, 1], device='cuda:0'), 4103: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5991: tensor([1, 1], device='cuda:0'), 12884: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 18914: tensor([1, 1], device='cuda:0'), 19162: tensor([1, 1], device='cuda:0'), 21285: tensor([1, 1], device='cuda:0')}, {541: tensor([0, 1], device='cuda:0'), 2421: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 17491: tensor([0, 1], device='cuda:0'), 17550: tensor([0, 1], device='cuda:0'), 20078: tensor([0, 1], device='cuda:0'), 24070: tensor([0, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 3826: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 13212: tensor([1, 1], device='cuda:0'), 16325: tensor([1, 1], device='cuda:0'), 22161: tensor([1, 1], device='cuda:0'), 22588: tensor([1, 1], device='cuda:0'), 22980: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1531: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8630: tensor([1, 1], device='cuda:0'), 12829: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 2252: tensor([0, 1], device='cuda:0'), 3324: tensor([0, 1], device='cuda:0'), 8006: tensor([0, 1], device='cuda:0'), 8169: tensor([0, 1], device='cuda:0'), 12876: tensor([0, 1], device='cuda:0'), 17550: tensor([0, 1], device='cuda:0'), 20078: tensor([0, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13334: tensor([1, 1], device='cuda:0'), 13819: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 20418: tensor([1, 1], device='cuda:0'), 21271: tensor([1, 1], device='cuda:0'), 22202: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2741: tensor([1, 1], device='cuda:0'), 3826: tensor([1, 1], device='cuda:0'), 4619: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5998: tensor([1, 1], device='cuda:0'), 10259: tensor([1, 1], device='cuda:0'), 17133: tensor([1, 1], device='cuda:0'), 22683: tensor([1, 1], device='cuda:0')}, {6217: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 7057: tensor([1, 1], device='cuda:0'), 8752: tensor([1, 1], device='cuda:0'), 10751: tensor([1, 1], device='cuda:0'), 17133: tensor([1, 1], device='cuda:0'), 18115: tensor([1, 1], device='cuda:0'), 21027: tensor([1, 1], device='cuda:0'), 22683: tensor([1, 1], device='cuda:0')}, {660: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 2256: tensor([1, 1], device='cuda:0'), 2575: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6217: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13184: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 14445: tensor([1, 1], device='cuda:0'), 15693: tensor([1, 1], device='cuda:0'), 17516: tensor([1, 1], device='cuda:0'), 20084: tensor([1, 1], device='cuda:0'), 24045: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4276: tensor([1, 1], device='cuda:0'), 4809: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 21642: tensor([1, 1], device='cuda:0'), 24551: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 2492: tensor([1, 1], device='cuda:0'), 3777: tensor([1, 1], device='cuda:0'), 4583: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7265: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1531: tensor([1, 1], device='cuda:0'), 2561: tensor([1, 1], device='cuda:0'), 3427: tensor([1, 1], device='cuda:0'), 4103: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8221: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0'), 21285: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6602: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 7635: tensor([1, 1], device='cuda:0'), 8088: tensor([1, 1], device='cuda:0'), 10740: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 19588: tensor([1, 1], device='cuda:0'), 22308: tensor([1, 1], device='cuda:0'), 23941: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2757: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 18767: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 3986: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 9501: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13036: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 15575: tensor([1, 1], device='cuda:0'), 18646: tensor([1, 1], device='cuda:0'), 24045: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 11465: tensor([0, 1], device='cuda:0'), 12943: tensor([0, 1], device='cuda:0'), 18646: tensor([0, 1], device='cuda:0'), 22005: tensor([0, 1], device='cuda:0')}, {70: tensor([1, 0], device='cuda:0'), 234: tensor([1, 0], device='cuda:0'), 1750: tensor([1, 0], device='cuda:0'), 2252: tensor([1, 0], device='cuda:0'), 2421: tensor([1, 0], device='cuda:0'), 4963: tensor([1, 0], device='cuda:0'), 10216: tensor([1, 0], device='cuda:0'), 12752: tensor([1, 0], device='cuda:0'), 15354: tensor([1, 0], device='cuda:0'), 18106: tensor([1, 0], device='cuda:0'), 18679: tensor([1, 0], device='cuda:0')}, {2492: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 10259: tensor([1, 1], device='cuda:0'), 10534: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 18646: tensor([1, 1], device='cuda:0')}, {1497: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8830: tensor([1, 1], device='cuda:0'), 8865: tensor([1, 1], device='cuda:0'), 13717: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 0], device='cuda:0'), 6217: tensor([1, 0], device='cuda:0'), 7267: tensor([1, 0], device='cuda:0'), 13457: tensor([1, 0], device='cuda:0'), 15575: tensor([1, 0], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 1947: tensor([1, 1], device='cuda:0'), 3986: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6311: tensor([1, 1], device='cuda:0'), 10835: tensor([1, 1], device='cuda:0'), 11062: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 19091: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 5408: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 23129: tensor([1, 1], device='cuda:0')}, {1776: tensor([0, 1], device='cuda:0'), 4594: tensor([0, 1], device='cuda:0'), 4963: tensor([0, 1], device='cuda:0'), 7261: tensor([0, 1], device='cuda:0'), 7267: tensor([0, 1], device='cuda:0'), 8916: tensor([0, 1], device='cuda:0'), 12943: tensor([0, 1], device='cuda:0'), 18914: tensor([0, 1], device='cuda:0'), 21328: tensor([0, 1], device='cuda:0'), 22910: tensor([0, 1], device='cuda:0'), 24045: tensor([0, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 2421: tensor([1, 1], device='cuda:0'), 3520: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8236: tensor([1, 1], device='cuda:0'), 8830: tensor([1, 1], device='cuda:0'), 9501: tensor([1, 1], device='cuda:0'), 14445: tensor([1, 1], device='cuda:0'), 17205: tensor([1, 1], device='cuda:0'), 17579: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0')}, {234: tensor([1, 1], device='cuda:0'), 4809: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 17796: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5811: tensor([1, 1], device='cuda:0'), 7690: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 22161: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 7690: tensor([1, 1], device='cuda:0'), 16618: tensor([1, 1], device='cuda:0'), 19260: tensor([1, 1], device='cuda:0')}, {70: tensor([0, 1], device='cuda:0'), 2107: tensor([0, 1], device='cuda:0'), 3470: tensor([0, 1], device='cuda:0'), 5374: tensor([0, 1], device='cuda:0'), 7146: tensor([0, 1], device='cuda:0'), 14318: tensor([0, 1], device='cuda:0'), 15333: tensor([0, 1], device='cuda:0'), 15573: tensor([0, 1], device='cuda:0'), 22455: tensor([0, 1], device='cuda:0'), 22743: tensor([0, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2421: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 17411: tensor([1, 1], device='cuda:0'), 19573: tensor([1, 1], device='cuda:0'), 20636: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 907: tensor([1, 1], device='cuda:0'), 1328: tensor([1, 1], device='cuda:0'), 2102: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6327: tensor([1, 1], device='cuda:0'), 7261: tensor([1, 1], device='cuda:0'), 8881: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 13503: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 8454: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 22308: tensor([1, 1], device='cuda:0')}, {1172: tensor([1, 1], device='cuda:0'), 1202: tensor([1, 1], device='cuda:0'), 5991: tensor([1, 1], device='cuda:0'), 7842: tensor([1, 1], device='cuda:0'), 11062: tensor([1, 1], device='cuda:0'), 17680: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6979: tensor([1, 1], device='cuda:0'), 7690: tensor([1, 1], device='cuda:0'), 10106: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 14016: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2256: tensor([1, 1], device='cuda:0'), 2469: tensor([1, 1], device='cuda:0'), 2616: tensor([1, 1], device='cuda:0'), 4463: tensor([1, 1], device='cuda:0'), 4597: tensor([1, 1], device='cuda:0'), 11458: tensor([1, 1], device='cuda:0'), 11568: tensor([1, 1], device='cuda:0'), 12732: tensor([1, 1], device='cuda:0'), 13602: tensor([1, 1], device='cuda:0')}, {1391: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8916: tensor([1, 1], device='cuda:0'), 14232: tensor([1, 1], device='cuda:0'), 14445: tensor([1, 1], device='cuda:0'), 14496: tensor([1, 1], device='cuda:0'), 15354: tensor([1, 1], device='cuda:0'), 16319: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 20078: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 3324: tensor([1, 1], device='cuda:0'), 4692: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 22924: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 2107: tensor([1, 1], device='cuda:0'), 4585: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7057: tensor([1, 1], device='cuda:0'), 12471: tensor([1, 1], device='cuda:0'), 13184: tensor([1, 1], device='cuda:0'), 13503: tensor([1, 1], device='cuda:0'), 22337: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 442: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 10580: tensor([1, 1], device='cuda:0'), 16325: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 23306: tensor([1, 1], device='cuda:0')}, {2102: tensor([1, 0], device='cuda:0'), 4963: tensor([1, 0], device='cuda:0'), 7146: tensor([1, 0], device='cuda:0'), 9286: tensor([1, 0], device='cuda:0'), 10112: tensor([1, 0], device='cuda:0'), 14496: tensor([1, 0], device='cuda:0'), 17230: tensor([1, 0], device='cuda:0'), 18619: tensor([1, 0], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 3364: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5718: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13207: tensor([1, 1], device='cuda:0'), 17714: tensor([1, 1], device='cuda:0')}, {2107: tensor([1, 1], device='cuda:0'), 2226: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6726: tensor([1, 1], device='cuda:0'), 12849: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 14491: tensor([1, 1], device='cuda:0'), 15255: tensor([1, 1], device='cuda:0')}, {3986: tensor([1, 1], device='cuda:0'), 4103: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 6259: tensor([1, 1], device='cuda:0'), 6871: tensor([1, 1], device='cuda:0'), 9492: tensor([1, 1], device='cuda:0'), 11431: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 16403: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {2198: tensor([1, 1], device='cuda:0'), 2421: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9309: tensor([1, 1], device='cuda:0'), 15177: tensor([1, 1], device='cuda:0'), 18966: tensor([1, 1], device='cuda:0'), 23977: tensor([1, 1], device='cuda:0'), 24186: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1776: tensor([1, 1], device='cuda:0'), 2421: tensor([1, 1], device='cuda:0'), 3377: tensor([1, 1], device='cuda:0'), 4325: tensor([1, 1], device='cuda:0'), 4766: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 5517: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13187: tensor([1, 1], device='cuda:0'), 18679: tensor([1, 1], device='cuda:0'), 19003: tensor([1, 1], device='cuda:0'), 21285: tensor([1, 1], device='cuda:0'), 22599: tensor([1, 1], device='cuda:0'), 23921: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 4196: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 5408: tensor([1, 1], device='cuda:0'), 6327: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 21249: tensor([1, 1], device='cuda:0'), 22683: tensor([1, 1], device='cuda:0'), 23426: tensor([1, 1], device='cuda:0'), 24070: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 7690: tensor([1, 1], device='cuda:0'), 8036: tensor([1, 1], device='cuda:0'), 13457: tensor([1, 1], device='cuda:0'), 22588: tensor([1, 1], device='cuda:0')}, {4963: tensor([1, 1], device='cuda:0'), 6600: tensor([1, 1], device='cuda:0'), 11373: tensor([1, 1], device='cuda:0'), 13503: tensor([1, 1], device='cuda:0'), 22308: tensor([1, 1], device='cuda:0'), 24294: tensor([1, 1], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 5374: tensor([1, 1], device='cuda:0'), 7146: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0')}, {1437: tensor([1, 1], device='cuda:0'), 1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9501: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13503: tensor([1, 1], device='cuda:0'), 18767: tensor([1, 1], device='cuda:0'), 22198: tensor([1, 1], device='cuda:0')}, {49: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 8172: tensor([1, 1], device='cuda:0'), 8830: tensor([1, 1], device='cuda:0'), 10956: tensor([1, 1], device='cuda:0'), 11012: tensor([1, 1], device='cuda:0'), 12752: tensor([1, 1], device='cuda:0'), 12943: tensor([1, 1], device='cuda:0'), 13717: tensor([1, 1], device='cuda:0'), 17205: tensor([1, 1], device='cuda:0'), 17550: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 20092: tensor([1, 1], device='cuda:0'), 21328: tensor([1, 1], device='cuda:0')}, {70: tensor([1, 0], device='cuda:0'), 2107: tensor([1, 0], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 9219: tensor([1, 1], device='cuda:0'), 11373: tensor([1, 0], device='cuda:0'), 11431: tensor([1, 0], device='cuda:0'), 11568: tensor([1, 0], device='cuda:0'), 13184: tensor([1, 0], device='cuda:0'), 13212: tensor([1, 0], device='cuda:0'), 15573: tensor([1, 0], device='cuda:0'), 21328: tensor([1, 0], device='cuda:0'), 22308: tensor([1, 0], device='cuda:0'), 24551: tensor([1, 0], device='cuda:0')}, {1750: tensor([1, 1], device='cuda:0'), 4963: tensor([1, 1], device='cuda:0'), 13534: tensor([1, 1], device='cuda:0'), 22588: tensor([1, 1], device='cuda:0')}, {2198: tensor([1, 1], device='cuda:0'), 7267: tensor([1, 1], device='cuda:0'), 7395: tensor([1, 1], device='cuda:0'), 12241: tensor([1, 1], device='cuda:0'), 15573: tensor([1, 1], device='cuda:0'), 17588: tensor([1, 1], device='cuda:0'), 18799: tensor([1, 1], device='cuda:0')}, {4963: tensor([1], device='cuda:0'), 12943: tensor([1], device='cuda:0')}], caches=[], alive_latents=[], answer_indices=[], correct_activations=[], ablation_effects=[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([[0., 0., 0.,  ..., 0., 0., 0.]])], tokens=[], prompts=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: consider instantiating a trainer here once initial exploration is done\n",
    "# manually init IT components for now\n",
    "it_init(**it_session)\n",
    "assert sl_test_module.it_cfg.entailment_mapping_indices is not None\n",
    "\n",
    "#from copy import deepcopy\n",
    "\n",
    "# TODO: move to module\n",
    "# TODO: constrain out_summ analysis typing appropriately once usage pattern stabilizes\n",
    "def run_test_split_fn(\n",
    "    module: ITModule,\n",
    "    datamodule: ITDataModule,\n",
    "    limit_test_batches: int,\n",
    "    out_summ: Any,\n",
    "    step_fn: str = \"test_step\",\n",
    "    *args,\n",
    "    **kwargs,\n",
    "):\n",
    "    dataloader = datamodule.test_dataloader()\n",
    "    module._it_state._current_epoch = 0  # TODO: test removing this, prob not needed in this context\n",
    "    #module.model.eval()\n",
    "    step_func = getattr(module, step_fn)\n",
    "    for batch_idx, batch in tqdm(enumerate(dataloader)):\n",
    "        if batch_idx >= limit_test_batches >= 0:\n",
    "            break\n",
    "        batch = module.batch_to_device(batch)\n",
    "        step_func(batch, batch_idx, out_summ=out_summ, *args, **kwargs)\n",
    "        module.global_step += 1\n",
    "    return out_summ\n",
    "\n",
    "for handle in sl_test_module.sae_handles:\n",
    "    handle.requires_grad_(False)\n",
    "hook_sae_acts_post = f\"{sl_test_module.sae_handles[0].cfg.hook_name}.hook_sae_acts_post\"\n",
    "\n",
    "test_cache_base_args = dict(\n",
    "    limit_test_batches=-1, logit_diff_fn=boolean_logits_to_avg_logit_diff, hooks_filter=hook_sae_acts_post, **it_session\n",
    ")\n",
    "\n",
    "logit_diff_summs = {\"sae_cache\": LogitDiffsSumm(), \"ablation\": LogitDiffsSumm()}\n",
    "\n",
    "#logit_diff_summs_sae_cache = LogitDiffsSumm()\n",
    "\n",
    "# TODO: maybe combine prompt and tokens collection into a single function, wrapping clean, sae and ablated modes\n",
    "run_clean_sanity_check = False\n",
    "\n",
    "sl_test_module.model.requires_grad_(False)\n",
    "#{n: p.requires_grad for n,p in sl_test_module.model.named_parameters()}\n",
    "if run_clean_sanity_check:\n",
    "    logit_diff_summs[\"clean\"] = LogitDiffsSumm()\n",
    "    #logit_diff_summs_clean = LogitDiffsSumm()\n",
    "    run_test_split_fn(\n",
    "        run_ctx=\"clean\",\n",
    "        step_fn=\"activation_cache_test_step\",\n",
    "        out_summ=logit_diff_summs[\"clean\"],\n",
    "        #out_summ=logit_diff_summs_clean,\n",
    "        **test_cache_base_args,\n",
    "    )\n",
    "\n",
    "#gc.collect()\n",
    "#torch.cuda.memory._dump_snapshot(Path(sl_test_module.core_log_dir) / \"before_cache_with_saes_run.pickle\")\n",
    "#logit_diff_summs_sae_cache = LogitDiffsSumm()\n",
    "run_test_split_fn(\n",
    "    run_ctx=\"cache_with_saes\",\n",
    "    step_fn=\"activation_cache_test_step\",\n",
    "    out_summ=logit_diff_summs[\"sae_cache\"],\n",
    "    #out_summ=logit_diff_summs_sae_cache,\n",
    "    save_prompts=True,\n",
    "    save_tokens=True,\n",
    "    #save_caches=True,\n",
    "    **test_cache_base_args,\n",
    ")\n",
    "\n",
    "#namespace = globals().copy() | locals()\n",
    "#sl_mem_utils.profile_pytorch_memory(namespace=namespace, filter_device=\"cuda:0\")\n",
    "\n",
    "ablation_fwd_hook_cfg = {\n",
    "    \"hook_names\": hook_sae_acts_post,\n",
    "    \"hook_fn\": ablate_sae_latent,\n",
    "    \"alive_latents\": logit_diff_summs[\"sae_cache\"].alive_latents,\n",
    "    \"answer_indices\": logit_diff_summs[\"sae_cache\"].answer_indices,\n",
    "    \"base_logit_diffs\": logit_diff_summs[\"sae_cache\"].logit_diffs,\n",
    "    # \"alive_latents\": deepcopy(logit_diff_summs[\"sae_cache\"].alive_latents),\n",
    "    # \"answer_indices\": deepcopy(logit_diff_summs[\"sae_cache\"].answer_indices),\n",
    "    # \"base_logit_diffs\": deepcopy(logit_diff_summs[\"sae_cache\"].logit_diffs),\n",
    "    # \"alive_latents\": deepcopy(logit_diff_summs_sae_cache.alive_latents),\n",
    "    # \"answer_indices\": deepcopy(logit_diff_summs_sae_cache.answer_indices),\n",
    "    # \"base_logit_diffs\": deepcopy(logit_diff_summs_sae_cache.logit_diffs),\n",
    "}\n",
    "\n",
    "#del logit_diff_summs[\"sae_cache\"]\n",
    "#del logit_diff_summs_sae_cache\n",
    "#gc.collect()\n",
    "\n",
    "#torch.cuda.memory._record_memory_history()\n",
    "#torch.cuda.memory._dump_snapshot(Path(sl_test_module.core_log_dir) / \"before_ablation_run.pickle\")\n",
    "#logit_diff_summs_ablation = LogitDiffsSumm()\n",
    "run_test_split_fn(\n",
    "    run_ctx=\"hooks_with_saes\",\n",
    "    step_fn=\"ablation_test_step\",\n",
    "    fwd_hooks_cfg=ablation_fwd_hook_cfg,\n",
    "    out_summ=logit_diff_summs[\"ablation\"],\n",
    "    #out_summ=logit_diff_summs_ablation,\n",
    "    **test_cache_base_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_clean_sanity_check:\n",
    "\n",
    "    translated_labels = [\n",
    "        sl_test_module.datamodule.tokenizer.batch_decode(labels, **DEFAULT_DECODE_KWARGS)\n",
    "        for labels in logit_diff_summs[\"clean\"].labels\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"prompt\": logit_diff_summs[\"sae_cache\"].prompts,\n",
    "            \"correct_answer\": translated_labels,\n",
    "            \"clean_logit_diff\": logit_diff_summs[\"clean\"].logit_diffs,\n",
    "            \"sae_logit_diff\": logit_diff_summs[\"sae_cache\"].logit_diffs,\n",
    "        }\n",
    "    )\n",
    "    df = df.explode([\"prompt\", \"correct_answer\", \"clean_logit_diff\", \"sae_logit_diff\"])\n",
    "    df[\"sample_id\"] = range(len(df))\n",
    "    df = df[[\"sample_id\", \"prompt\", \"correct_answer\", \"clean_logit_diff\", \"sae_logit_diff\"]]\n",
    "    df = df[df.clean_logit_diff > 0].sort_values(by=\"clean_logit_diff\", ascending=False)\n",
    "\n",
    "    print(\n",
    "        tabulate(\n",
    "            df,\n",
    "            headers=[\"Sample ID\", \"Prompt\", \"Answer\", \"Clean Logit Diff\", \"SAE Logit Diff\"],\n",
    "            maxcolwidths=[None, 80, None, None, None],\n",
    "            tablefmt=\"grid\",\n",
    "            numalign=\"left\",\n",
    "            floatfmt=\"+.3f\",\n",
    "            showindex=\"never\",\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+----------------------+\n",
      "| Mode      |   Total Correct | Percentage Correct   |\n",
      "+===========+=================+======================+\n",
      "| sae_cache |             129 | 46.57%               |\n",
      "+-----------+-----------------+----------------------+\n",
      "| ablation  |             129 | 46.57%               |\n",
      "+-----------+-----------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "mode_correct = {}\n",
    "\n",
    "for mode, summ in logit_diff_summs.items():\n",
    "    if mode in [\"clean\", \"sae_cache\"]:\n",
    "        correct_statuses = [(labels == preds) for labels, preds in zip(summ.orig_labels, summ.preds)]\n",
    "        positive_logit_diff_statuses = [(logit_diffs > 0) for logit_diffs in summ.logit_diffs]\n",
    "        assert all(torch.eq(torch.cat(correct_statuses), torch.cat(positive_logit_diff_statuses)))\n",
    "        total_correct = sum(torch.cat(correct_statuses)).item()\n",
    "        percentage_correct = total_correct / len(torch.cat(correct_statuses)) * 100\n",
    "        mode_correct[mode] = (total_correct, percentage_correct)\n",
    "    else:\n",
    "        ablation_per_batch_preds = [torch.stack([p for p in pl.values()]).mode(dim=0).values.cpu() for pl in summ.preds]\n",
    "        num_correct = [(labels == preds).nonzero().unique().size(0) for labels, preds in zip(summ.orig_labels, ablation_per_batch_preds)]\n",
    "        total_correct = sum(num_correct)\n",
    "        batch_size = summ.labels[0].size(0)\n",
    "        percentage_correct = total_correct / (len(torch.cat(summ.orig_labels))) * 100\n",
    "        mode_correct[mode] = (total_correct, percentage_correct)\n",
    "\n",
    "table_rows = []\n",
    "for mode, (total_correct, percentage_correct) in mode_correct.items():\n",
    "    table_rows.append([mode, total_correct, f\"{percentage_correct:.2f}%\"])\n",
    "\n",
    "print(tabulate(table_rows, headers=[\"Mode\", \"Total Correct\", \"Percentage Correct\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_per_batch_effects_graphs = False\n",
    "\n",
    "if generate_per_batch_effects_graphs:\n",
    "    for i, ablation_effects in enumerate(logit_diff_summs[\"ablation\"].ablation_effects):\n",
    "        px.line(\n",
    "            ablation_effects.mean(dim=0).cpu().numpy(),\n",
    "            title=f\"Causal effects of latent ablation on logit diff of batch {i} ({len(logit_diff_summs['sae_cache'].alive_latents[i])} alive)\",\n",
    "            labels={\"index\": \"Latent\", \"value\": \"Causal effect on logit diff\"},\n",
    "            template=\"ggplot2\",\n",
    "            width=1000,\n",
    "        ).update_layout(showlegend=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|   Latent Index |   Total Positive Effect |   Mean Effect |   Mean Activation |   Num Examples Active |   Proportion Correct Examples Active |\n",
      "+================+=========================+===============+===================+=======================+======================================+\n",
      "|           9501 |               0.177643  |   0.00137708  |         0.042603  |                     2 |                           0.0155039  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|          22308 |               0.0970917 |   0.000752649 |         0.0381489 |                     3 |                           0.0232558  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|            234 |               0.080368  |   0.000623008 |         0.0267507 |                     4 |                           0.0310078  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           3203 |               0.0788879 |   0.000611534 |         0.0215768 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           5374 |               0.0698853 |   0.000541746 |         0.0219904 |                     2 |                           0.0155039  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           1750 |               0.0536957 |   0.000416246 |         0.0196182 |                     8 |                           0.0620155  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           5773 |               0.0521851 |   0.000404535 |         0.0156282 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|          23129 |               0.0519257 |   0.000402524 |         0.0109184 |                     2 |                           0.0155039  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|          13184 |               0.0440369 |   0.000341371 |         0.0113947 |                     5 |                           0.0387597  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           2581 |               0.0389252 |   0.000301746 |         0.0148076 |                     2 |                           0.0155039  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|   Latent Index |   Total Negative Effect |   Mean Effect |   Mean Activation |   Num Examples Active |   Proportion Correct Examples Active |\n",
      "+================+=========================+===============+===================+=======================+======================================+\n",
      "|           4963 |              -1.90787   |  -0.0147897   |         0.250286  |                    81 |                           0.627907   |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           4634 |              -0.12291   |  -0.000952787 |         0.0353319 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           4692 |              -0.120712  |  -0.000935754 |         0.0175352 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|          12943 |              -0.103874  |  -0.000805226 |         0.0297278 |                    23 |                           0.178295   |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           8881 |              -0.0795441 |  -0.000616621 |         0.0155901 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|          10902 |              -0.0688324 |  -0.000533585 |         0.0206271 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           3520 |              -0.0464859 |  -0.000360356 |         0.0166622 |                     2 |                           0.0155039  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|           9925 |              -0.0337677 |  -0.000261765 |         0.0142197 |                     1 |                           0.00775194 |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|             70 |              -0.0333252 |  -0.000258335 |         0.0424937 |                    31 |                           0.24031    |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "|          18914 |              -0.0325775 |  -0.000252539 |         0.0125603 |                     4 |                           0.0310078  |\n",
      "+----------------+-------------------------+---------------+-------------------+-----------------------+--------------------------------------+\n",
      "#9501 had total causal effect 0.18 and was active in 2 examples\n",
      "https://neuronpedia.org/gpt2-small/9-att-kk/9501?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/9501?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f655a5b0e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#22308 had total causal effect 0.10 and was active in 3 examples\n",
      "https://neuronpedia.org/gpt2-small/9-att-kk/22308?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/22308?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6504c431d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#234 had total causal effect 0.08 and was active in 4 examples\n",
      "https://neuronpedia.org/gpt2-small/9-att-kk/234?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/234?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6504c422d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4963 had total causal effect -1.91 and was active in 81 examples\n",
      "https://neuronpedia.org/gpt2-small/9-att-kk/4963?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/4963?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6504c41310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4634 had total causal effect -0.12 and was active in 1 examples\n",
      "https://neuronpedia.org/gpt2-small/9-att-kk/4634?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/4634?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6504c422d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4692 had total causal effect -0.12 and was active in 1 examples\n",
      "https://neuronpedia.org/gpt2-small/9-att-kk/4692?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://neuronpedia.org/gpt2-small/9-att-kk/4692?embed=true&embedexplanation=true&embedplots=true&embedtest=true&height=300\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6504c4ee70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "k = 10\n",
    "\n",
    "correct_acts = torch.cat(logit_diff_summs[\"sae_cache\"].correct_activations)\n",
    "avg_correct_act, num_correct_act = correct_acts.mean(dim=0), correct_acts.count_nonzero(dim=0)\n",
    "proportion_correct_active = num_correct_act / len(correct_acts)\n",
    "correct_mask = torch.cat([(labels == preds) for labels, preds in zip(logit_diff_summs[\"ablation\"].orig_labels, ablation_per_batch_preds)])\n",
    "per_example_ablation_effects = torch.cat(logit_diff_summs[\"ablation\"].ablation_effects)[correct_mask]\n",
    "total_ablation_effects = per_example_ablation_effects.sum(dim=0)\n",
    "avg_ablation_effects = per_example_ablation_effects.mean(dim=0)\n",
    "topk_latents_by_total_ablation_positive = total_ablation_effects.topk(k)\n",
    "topk_latents_by_total_ablation_negative = total_ablation_effects.topk(k, largest=False)\n",
    "\n",
    "for i, total_summ in enumerate([topk_latents_by_total_ablation_positive, topk_latents_by_total_ablation_negative]):\n",
    "    table_rows = []\n",
    "    for value, ind in zip(*total_summ):\n",
    "        table_rows.append([\n",
    "            ind.item(),\n",
    "            value.item(),\n",
    "            avg_ablation_effects[ind].item(),\n",
    "            avg_correct_act[ind].item(),\n",
    "            num_correct_act[ind].item(),\n",
    "            proportion_correct_active[ind].item(),\n",
    "        ])\n",
    "    print(tabulate(table_rows,\n",
    "                headers=[\"Latent Index\", f\"Total {\"Positive\" if i == 0 else \"Negative\"} Effect\", \"Mean Effect\", \"Mean Activation\", \"Num Examples Active\", \n",
    "                            \"Proportion Correct Examples Active\"], tablefmt=\"grid\"))\n",
    "\n",
    "# Print the top 3 positive and negative dashboards\n",
    "dashboard_k = 3\n",
    "topk_latents_by_total_ablation_positive = total_ablation_effects.topk(dashboard_k)\n",
    "topk_latents_by_total_ablation_negative = total_ablation_effects.topk(dashboard_k, largest=False)\n",
    "for i, topk_ablation_latents in enumerate([topk_latents_by_total_ablation_positive, topk_latents_by_total_ablation_negative]):\n",
    "    for value, ind in zip(*topk_ablation_latents):\n",
    "        print(f\"#{ind} had total causal effect {value:.2f} and was active in {num_correct_act[ind]} examples\")\n",
    "        display_dashboard(\n",
    "            sae_release=\"gpt2-small-hook-z-kk\",\n",
    "            sae_id=f\"blocks.{layer}.hook_z\",\n",
    "            latent_idx=int(ind),\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: continue implementation here\n",
    "#   - continue with attribution patching reproduction of latent effects! (on 2 batch subset, plot top latents for dataset)\n",
    "#   - extend attribution patching to collect latent effects at two different layers and replot top latents\n",
    "#   - apply created pipeline to gemma2 and other models!\n",
    "#   - go back and extend ablation to iterate over multiple sae layers\n",
    "#   - explore using a threshold positive logit diff for tuning\n",
    "#   - though relative logits remain comparable, investigate impact of logit magnitude being substantially smaller with padding_side=left (should be able to re-run with padding_side=right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cache_fwd_and_bwd(model: HookedSAETransformer, saes: list[SAE], input, metric):\n",
    "#     \"\"\"\n",
    "#     Get forward and backward caches for a model, given a metric.\n",
    "#     \"\"\"\n",
    "#     filter_sae_acts = lambda name: \"hook_sae_acts_post\" in name\n",
    "\n",
    "#     # This hook function will store activations in the appropriate cache\n",
    "#     cache_dict = {\"fwd\": {}, \"bwd\": {}}\n",
    "\n",
    "#     def cache_hook(act, hook, dir: Literal[\"fwd\", \"bwd\"]):\n",
    "#         cache_dict[dir][hook.name] = act.detach()\n",
    "\n",
    "#     with model.saes(saes=saes):\n",
    "#         # We add hooks to cache values from the forward and backward pass respectively\n",
    "#         with model.hooks(\n",
    "#             fwd_hooks=[(filter_sae_acts, partial(cache_hook, dir=\"fwd\"))],\n",
    "#             bwd_hooks=[(filter_sae_acts, partial(cache_hook, dir=\"bwd\"))],\n",
    "#         ):\n",
    "#             # Forward pass fills the fwd cache, then backward pass fills the bwd cache (we don't care about metric value)\n",
    "#             _ = metric(model(input)).backward()\n",
    "\n",
    "#     return (\n",
    "#         ActivationCache(cache_dict[\"fwd\"], model),\n",
    "#         ActivationCache(cache_dict[\"bwd\"], model),\n",
    "#     )\n",
    "\n",
    "\n",
    "# clean_logits = gpt2.run_with_saes(prompts, saes=[attn_saes[layer]])\n",
    "# clean_logit_diff = logits_to_ave_logit_diff(clean_logits)\n",
    "\n",
    "# torch.set_grad_enabled(True)\n",
    "# clean_cache, clean_grad_cache = get_cache_fwd_and_bwd(\n",
    "#     gpt2,\n",
    "#     [attn_saes[layer]],\n",
    "#     prompts,\n",
    "#     lambda logits: logits_to_ave_logit_diff(logits, keep_as_tensor=True, reduction=\"sum\"),\n",
    "# )\n",
    "# torch.set_grad_enabled(False)\n",
    "\n",
    "# # Extract activations and gradients\n",
    "# hook_sae_acts_post = f\"{attn_saes[layer].cfg.hook_name}.hook_sae_acts_post\"\n",
    "# clean_sae_acts_post = clean_cache[hook_sae_acts_post]\n",
    "# clean_grad_sae_acts_post = clean_grad_cache[hook_sae_acts_post]\n",
    "\n",
    "# # Compute attribution values for all latents, then index to get live ones\n",
    "# attribution_values = (clean_grad_sae_acts_post * clean_sae_acts_post)[:, s2_pos, alive_latents].mean(0)\n",
    "\n",
    "# # Visualize results\n",
    "# px.scatter(\n",
    "#     pd.DataFrame(\n",
    "#         {\n",
    "#             \"Ablation\": ablation_effects[alive_latents].cpu().numpy(),\n",
    "#             \"Attribution Patching\": attribution_values.cpu().numpy(),\n",
    "#             \"Latent\": alive_latents,\n",
    "#         }\n",
    "#     ),\n",
    "#     x=\"Ablation\",\n",
    "#     y=\"Attribution Patching\",\n",
    "#     hover_data=[\"Latent\"],\n",
    "#     title=\"Attribution Patching vs Ablation\",\n",
    "#     template=\"ggplot2\",\n",
    "#     width=800,\n",
    "#     height=600,\n",
    "# ).add_shape(\n",
    "#     type=\"line\",\n",
    "#     x0=attribution_values.min(),\n",
    "#     x1=attribution_values.max(),\n",
    "#     y0=attribution_values.min(),\n",
    "#     y1=attribution_values.max(),\n",
    "#     line=dict(color=\"red\", width=2, dash=\"dash\"),\n",
    "# ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
