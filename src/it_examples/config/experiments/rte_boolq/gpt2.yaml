it_session:
  datamodule_cls: it_examples.experiments.rte_boolq.datamodules.GPT2RTEBoolqDataModule
  datamodule_cfg:
    class_path: interpretune.base.config.datamodule.ITDataModuleConfig
    init_args:
      model_name_or_path: gpt2
      task_name: rte
      train_batch_size: 32
      eval_batch_size: 32
      data_collator_cfg:
        collator_class: transformers.DataCollatorWithPadding
      prompt_cfg:
        class_path: it_examples.experiments.rte_boolq.config.RTEBoolqPromptConfig
        init_args:
          cust_task_prompt:
            context: '<|PREMISE|>:'
            question: '<|HYPOTHESIS|>:'
      tokenizers_parallelism: false
      enable_datasets_cache: true
      prepare_data_map_cfg:
        batched: true
      tokenizer_id_overrides:
        pad_token_id: 50256
      tokenizer_kwargs:
        use_fast: true  # by default true
        add_bos_token: true
        local_files_only: false
        padding_side: right
        model_input_names: ['input_ids', 'attention_mask']
  module_cls: it_examples.experiments.rte_boolq.modules.RTEBoolqLMHeadModule
  module_cfg:
    class_path: it_examples.experiments.rte_boolq.config.RTEBoolqConfig
    init_args:
      # N.B. We can't inherit dictionary-contained keys like hf_from_pretrained_cfg['device_map'] at the experiment
      # level because while jsonargparse will update/inherit `init_args`, the full dictionary object is replaced by the
      # overriding config rather than the relevant dictionary being updated.
      hf_from_pretrained_cfg:
        class_path: interpretune.base.config.module.HFFromPretrainedConfig
        init_args:
          use_model_cache: false
          model_head: transformers.GPT2LMHeadModel
          activation_checkpointing: false
