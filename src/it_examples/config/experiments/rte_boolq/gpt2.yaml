it_session:
  datamodule_cls: it_examples.experiments.rte_boolq.datamodules.GPT2RTEBoolqDataModule
  datamodule_cfg:
    class_path: interpretune.base.config.datamodule.ITDataModuleConfig
    init_args:
      model_name_or_path: gpt2
      task_name: rte
      train_batch_size: 32
      eval_batch_size: 32
      data_collator_cfg:
        collator_class: transformers.DataCollatorWithPadding
      prompt_cfg:
        class_path: it_examples.experiments.rte_boolq.config.RTEBoolqPromptConfig
        init_args:
          cust_task_prompt:
            context: '<|PREMISE|>:'
            question: '<|HYPOTHESIS|>:'
      tokenizers_parallelism: false
      enable_datasets_cache: true
      prepare_data_map_cfg:
        batched: true
      tokenizer_id_overrides:
        pad_token_id: 50256
      tokenizer_kwargs:
        use_fast: true  # by default true
        add_bos_token: true
        local_files_only: false
        padding_side: right
        model_input_names: ['input_ids', 'attention_mask']
  module_cls: it_examples.experiments.rte_boolq.modules.RTEBoolqClassificationModule
  module_cfg:
    class_path: it_examples.experiments.rte_boolq.config.RTEBoolqConfig
    init_args:
      use_model_cache: false
      auto_model_cfg:
        model_head: transformers.GPT2ForSequenceClassification
      activation_checkpointing: false
