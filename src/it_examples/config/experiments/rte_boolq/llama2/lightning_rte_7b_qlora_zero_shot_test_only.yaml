data.class_path: it_examples.experiments.rte_boolq.lightning.Llama2RTEBoolqLightningDataModule
model.class_path: it_examples.experiments.rte_boolq.lightning.Llama2ITLightningModule
itdm_cfg:
  class_path: interpretune.config_classes.datamodule.ITDataModuleConfig
  init_args:
    model_name_or_path: meta-llama/Llama-2-7b-chat-hf
    task_name: rte
    dataset_path: /home/speediedan/.cache/huggingface/datasets/rte
    train_batch_size: 2
    eval_batch_size: 2
    #prepare_validation_set_only: true
    cust_tokenization_pattern: llama2-chat
it_cfg:
  class_path: interpretune.config_classes.module.ITConfig
  init_args:
    # defining the config class with custom dataclass overrides
    zero_shot_cfg:
      class_path: it_examples.experiments.rte_boolq.core.RTEBoolqZeroShotClassificationConfig
      init_args:
        enabled: true
        lm_generation_cfg:
          class_path: interpretune.mixins.zero_shot_classification.HFGenerationConfig
          init_args:
            max_new_tokens: 5
    activation_checkpointing: false
    use_model_cache: true
    auto_model_cfg:
      model_head: transformers.LlamaForCausalLM
trainer:
  devices: 1
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      name: llama2_chat_rte_7b_qlora_zero_shot_test_only
