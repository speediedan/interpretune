name: Test full

on:
  workflow_dispatch:
    inputs:
      logLevel:
        description: 'Log level'
        required: false
        default: 'INFO'
        type: choice
        options:
        - 'INFO'
        - 'DEBUG'
      run_resource_monitor:
        description: 'Run CI resource monitor'
        required: false
        default: '0'
        type: string
      enable_os_trace:
        description: 'Enable OS-level tracing (Windows only currently)'
        required: false
        default: '0'
        type: string
      pytest_filter_pattern:
        description: 'Pytest filter pattern (optional)'
        required: false
        default: ''
        type: string
      run_w_grafana:
        description: 'Run Grafana Alloy resource monitoring (Linux only)'
        required: false
        default: '0'
        type: string
  push:
    branches: [main, "release/*", "bugfix/*", "feature/*"]
    paths:
      - "setup.*"
      - "requirements.txt"
      - "pyproject.toml"
      - ".codecov.yml"
      - "tests/**"
      - "src/**"
      - "requirements/**"
      - ".github/workflows/ci_test-full.yml"
      - ".actions/**"
      # Exclude documentation-only files from triggering
      - "!docs/**"
      - "!**/*.md"
      - "!**/*.rst"
      - "!mkdocs.yml"
      - "!**/CHANGELOG.md"
      - "!**/CODE_OF_CONDUCT.md"
      - "!**/CONTRIBUTING.md"
      - "!**/LICENSE*"
  pull_request:
    branches: [main, "release/*", "bugfix/*", "feature/*"]
    types: [opened, reopened, ready_for_review, synchronize]
    paths:
      - "setup.*"
      - "requirements.txt"
      - "pyproject.toml"
      - ".codecov.yml"
      - "tests/**"
      - "src/**"
      - "requirements/**"
      - ".github/workflows/ci_test-full.yml"
      - ".actions/**"
      # Exclude documentation-only files from triggering
      - "!docs/**"
      - "!**/*.md"
      - "!**/*.rst"
      - "!mkdocs.yml"
      - "!**/CHANGELOG.md"
      - "!**/CODE_OF_CONDUCT.md"
      - "!**/CONTRIBUTING.md"
      - "!**/LICENSE*"

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-${{ github.head_ref }}
  cancel-in-progress: ${{ ! (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/release/')) }}

jobs:
  # this job allows us to set CI test filters, log level, resource monitor and os tracing, test with precedence:
  # workflow_dispatch inputs -> manual workflow overrides -> repository variable defaults -> fallback defaults
  log-dispatch-inputs:
    runs-on: ubuntu-latest
    outputs:
      log_level: ${{ steps.resolve_dispatch_vars.outputs.log_level }}
      run_resource_monitor: ${{ steps.resolve_dispatch_vars.outputs.run_resource_monitor }}
      enable_os_trace: ${{ steps.resolve_dispatch_vars.outputs.enable_os_trace }}
      pytest_filter_pattern: ${{ steps.resolve_dispatch_vars.outputs.pytest_filter_pattern }}
      run_w_grafana: ${{ steps.resolve_dispatch_vars.outputs.run_w_grafana }}
    steps:
      - name: Capture manual workflow overrides
        id: capture-manual-overrides
        env:
          # toggle comments here as desired to force more granular logging for this workflow
          IT_CI_LOG_LEVEL: ${{ vars.IT_CI_LOG_LEVEL || 'INFO' }}
          # IT_CI_LOG_LEVEL: "DEBUG"
          CI_RESOURCE_MONITOR: ${{ vars.CI_RESOURCE_MONITOR || '0' }}
          # CI_RESOURCE_MONITOR: "1"
          ENABLE_OS_TRACE: "0"
          # ENABLE_OS_TRACE: "1"
          PYTEST_FILTER_PATTERN: ""
          # PYTEST_FILTER_PATTERN: "test_format_columns_all_indices or test_run_with_saes_with_cache_fwd_bwd"
          RUN_W_GRAFANA: ${{ vars.RUN_W_GRAFANA || '0' }}
          # RUN_W_GRAFANA: "1"
        run: |
          echo "IT_CI_LOG_LEVEL=${{ env.IT_CI_LOG_LEVEL || 'INFO' }}" >> $GITHUB_OUTPUT
          echo "CI_RESOURCE_MONITOR=${{ env.CI_RESOURCE_MONITOR || '0' }}" >> $GITHUB_OUTPUT
          echo "ENABLE_OS_TRACE=${{ env.ENABLE_OS_TRACE }}" >> $GITHUB_OUTPUT
          echo "PYTEST_FILTER_PATTERN=${{ env.PYTEST_FILTER_PATTERN }}" >> $GITHUB_OUTPUT
          echo "RUN_W_GRAFANA=${{ env.RUN_W_GRAFANA || '0' }}" >> $GITHUB_OUTPUT
      - name: Resolve workflow dispatch inputs
        id: resolve_dispatch_vars
        run: |
          echo "log_level=${{ inputs.logLevel != '' && inputs.logLevel || steps.capture-manual-overrides.outputs.IT_CI_LOG_LEVEL }}" >> $GITHUB_OUTPUT
          echo "run_resource_monitor=${{ inputs.run_resource_monitor != '' && inputs.run_resource_monitor || steps.capture-manual-overrides.outputs.CI_RESOURCE_MONITOR }}" >> $GITHUB_OUTPUT
          echo "enable_os_trace=${{ inputs.enable_os_trace != '' && inputs.enable_os_trace || steps.capture-manual-overrides.outputs.ENABLE_OS_TRACE }}" >> $GITHUB_OUTPUT
          echo "pytest_filter_pattern=${{ inputs.pytest_filter_pattern != '' && inputs.pytest_filter_pattern || steps.capture-manual-overrides.outputs.PYTEST_FILTER_PATTERN }}" >> $GITHUB_OUTPUT
          echo "run_w_grafana=${{ inputs.run_w_grafana != '' && inputs.run_w_grafana || steps.capture-manual-overrides.outputs.RUN_W_GRAFANA || '1' }}" >> $GITHUB_OUTPUT
  cpu:
    needs: log-dispatch-inputs
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [
          ubuntu-22.04,
          windows-2022,
          macos-14
          ]
        python-version: ["3.12"]
    timeout-minutes: 90
    env:
      IT_USE_CT_COMMIT_PIN: "1"
      WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
      HF_GATED_PUBLIC_REPO_AUTH_KEY: ${{ secrets.HF_GATED_PUBLIC_REPO_AUTH_KEY }}
      ### we need to set the below secrets/vars for Grafana Alloy monitoring in our composite action (which doesn't have direct access to those workflow inputs)
      IT_GRAFANA_GITHUB_TOKEN: ${{ secrets.IT_GRAFANA_GITHUB_TOKEN }}
      PROM_PUSH_URL: ${{ vars.PROM_PUSH_URL }}
      GHA_GRAFANA_USER_ID: ${{ secrets.GHA_GRAFANA_USER_ID }}
      GHA_ALLOY_WRITE_TOKEN: ${{ secrets.GHA_ALLOY_WRITE_TOKEN }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Reset caching
        id: set_time_period
        run: |
          python -c "import time; days = time.time() / 60 / 60 / 24; print(f'TIME_PERIOD=d{int(days / 7) * 7}')" >> $GITHUB_OUTPUT

      - name: Install libpq (macOS only)
        if: runner.os == 'macOS'
        run: |
          brew reinstall libpq
          brew link --force libpq

      # Note: This uses an internal pip API and may not always work
      # https://github.com/actions/cache/blob/master/examples.md#multiple-oss-in-a-workflow
      - name: Get pip cache dir
        id: pip-cache
        shell: bash
        run: |
          echo "PIP_CACHE_DIR=$(pip cache dir)" >> $GITHUB_ENV

      - name: pip cache
        uses: actions/cache@v4
        with:
          path: ${{ env.PIP_CACHE_DIR }}/wheels
          key: ${{ runner.os }}-pip-wheels-${{ steps.set_time_period.outputs.TIME_PERIOD }}-py${{ matrix.python-version }}-${{ hashFiles('requirements/ci/requirements.txt') }}-${{ hashFiles('requirements/post_upgrades.txt') }}-${{ hashFiles('requirements/platform_dependent.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-wheels-${{ steps.set_time_period.outputs.TIME_PERIOD }}-py${{ matrix.python-version }}-

      - name: Set up venv and install ci dependencies (all OS)
        shell: bash
        run: |
          python -m pip install --upgrade pip setuptools wheel build --cache-dir "$PIP_CACHE_DIR"
          # Prefer CI pinned requirements if present
          if [ -f requirements/ci/requirements.txt ]; then
            pip install -r requirements/ci/requirements.txt --cache-dir "$PIP_CACHE_DIR"
            python -m pip install -e '.[test,examples,lightning]' --cache-dir "$PIP_CACHE_DIR"
          else
            python -m pip install -e '.[test,examples,lightning]' -c requirements/ci_constraints.txt --cache-dir "$PIP_CACHE_DIR"
          fi
          pip list

      - name: Install platform-dependent packages
        shell: bash
        run: |
          # Install platform-dependent packages with flexible constraints to allow platform-specific resolution
          if [ -f requirements/platform_dependent.txt ] && [ -s requirements/platform_dependent.txt ]; then
            echo "Installing platform-dependent packages..."
            python -m pip install -r requirements/platform_dependent.txt --cache-dir "$PIP_CACHE_DIR" || echo "Some platform-dependent packages may not be available on this platform, continuing..."
          else
            echo "No platform-dependent packages to install."
          fi

      - name: Optional post-upgrades (datasets/fsspec etc)
        shell: bash
        env:
          APPLY_POST_UPGRADES: ${{ vars.APPLY_POST_UPGRADES || '1' }}
        run: |
          if [ "${APPLY_POST_UPGRADES}" = "1" ] && [ -s requirements/post_upgrades.txt ]; then
            echo "Applying post-upgrades..."
            python -m pip install --upgrade -r requirements/post_upgrades.txt --cache-dir "$PIP_CACHE_DIR"
            pip list
          else
            echo "Skipping post-upgrades (either disabled or file empty)."
          fi

      - name: Run pytest coverage w/ configured instrumentation
        id: run-pytest-coverage
        uses: ./.github/actions/run-pytest-instrumented
        with:
          pytest_filter_pattern: ${{ needs.log-dispatch-inputs.outputs.pytest_filter_pattern }}
          python_version: ${{ matrix.python-version }}
          runner_os: ${{ runner.os }}
          it_ci_log_level: ${{ needs.log-dispatch-inputs.outputs.log_level }}
          workspace: ${{ github.workspace }}
          enable_os_trace: ${{ needs.log-dispatch-inputs.outputs.enable_os_trace }}
          run_resource_monitor: ${{ needs.log-dispatch-inputs.outputs.run_resource_monitor }}
          run_w_grafana: ${{ needs.log-dispatch-inputs.outputs.run_w_grafana }}

      - name: Upload pytest results
        uses: actions/upload-artifact@v4
        with:
          name: pytest-results-${{ runner.os }}-${{ matrix.python-version }}
          path: junit/test-results-${{ runner.os }}-py${{ matrix.python-version }}.xml
        if: failure()

      - name: Load analysis debug dump directory path (on failure)
        if: failure()
        shell: bash
        run: |
          DEBUG_DUMP_DIR="$(python -c 'import tempfile; from interpretune.utils.exceptions import IT_ANALYSIS_DUMP_DIR_NAME; from pathlib import Path; print(Path(tempfile.gettempdir()) / IT_ANALYSIS_DUMP_DIR_NAME)')"
          if [ -d "$DEBUG_DUMP_DIR" ]; then
            echo "DEBUG_DUMP_DIR=$DEBUG_DUMP_DIR" >> $GITHUB_ENV
          fi

      - name: Upload analysis debug dump artifact (if present)
        if: ${{ failure() &&  env.DEBUG_DUMP_DIR != '' }}
        uses: actions/upload-artifact@v4
        with:
          if-no-files-found: ignore
          name: analysis-debug-dump-files-${{ runner.os }}-${{ matrix.python-version }}
          path: ${{ env.DEBUG_DUMP_DIR }}
        continue-on-error: true

      - name: Upload wtrace output (if present)
        if: always() && runner.os == 'Windows' && needs.log-dispatch-inputs.outputs.enable_os_trace == '1' && steps.run-pytest-coverage.outputs.wtrace_log_path != ''
        uses: actions/upload-artifact@v4
        with:
          name: wtrace-filesystem-errors-${{ runner.os }}-${{ matrix.python-version }}
          path: ${{ steps.run-pytest-coverage.outputs.wtrace_log_path }}

      - name: Upload CI resource monitor log (if present)
        if: always() && runner.os == 'Linux' && needs.log-dispatch-inputs.outputs.run_resource_monitor == '1'
        uses: actions/upload-artifact@v4
        with:
          name: ci_resource_monitor-log-${{ runner.os }}-${{ matrix.python-version }}
          path: /tmp/ci_resource_monitor.log
        continue-on-error: true

      - name: Prepare Alloy log (if present)
        id: prepare-alloy-log
        if: always() && runner.os == 'Linux' && needs.log-dispatch-inputs.outputs.run_w_grafana == '1'
        shell: bash
        run: |
          if [ -f /tmp/alloy.log ]; then
            echo "Uploading /tmp/alloy.log as artifact."
            tar -czf /tmp/alloy-log-${{ runner.os }}-${{ matrix.python-version }}.tar.gz -C /tmp alloy.log
            echo "file_exists=true" >> $GITHUB_OUTPUT
          else
            echo "/tmp/alloy.log not found, skipping upload."
            echo "file_exists=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Upload Alloy log artifact
        if: always() && runner.os == 'Linux' && needs.log-dispatch-inputs.outputs.run_w_grafana == '1' && steps.prepare-alloy-log.outputs.file_exists == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: alloy-log-${{ runner.os }}-${{ matrix.python-version }}
          path: /tmp/alloy-log-${{ runner.os }}-${{ matrix.python-version }}.tar.gz
        continue-on-error: true

      - name: Statistics
        if: success()
        shell: bash
        run: |
          if [ -f .coverage ]; then
            python -m coverage report
            python -m coverage xml
          else
            echo "No coverage data to report."
          fi

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
        with:
          file: coverage.xml
          flags: cpu,pytest,python${{ matrix.python-version }}
          name: CPU-coverage
          fail_ci_if_error: false
          verbose: true # optional (default = false)
